{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.csrnet_pytorch.src import *\n",
    "from models.csrnet_pytorch.src.crowd_count import *\n",
    "from models.csrnet_pytorch.src.network import *\n",
    "from models.csrnet_pytorch.src.data_loader import ImageDataLoader\n",
    "from models.csrnet_pytorch.src.timer import *\n",
    "from models.csrnet_pytorch.src.evaluate_model import *\n",
    "from models.csrnet_pytorch.src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check to see if device can be trained on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Using gpu Tesla K80 with device number 0.\n",
      "Memory allocated = 0\n",
      "Memory cached = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cuda configurations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "current_device_name = torch.cuda.get_device_name(current_device)\n",
    "memory_allocated = torch.cuda.memory_allocated()\n",
    "memory_cached = torch.cuda.memory_cached()\n",
    "\n",
    "print(\n",
    "    f'Using gpu {current_device_name} with device number {current_device}.\\n'\n",
    "    f'Memory allocated = {memory_allocated}\\n'\n",
    "    f'Memory cached = {memory_cached}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'csrnet'\n",
    "dataset_name = 'JHU'\n",
    "output_dir = f'../output/{method}/saved_models/{dataset_name}'\n",
    "\n",
    "# Training data path\n",
    "train_path = '../data/JHU/train/consolidated'\n",
    "train_gt_path = '../data/JHU/train/gt'\n",
    "\n",
    "# Validation data path\n",
    "val_path = '../data/JHU/val/consolidated'\n",
    "val_gt_path = '../data/JHU/val/gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (model): CSRNet(\n",
       "    (column): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Conv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Conv2d(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Conv2d(\n",
       "        (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "is_cuda = True  # Determine if we should use the CPU to train or GPU\n",
    "\n",
    "model = CrowdCounter(is_cuda=is_cuda)  # is_cuda determines if all the input tensors should be converted to cuda tensors\n",
    "network.weights_normal_init(model, dev=0.01)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.column.0.conv.weight\tcpu\ttorch.Size([64, 3, 3, 3])\n",
      "model.column.0.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.1.conv.weight\tcpu\ttorch.Size([64, 64, 3, 3])\n",
      "model.column.1.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.3.conv.weight\tcpu\ttorch.Size([128, 64, 3, 3])\n",
      "model.column.3.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.4.conv.weight\tcpu\ttorch.Size([128, 128, 3, 3])\n",
      "model.column.4.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.6.conv.weight\tcpu\ttorch.Size([256, 128, 3, 3])\n",
      "model.column.6.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.7.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.column.7.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.8.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.column.8.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.10.conv.weight\tcpu\ttorch.Size([512, 256, 3, 3])\n",
      "model.column.10.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.11.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.11.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.12.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.12.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.13.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.13.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.14.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.14.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.15.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.15.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.16.conv.weight\tcpu\ttorch.Size([256, 512, 3, 3])\n",
      "model.column.16.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.17.conv.weight\tcpu\ttorch.Size([128, 256, 3, 3])\n",
      "model.column.17.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.18.conv.weight\tcpu\ttorch.Size([64, 128, 3, 3])\n",
      "model.column.18.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.19.conv.weight\tcpu\ttorch.Size([1, 64, 1, 1])\n",
      "model.column.19.conv.bias\tcpu\ttorch.Size([1])\n",
      "\n",
      "Model's state_dict: \n",
      "\n",
      "model.column.0.conv.weight \t torch.float32\n",
      "model.column.0.conv.bias \t torch.float32\n",
      "model.column.1.conv.weight \t torch.float32\n",
      "model.column.1.conv.bias \t torch.float32\n",
      "model.column.3.conv.weight \t torch.float32\n",
      "model.column.3.conv.bias \t torch.float32\n",
      "model.column.4.conv.weight \t torch.float32\n",
      "model.column.4.conv.bias \t torch.float32\n",
      "model.column.6.conv.weight \t torch.float32\n",
      "model.column.6.conv.bias \t torch.float32\n",
      "model.column.7.conv.weight \t torch.float32\n",
      "model.column.7.conv.bias \t torch.float32\n",
      "model.column.8.conv.weight \t torch.float32\n",
      "model.column.8.conv.bias \t torch.float32\n",
      "model.column.10.conv.weight \t torch.float32\n",
      "model.column.10.conv.bias \t torch.float32\n",
      "model.column.11.conv.weight \t torch.float32\n",
      "model.column.11.conv.bias \t torch.float32\n",
      "model.column.12.conv.weight \t torch.float32\n",
      "model.column.12.conv.bias \t torch.float32\n",
      "model.column.13.conv.weight \t torch.float32\n",
      "model.column.13.conv.bias \t torch.float32\n",
      "model.column.14.conv.weight \t torch.float32\n",
      "model.column.14.conv.bias \t torch.float32\n",
      "model.column.15.conv.weight \t torch.float32\n",
      "model.column.15.conv.bias \t torch.float32\n",
      "model.column.16.conv.weight \t torch.float32\n",
      "model.column.16.conv.bias \t torch.float32\n",
      "model.column.17.conv.weight \t torch.float32\n",
      "model.column.17.conv.bias \t torch.float32\n",
      "model.column.18.conv.weight \t torch.float32\n",
      "model.column.18.conv.bias \t torch.float32\n",
      "model.column.19.conv.weight \t torch.float32\n",
      "model.column.19.conv.bias \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}\\t{param.device}\\t{param.shape}')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"\\nModel's state_dict: \\n\")\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, \"\\t\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing to cuda weights\n"
     ]
    }
   ],
   "source": [
    "# Change model weights tensors to be cuda tensors if is_cuda is true and cuda is available\n",
    "\n",
    "if is_cuda and torch.cuda.is_available():\n",
    "    print(\"Changing to cuda weights\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "momentum = 0.9\n",
    "disp_interval = 1\n",
    "log_interval = 250\n",
    "\n",
    "train_loss = 0\n",
    "step_cnt = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "\n",
    "# Set initial values\n",
    "best_mae, best_mse, best_epoch = 999999, 999999, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 107\n",
      "Validation instances: 50\n"
     ]
    }
   ],
   "source": [
    "# Load the images, take note the num_pool argument\n",
    "\n",
    "data_loader = ImageDataLoader(train_path, shuffle=False, pre_load=False, num_pool = 3)\n",
    "data_loader_val = ImageDataLoader(val_path, shuffle=False, pre_load=False, num_pool = 3)\n",
    "\n",
    "print('Training instances: {}'.format(data_loader.get_num_samples()))\n",
    "print('Validation instances: {}'.format(data_loader_val.get_num_samples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs')\n",
    "\n",
    "layout = {\n",
    "    \n",
    "    'MAE': {'Weather': ['Margin', ['Weather/None', 'Weather/Fog', 'Weather/Rain', 'Weather/Snow']],\n",
    "           'Crowd Density': ['Margin', ['Crowd Density/Low', 'Crowd Density/Med', 'Crowd Density/High']]},\n",
    "    \n",
    "    'MSE': {'Weather': ['Margin', ['Weather/None', 'Weather/Fog', 'Weather/Rain', 'Weather/Snow']],\n",
    "           'Crowd Density': ['Margin', ['Crowd Density/Low', 'Crowd Density/Med', 'Crowd Density/High']]}\n",
    "}\n",
    "\n",
    "#writer.add_custom_scalars(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 1.8387s, gt_cnt: 23869.9, et_cnt:     0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models/csrnet_pytorch/src/network.py:53: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  v = Variable(torch.as_tensor(x).type(dtype), requires_grad = False, volatile = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mEPOCH: 0, MAE: 16082.142192687988, MSE: 806773205.8249829\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models/csrnet_pytorch/src/utils.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  density_map = 255 * density_map / np.max(density_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 13.6044s, gt_cnt: 23869.9, et_cnt:     0.0\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-dc34cf14140a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Evaluate the mae and mse results by doing a forward pass against the validation dataset i.e data_loader_val for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mMAEcrowddensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSEcrowddensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAEweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSEweather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Pocket algorithm: Check to see if the current epoch mae is better than the best recorded one,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/models/csrnet_pytorch/src/evaluate_model.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(trained_model, data_loader, is_cuda)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdensity_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdensity_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensity_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mgt_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0met_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "    for id, blob in enumerate(data_loader):                \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "        metadata = blob['metadata']\n",
    "                        \n",
    "        # Forward pass\n",
    "        density_map = model(im_data, gt_data)\n",
    "        \n",
    "        loss = model.loss\n",
    "        train_loss += loss.data\n",
    "        \n",
    "        # Write to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        # Reset zero gradient and backpropagate\n",
    "        step_cnt += 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % disp_interval == 0:            \n",
    "            duration = t.toc(average=False)\n",
    "            fps = step_cnt / duration\n",
    "            gt_count = np.sum(gt_data)    \n",
    "\n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            log_text = 'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %7.1f, et_cnt: %7.1f' % (epoch,step, 1./fps, gt_count, et_count)\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            re_cnt = True\n",
    "       \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "        break\n",
    "\n",
    "    # Overwrite the current model weights\n",
    "    current_model = f'{method}_{learning_rate}.h5'\n",
    "    save_name = os.path.join(output_dir, current_model)\n",
    "    network.save_net(save_name, model)\n",
    "            \n",
    "    # Evaluate the mae and mse results by doing a forward pass against the validation dataset i.e data_loader_val for\n",
    "    # each epoch\n",
    "    MAEcrowddensity, MSEcrowddensity, MAEweather, MSEweather, MAE, MSE = evaluate_model(save_name, data_loader_val, is_cuda=is_cuda)\n",
    "    \n",
    "    # Pocket algorithm: Check to see if the current epoch mae is better than the best recorded one,\n",
    "    # If it is, then overwrite the current best .h5 weights file\n",
    "    if MAE < best_mae:\n",
    "        # Save the new best mae and mse\n",
    "        best_mae = MAE\n",
    "        best_mse = MSE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_model_epoch_{best_epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    # Print out the best epoch that beat the current best mae\n",
    "    log_text = f'EPOCH: {epoch}, MAE: {MAE}, MSE: {MSE}'\n",
    "    log_print(log_text, color='blue', attrs=['bold'])\n",
    "\n",
    "    # Save the results to tensorboard for each epoch\n",
    "    if use_tensorboard:\n",
    "        \n",
    "        # overall segment\n",
    "        writer.add_scalar(\"Overall/MAE\", MAE, epoch)\n",
    "        writer.add_scalar(\"Overall/MSE\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Overall/train_loss\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        \n",
    "        # crowd density segment\n",
    "        writer.add_scalar('High/MAE', MAEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('High/MSE', MSEcrowddensity['High'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Med/MAE', MAEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Med/MSE', MSEcrowddensity['Med'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Low/MAE', MAEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Low/MSE', MSEcrowddensity['Low'], epoch)\n",
    "        \n",
    "        # weather segment\n",
    "        writer.add_scalar('None/MAE', MAEweather['None'], epoch)\n",
    "        writer.add_scalar('None/MSE', MSEweather['None'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Fog/MAE', MAEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Fog/MSE', MSEweather['Fog'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Rain/MAE', MAEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Rain/MSE', MSEweather['Rain'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Snow/MAE', MAEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Snow/MSE', MSEweather['Snow'], epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.csrnet_pytorch.src import *\n",
    "from models.csrnet_pytorch.src.crowd_count import *\n",
    "from models.csrnet_pytorch.src.network import *\n",
    "from models.csrnet_pytorch.src.data_loader import ImageDataLoader\n",
    "from models.csrnet_pytorch.src.timer import *\n",
    "from models.csrnet_pytorch.src.evaluate_model import *\n",
    "from models.csrnet_pytorch.src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check to see if device can be trained on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Using gpu Tesla K80 with device number 0.\n",
      "Memory allocated = 0\n",
      "Memory cached = 0\n"
     ]
    }
   ],
   "source": [
    "# Cuda configurations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "current_device_name = torch.cuda.get_device_name(current_device)\n",
    "memory_allocated = torch.cuda.memory_allocated()\n",
    "memory_cached = torch.cuda.memory_reserved()\n",
    "\n",
    "print(\n",
    "    f'Using gpu {current_device_name} with device number {current_device}.\\n'\n",
    "    f'Memory allocated = {memory_allocated}\\n'\n",
    "    f'Memory cached = {memory_cached}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'csrnet'\n",
    "dataset_name = 'JHU'\n",
    "output_dir = f'../output/{method}/saved_models/{dataset_name}'\n",
    "\n",
    "# Training data path\n",
    "train_path = '../data/JHU/train/consolidated'\n",
    "train_gt_path = '../data/JHU/train/gt'\n",
    "\n",
    "# Validation data path\n",
    "val_path = '../data/JHU/val/consolidated'\n",
    "val_gt_path = '../data/JHU/val/gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (model): CSRNet(\n",
       "    (column): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Conv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Conv2d(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Conv2d(\n",
       "        (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): SmoothL1Loss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "is_cuda = True  # Determine if we should use the CPU to train or GPU\n",
    "\n",
    "model = CrowdCounter(is_cuda=is_cuda)  # is_cuda determines if all the input tensors should be converted to cuda tensors\n",
    "network.weights_normal_init(model, dev=0.01)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.column.0.conv.weight\tcpu\ttorch.Size([64, 3, 3, 3])\n",
      "model.column.0.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.1.conv.weight\tcpu\ttorch.Size([64, 64, 3, 3])\n",
      "model.column.1.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.3.conv.weight\tcpu\ttorch.Size([128, 64, 3, 3])\n",
      "model.column.3.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.4.conv.weight\tcpu\ttorch.Size([128, 128, 3, 3])\n",
      "model.column.4.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.6.conv.weight\tcpu\ttorch.Size([256, 128, 3, 3])\n",
      "model.column.6.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.7.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.column.7.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.8.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.column.8.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.10.conv.weight\tcpu\ttorch.Size([512, 256, 3, 3])\n",
      "model.column.10.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.11.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.11.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.12.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.12.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.13.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.13.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.14.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.14.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.15.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.column.15.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.column.16.conv.weight\tcpu\ttorch.Size([256, 512, 3, 3])\n",
      "model.column.16.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.column.17.conv.weight\tcpu\ttorch.Size([128, 256, 3, 3])\n",
      "model.column.17.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.column.18.conv.weight\tcpu\ttorch.Size([64, 128, 3, 3])\n",
      "model.column.18.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.column.19.conv.weight\tcpu\ttorch.Size([1, 64, 1, 1])\n",
      "model.column.19.conv.bias\tcpu\ttorch.Size([1])\n",
      "\n",
      "Model's state_dict: \n",
      "\n",
      "model.column.0.conv.weight \t torch.float32\n",
      "model.column.0.conv.bias \t torch.float32\n",
      "model.column.1.conv.weight \t torch.float32\n",
      "model.column.1.conv.bias \t torch.float32\n",
      "model.column.3.conv.weight \t torch.float32\n",
      "model.column.3.conv.bias \t torch.float32\n",
      "model.column.4.conv.weight \t torch.float32\n",
      "model.column.4.conv.bias \t torch.float32\n",
      "model.column.6.conv.weight \t torch.float32\n",
      "model.column.6.conv.bias \t torch.float32\n",
      "model.column.7.conv.weight \t torch.float32\n",
      "model.column.7.conv.bias \t torch.float32\n",
      "model.column.8.conv.weight \t torch.float32\n",
      "model.column.8.conv.bias \t torch.float32\n",
      "model.column.10.conv.weight \t torch.float32\n",
      "model.column.10.conv.bias \t torch.float32\n",
      "model.column.11.conv.weight \t torch.float32\n",
      "model.column.11.conv.bias \t torch.float32\n",
      "model.column.12.conv.weight \t torch.float32\n",
      "model.column.12.conv.bias \t torch.float32\n",
      "model.column.13.conv.weight \t torch.float32\n",
      "model.column.13.conv.bias \t torch.float32\n",
      "model.column.14.conv.weight \t torch.float32\n",
      "model.column.14.conv.bias \t torch.float32\n",
      "model.column.15.conv.weight \t torch.float32\n",
      "model.column.15.conv.bias \t torch.float32\n",
      "model.column.16.conv.weight \t torch.float32\n",
      "model.column.16.conv.bias \t torch.float32\n",
      "model.column.17.conv.weight \t torch.float32\n",
      "model.column.17.conv.bias \t torch.float32\n",
      "model.column.18.conv.weight \t torch.float32\n",
      "model.column.18.conv.bias \t torch.float32\n",
      "model.column.19.conv.weight \t torch.float32\n",
      "model.column.19.conv.bias \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}\\t{param.device}\\t{param.shape}')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"\\nModel's state_dict: \\n\")\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, \"\\t\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing to cuda weights\n"
     ]
    }
   ],
   "source": [
    "# Change model weights tensors to be cuda tensors if is_cuda is true and cuda is available\n",
    "\n",
    "if is_cuda and torch.cuda.is_available():\n",
    "    print(\"Changing to cuda weights\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "momentum = 0.9\n",
    "disp_interval = 1\n",
    "log_interval = 250\n",
    "\n",
    "train_loss = 0\n",
    "step_cnt = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "\n",
    "# Set initial values\n",
    "best_mae, best_mse, best_epoch = 999999, 999999, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 3\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 500\n",
      "Validation instances: 100\n"
     ]
    }
   ],
   "source": [
    "# Load the images, take note the num_pool argument\n",
    "\n",
    "data_loader = ImageDataLoader(train_path, shuffle=False, pre_load=False, num_pool = 3)\n",
    "data_loader_val = ImageDataLoader(val_path, shuffle=False, pre_load=False, num_pool = 3)\n",
    "\n",
    "print('Training instances: {}'.format(data_loader.get_num_samples()))\n",
    "print('Validation instances: {}'.format(data_loader_val.get_num_samples()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Analysis\n",
    "\n",
    "def AnalyseLoader(loader, title='Breakdown of the images in the loader by type'):\n",
    "    d = {'High': 0, 'Med': 0, 'Low': 0, 'None': 0, 'Fog': 0, 'Rain': 0, 'Snow': 0}\n",
    "    colours = ['orange', 'orange', 'orange', 'green', 'green', 'green', 'green']\n",
    "    labels = ['crowd', 'weather', 'weather', 'weather', 'weather', 'weather', 'weather']\n",
    "    for id, blob in enumerate(loader):\n",
    "        metadata = blob['metadata']\n",
    "        d[metadata['crowd_density']] += 1\n",
    "        d[metadata['weather']] += 1\n",
    "    for i, key in enumerate(d):\n",
    "        plt.text(i, d[key], '{}%'.format(d[key]*100/loader.get_num_samples()), \n",
    "                 ha='center', va='bottom', size=10)\n",
    "    pd.Series(d).plot(kind='bar', figsize=(8,5), color=colours)\n",
    "    leg1 = mpatches.Patch(color='orange', label='Crowd Density')\n",
    "    leg2 = mpatches.Patch(color='green', label='Weather')\n",
    "    plt.legend(handles=[leg1, leg2])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "#AnalyseLoader(data_loader, title='train')\n",
    "#AnalyseLoader(data_loader_val, title='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs/{learning_rate}_{epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m[  1,   1] Actual Count:     40, Estimated Count:    0.0\u001b[0m\n",
      "\u001b[1m\u001b[32m[  1,   2] Actual Count:     76, Estimated Count:   26.5\u001b[0m\n",
      "\u001b[1m\u001b[32m[  1,   3] Actual Count:    756, Estimated Count:  512.9\u001b[0m\n",
      "\u001b[1m\u001b[32m[  1,   4] Actual Count:    839, Estimated Count: 1447.8\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a345d63f4592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    train_loss = 0.0\n",
    "    for id, blob in enumerate(data_loader, 1):  \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "        metadata = blob['metadata']\n",
    "                        \n",
    "        # Set the parameter gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass + backward pass + optimise\n",
    "        try:\n",
    "            density_map = model(im_data, gt_data)\n",
    "        except:\n",
    "            continue\n",
    "        loss = model.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Write to tensorboard\n",
    "        train_loss += loss.item()\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        if id % disp_interval == 0:            \n",
    "            duration = t.toc(average=False)\n",
    "            fps = step_cnt / duration\n",
    "            gt_count = np.sum(gt_data)    \n",
    "\n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            #log_text = 'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %7.1f, et_cnt: %7.1f' % (epoch,step, 1./1, gt_count, et_count)\n",
    "            log_text = '[%3d, %3d] Actual Count: %6d, Estimated Count: %6.1f' % (epoch+1, id, gt_count, et_count)\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            re_cnt = True\n",
    "       \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "            \n",
    "        # if id+1 == 10: break\n",
    "    \n",
    "    # Overwrite the current model weights\n",
    "    current_model = f'{method}_{learning_rate}.h5'\n",
    "    save_name = os.path.join(output_dir, current_model)\n",
    "    network.save_net(save_name, model)\n",
    "            \n",
    "    # Evaluate the mae and mse results by doing a forward pass against the validation dataset i.e data_loader_val for\n",
    "    # each epoch\n",
    "    MAEcrowddensity, MSEcrowddensity, MAEweather, MSEweather, MAE, MSE, RMSE = evaluate_model(save_name, data_loader_val, is_cuda=is_cuda)\n",
    "    \n",
    "    # Pocket algorithm: Check to see if the current epoch mae is better than the best recorded one,\n",
    "    # If it is, then overwrite the current best .h5 weights file\n",
    "    if MAE < best_mae:\n",
    "        # Save the new best mae and mse\n",
    "        best_mae = MAE\n",
    "        best_mse = MSE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_model_epoch_{best_epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    # Print out the best epoch that beat the current best mae\n",
    "    log_text = f'EPOCH: {epoch+1}, Val MAE: {MAE}, Val MSE: {MSE}'\n",
    "    log_print(log_text, color='blue', attrs=['bold'])\n",
    "\n",
    "    # Save the results to tensorboard for each epoch\n",
    "    if use_tensorboard:\n",
    "        \n",
    "        # overall segment\n",
    "        writer.add_scalar(\"Overall/Val MAE\", MAE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val MSE\", MSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val RMSE\", RMSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Train MSE\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        writer.add_scalar(\"Overall/Train RMSE\", np.sqrt(train_loss / data_loader.get_num_samples()), epoch)\n",
    "        \n",
    "        # crowd density segment\n",
    "        writer.add_scalar('Crowd Density/High/MAE', MAEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/MSE', MSEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/RMSE', np.sqrt(MSEcrowddensity['High']), epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Med/MAE', MAEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/MSE', MSEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/RMSE', np.sqrt(MSEcrowddensity['Med']), epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Low/MAE', MAEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/MSE', MSEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/RMSE', np.sqrt(MSEcrowddensity['Low']), epoch)\n",
    "        \n",
    "        # weather segment\n",
    "        writer.add_scalar('Weather/No Degradation/MAE', MAEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/MSE', MSEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/RMSE', np.sqrt(MSEweather['None']), epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Fog/MAE', MAEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/MSE', MSEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/RMSE', np.sqrt(MSEweather['Fog']), epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Rain/MAE', MAEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/MSE', MSEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/RMSE', np.sqrt(MSEweather['Rain']), epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Snow/MAE', MAEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/MSE', MSEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/RMSE', np.sqrt(MSEweather['Snow']), epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

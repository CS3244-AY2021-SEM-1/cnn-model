{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.mcnnpytorch.src.crowd_count import CrowdCounter\n",
    "from models.mcnnpytorch.src import network\n",
    "from models.mcnnpytorch.src.data_loader import ImageDataLoader\n",
    "from models.mcnnpytorch.src.timer import Timer\n",
    "from models.mcnnpytorch.src import utils\n",
    "from models.mcnnpytorch.src.evaluate_model import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'mcnn'\n",
    "dataset_name = 'shtechB'\n",
    "output_dir = '../output/mcnnpytorch/saved_models'\n",
    "\n",
    "train_path = '../data/SHT/part_B_final/train_data/consolidated'\n",
    "train_gt_path = '../data/SHT/part_B_final/train_data/ground_truth'\n",
    "val_path = '../data/SHT/part_B_final/test_data/consolidated'\n",
    "val_gt_path = '../data/SHT/part_B_final/test_data/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (DME): MCNN(\n",
       "    (branch1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(40, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(20, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(30, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "net = CrowdCounter()\n",
    "network.weights_normal_init(net, dev=0.01)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "start_step = 0\n",
    "end_step = 20\n",
    "momentum = 0.9\n",
    "disp_interval = 2\n",
    "log_interval = 250\n",
    "\n",
    "train_loss = 0\n",
    "step_cnt = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.00001\n",
    "\n",
    "params = list(net.parameters())\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 64678  \n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    torch.cuda.manual_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading the data. This may take a while...\n",
      "Completed Loading 3 files\n",
      "Pre-loading the data. This may take a while...\n",
      "Completed Loading 3 files\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_loader = ImageDataLoader(train_path, train_gt_path, shuffle=True, pre_load=True)\n",
    "data_loader_val = ImageDataLoader(val_path, val_gt_path, shuffle=False, pre_load=True)\n",
    "best_mae = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 426.2203s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    2, Time: 8.6151s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models/mcnnpytorch/src/network.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  v = Variable(torch.as_tensor(x).type(dtype), requires_grad = False, volatile = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mEPOCH: 0, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 6.7408s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    2, Time: 4.9336s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    0, Time: 2.7558s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    2, Time: 3.8162s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 2, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    0, Time: 2.9597s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    2, Time: 2.3137s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    0, Time: 1.2125s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    2, Time: 2.6159s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 4, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    0, Time: 2.0531s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    2, Time: 1.9633s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    0, Time: 1.0681s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    2, Time: 1.4193s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 6, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    0, Time: 1.6808s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    2, Time: 1.3548s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    0, Time: 0.6267s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    2, Time: 1.1362s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 8, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    0, Time: 1.1278s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    2, Time: 1.2428s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step    0, Time: 0.4798s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step    2, Time: 0.9479s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 10, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step    0, Time: 0.9387s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step    2, Time: 0.8238s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step    0, Time: 0.4292s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step    2, Time: 0.9589s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 12, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step    0, Time: 1.1509s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step    2, Time: 1.1791s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step    0, Time: 0.6459s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step    2, Time: 1.1464s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 14, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step    0, Time: 1.0657s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step    2, Time: 0.9685s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step    0, Time: 0.4607s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step    2, Time: 1.4080s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 16, MAE: 113.0, MSE: 132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 113.0, BEST MSE: 132.9, BEST MODEL: mcnn_shtechB_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step    0, Time: 1.4152s, gt_cnt: 230.0, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step    2, Time: 2.0710s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step    0, Time: 1.6241s, gt_cnt: 206.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step    2, Time: 6.2465s, gt_cnt: 234.0, et_cnt:  5.7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_step, end_step+1):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "    for blob in data_loader:                \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "        \n",
    "        density_map = net(im_data, gt_data)\n",
    "        loss = net.loss\n",
    "        train_loss += loss.data\n",
    "        \n",
    "        # Write to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "        \n",
    "        step_cnt += 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % disp_interval == 0:            \n",
    "            duration = t.toc(average=False)\n",
    "            fps = step_cnt / duration\n",
    "            gt_count = np.sum(gt_data)    \n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            log_text = 'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %4.1f, et_cnt: %4.1f' % (epoch,\n",
    "                step, 1./fps, gt_count,et_count)\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            re_cnt = True    \n",
    "    \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "\n",
    "    if (epoch % 2 == 0):\n",
    "        save_name = os.path.join(output_dir, '{}_{}_{}.h5'.format(method,dataset_name,epoch))\n",
    "        network.save_net(save_name, net)   \n",
    "        \n",
    "        #calculate error on the validation dataset \n",
    "        mae,mse = evaluate_model(save_name, data_loader_val)\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_mse = mse\n",
    "            best_model = '{}_{}_{}.h5'.format(method,dataset_name,epoch)\n",
    "    \n",
    "        log_text = 'EPOCH: %d, MAE: %.1f, MSE: %0.1f' % (epoch,mae,mse)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "        log_text = 'BEST MAE: %0.1f, BEST MSE: %0.1f, BEST MODEL: %s' % (best_mae,best_mse, best_model)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "        \n",
    "        if use_tensorboard:\n",
    "            writer.add_scalar(\"MAE\", mae, epoch)\n",
    "            writer.add_scalar(\"MSE\", train_loss, epoch)\n",
    "            writer.add_scalar(\"train_loss\", train_loss/data_loader.get_num_samples(), epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close tensorboard\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

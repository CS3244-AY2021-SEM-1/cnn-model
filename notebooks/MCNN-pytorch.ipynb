{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.mcnnpytorch.src.crowd_count import CrowdCounter\n",
    "from models.mcnnpytorch.src import network\n",
    "from models.mcnnpytorch.src.data_loader import ImageDataLoader\n",
    "from models.mcnnpytorch.src.timer import Timer\n",
    "from models.mcnnpytorch.src import utils\n",
    "from models.mcnnpytorch.src.evaluate_model import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "try:\n",
    "    from pycrayon import CrayonClient\n",
    "except ImportError:\n",
    "    CrayonClient = None\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'mcnn'\n",
    "dataset_name = 'shtechA'\n",
    "output_dir = '../output/mcnnpytorch/saved_models'\n",
    "\n",
    "train_path = '../data/SHT/part_A_final/train_data/consolidated'\n",
    "train_gt_path = '../data/SHT/part_A_final/train_data/ground_truth'\n",
    "val_path = '../data/SHT/part_A_final/test_data/consolidated'\n",
    "val_gt_path = '../data/SHT/part_A_final/test_data/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "start_step = 0\n",
    "end_step = 20\n",
    "lr = 0.00001\n",
    "momentum = 0.9\n",
    "disp_interval = 2\n",
    "log_interval = 250\n",
    "\n",
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "save_exp_name = method + '_' + dataset_name + '_' + 'v1'\n",
    "remove_all_log = False   # remove all historical experiments in TensorBoard\n",
    "exp_name = None # the previous experiment name in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboad\n",
    "use_tensorboard = use_tensorboard and CrayonClient is not None\n",
    "if use_tensorboard:\n",
    "    cc = CrayonClient(hostname='127.0.0.1')\n",
    "    if remove_all_log:\n",
    "        cc.remove_all_experiments()\n",
    "    if exp_name is None:    \n",
    "        exp_name = save_exp_name \n",
    "        exp = cc.create_experiment(exp_name)\n",
    "    else:\n",
    "        exp = cc.open_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 64678  \n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "    torch.cuda.manual_seed(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (DME): MCNN(\n",
       "    (branch1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(40, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(20, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(30, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load net\n",
    "net = CrowdCounter()\n",
    "network.weights_normal_init(net, dev=0.01)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "train_loss = 0\n",
    "step_cnt = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading the data. This may take a while...\n",
      "Completed Loading 4 files\n",
      "Pre-loading the data. This may take a while...\n",
      "Completed Loading 3 files\n"
     ]
    }
   ],
   "source": [
    "data_loader = ImageDataLoader(train_path, train_gt_path, shuffle=True, pre_load=True)\n",
    "data_loader_val = ImageDataLoader(val_path, val_gt_path, shuffle=False, pre_load=True)\n",
    "best_mae = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 16.6296s, gt_cnt: 1545.0, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    2, Time: 9.0322s, gt_cnt: 580.0, et_cnt: 20.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../models/mcnnpytorch/src/network.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  v = Variable(torch.as_tensor(x).type(dtype), requires_grad = False, volatile = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mEPOCH: 0, MAE: 497.9, MSE: 645.6\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 497.9, BEST MSE: 645.6, BEST MODEL: mcnn_shtechA_0.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 10.4750s, gt_cnt: 707.0, et_cnt: 37.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    2, Time: 5.9879s, gt_cnt: 1545.0, et_cnt: 61.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    0, Time: 3.2585s, gt_cnt: 580.0, et_cnt: 62.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    2, Time: 2.9807s, gt_cnt: 707.0, et_cnt: 83.9\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 2, MAE: 449.2, MSE: 605.1\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 449.2, BEST MSE: 605.1, BEST MODEL: mcnn_shtechA_2.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    0, Time: 2.9086s, gt_cnt: 262.0, et_cnt: 95.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    2, Time: 2.2657s, gt_cnt: 580.0, et_cnt: 105.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    0, Time: 2.0353s, gt_cnt: 262.0, et_cnt: 124.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    2, Time: 2.2885s, gt_cnt: 707.0, et_cnt: 143.9\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 4, MAE: 402.4, MSE: 568.0\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 402.4, BEST MSE: 568.0, BEST MODEL: mcnn_shtechA_4.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    0, Time: 2.3165s, gt_cnt: 262.0, et_cnt: 151.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    2, Time: 1.5287s, gt_cnt: 1545.0, et_cnt: 198.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    0, Time: 1.1884s, gt_cnt: 262.0, et_cnt: 181.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    2, Time: 1.2584s, gt_cnt: 1545.0, et_cnt: 233.9\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 6, MAE: 387.7, MSE: 531.6\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 387.7, BEST MSE: 531.6, BEST MODEL: mcnn_shtechA_6.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    0, Time: 1.5546s, gt_cnt: 1545.0, et_cnt: 252.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    2, Time: 0.9799s, gt_cnt: 707.0, et_cnt: 237.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    0, Time: 0.8744s, gt_cnt: 707.0, et_cnt: 253.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    2, Time: 0.9078s, gt_cnt: 580.0, et_cnt: 249.0\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 8, MAE: 380.3, MSE: 496.4\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 380.3, BEST MSE: 496.4, BEST MODEL: mcnn_shtechA_8.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    0, Time: 1.1419s, gt_cnt: 1545.0, et_cnt: 327.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    2, Time: 0.6765s, gt_cnt: 580.0, et_cnt: 277.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step    0, Time: 0.7865s, gt_cnt: 1545.0, et_cnt: 364.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step    2, Time: 0.7081s, gt_cnt: 707.0, et_cnt: 330.8\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 10, MAE: 373.3, MSE: 465.8\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 373.3, BEST MSE: 465.8, BEST MODEL: mcnn_shtechA_10.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step    0, Time: 0.8452s, gt_cnt: 580.0, et_cnt: 319.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step    2, Time: 0.6308s, gt_cnt: 707.0, et_cnt: 358.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step    0, Time: 0.7318s, gt_cnt: 707.0, et_cnt: 372.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step    2, Time: 0.5485s, gt_cnt: 1545.0, et_cnt: 450.4\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 12, MAE: 366.9, MSE: 441.6\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 366.9, BEST MSE: 441.6, BEST MODEL: mcnn_shtechA_12.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step    0, Time: 0.9144s, gt_cnt: 707.0, et_cnt: 400.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step    2, Time: 0.5516s, gt_cnt: 1545.0, et_cnt: 486.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step    0, Time: 0.5394s, gt_cnt: 580.0, et_cnt: 394.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step    2, Time: 0.5076s, gt_cnt: 262.0, et_cnt: 429.3\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 14, MAE: 360.4, MSE: 420.8\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 360.4, BEST MSE: 420.8, BEST MODEL: mcnn_shtechA_14.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step    0, Time: 0.7876s, gt_cnt: 1545.0, et_cnt: 540.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step    2, Time: 0.4425s, gt_cnt: 580.0, et_cnt: 433.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step    0, Time: 0.4847s, gt_cnt: 707.0, et_cnt: 487.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step    2, Time: 0.5475s, gt_cnt: 1545.0, et_cnt: 596.8\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 16, MAE: 353.5, MSE: 404.3\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 353.5, BEST MSE: 404.3, BEST MODEL: mcnn_shtechA_16.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step    0, Time: 0.5870s, gt_cnt: 580.0, et_cnt: 471.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step    2, Time: 0.5141s, gt_cnt: 1545.0, et_cnt: 631.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step    0, Time: 0.4231s, gt_cnt: 262.0, et_cnt: 528.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step    2, Time: 0.4637s, gt_cnt: 580.0, et_cnt: 502.4\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 18, MAE: 348.0, MSE: 395.4\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 348.0, BEST MSE: 395.4, BEST MODEL: mcnn_shtechA_18.h5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step    0, Time: 0.7892s, gt_cnt: 707.0, et_cnt: 563.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step    2, Time: 0.4746s, gt_cnt: 580.0, et_cnt: 522.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step    0, Time: 0.5277s, gt_cnt: 262.0, et_cnt: 574.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step    2, Time: 0.5851s, gt_cnt: 580.0, et_cnt: 542.7\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 20, MAE: 342.6, MSE: 391.0\u001b[0m\n",
      "\u001b[1m\u001b[32mBEST MAE: 342.6, BEST MSE: 391.0, BEST MODEL: mcnn_shtechA_20.h5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_step, end_step+1):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "    for blob in data_loader:                \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "        density_map = net(im_data, gt_data)\n",
    "        loss = net.loss\n",
    "        train_loss += loss.data\n",
    "        step_cnt += 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % disp_interval == 0:            \n",
    "            duration = t.toc(average=False)\n",
    "            fps = step_cnt / duration\n",
    "            gt_count = np.sum(gt_data)    \n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            log_text = 'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %4.1f, et_cnt: %4.1f' % (epoch,\n",
    "                step, 1./fps, gt_count,et_count)\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            re_cnt = True    \n",
    "    \n",
    "       \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "\n",
    "    if (epoch % 2 == 0):\n",
    "        save_name = os.path.join(output_dir, '{}_{}_{}.h5'.format(method,dataset_name,epoch))\n",
    "        network.save_net(save_name, net)     \n",
    "        #calculate error on the validation dataset \n",
    "        mae,mse = evaluate_model(save_name, data_loader_val)\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_mse = mse\n",
    "            best_model = '{}_{}_{}.h5'.format(method,dataset_name,epoch)\n",
    "        log_text = 'EPOCH: %d, MAE: %.1f, MSE: %0.1f' % (epoch,mae,mse)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "        log_text = 'BEST MAE: %0.1f, BEST MSE: %0.1f, BEST MODEL: %s' % (best_mae,best_mse, best_model)\n",
    "        log_print(log_text, color='green', attrs=['bold'])\n",
    "        if use_tensorboard:\n",
    "            exp.add_scalar_value('MAE', mae, step=epoch)\n",
    "            exp.add_scalar_value('MSE', mse, step=epoch)\n",
    "            exp.add_scalar_value('train_loss', train_loss/data_loader.get_num_samples(), step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.smc.src import *\n",
    "from models.smc.src.crowd_count import *\n",
    "from models.smc.src.network import *\n",
    "from models.smc.src.data_loader import ImageDataLoader\n",
    "from models.smc.src.timer import *\n",
    "from models.smc.src.evaluate_model import *\n",
    "from models.smc.src import utils\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check to see if device can be trained on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Using gpu Tesla T4 with device number 0.\n",
      "Memory allocated = 0\n",
      "Memory cached = 0\n"
     ]
    }
   ],
   "source": [
    "# Cuda configurations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "current_device_name = torch.cuda.get_device_name(current_device)\n",
    "memory_allocated = torch.cuda.memory_allocated()\n",
    "memory_cached = torch.cuda.memory_reserved()\n",
    "\n",
    "print(\n",
    "    f'Using gpu {current_device_name} with device number {current_device}.\\n'\n",
    "    f'Memory allocated = {memory_allocated}\\n'\n",
    "    f'Memory cached = {memory_cached}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'smc'\n",
    "dataset_name = 'JHU'\n",
    "output_dir = f'../output/{method}/saved_models/{dataset_name}'\n",
    "\n",
    "# Training data path\n",
    "train_path = '../data/JHU/train/consolidated'\n",
    "train_gt_path = '../data/JHU/train/gt'\n",
    "\n",
    "# Validation data path\n",
    "val_path = '../data/JHU/val/consolidated'\n",
    "val_gt_path = '../data/JHU/val/gt'\n",
    "\n",
    "# Test data path\n",
    "test_path = '../data/JHU/test/consolidated'\n",
    "test_gt_path = '../data/JHU/test/gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (model): SMC(\n",
       "    (r1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(40, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(20, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_2): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r3): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Conv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Conv2d(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(82, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "is_cuda = True  # Determine if we should use the CPU to train or GPU\n",
    "\n",
    "model = CrowdCounter(is_cuda=is_cuda)  # is_cuda determines if all the input tensors should be converted to cuda tensors\n",
    "network.weights_normal_init(model, dev=0.01)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.r1.0.conv.weight\tcpu\ttorch.Size([16, 3, 9, 9])\n",
      "model.r1.0.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.2.conv.weight\tcpu\ttorch.Size([32, 16, 7, 7])\n",
      "model.r1.2.conv.bias\tcpu\ttorch.Size([32])\n",
      "model.r1.4.conv.weight\tcpu\ttorch.Size([16, 32, 7, 7])\n",
      "model.r1.4.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.5.conv.weight\tcpu\ttorch.Size([8, 16, 7, 7])\n",
      "model.r1.5.conv.bias\tcpu\ttorch.Size([8])\n",
      "model.r2_1.0.conv.weight\tcpu\ttorch.Size([20, 3, 7, 7])\n",
      "model.r2_1.0.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.2.conv.weight\tcpu\ttorch.Size([40, 20, 5, 5])\n",
      "model.r2_1.2.conv.bias\tcpu\ttorch.Size([40])\n",
      "model.r2_1.4.conv.weight\tcpu\ttorch.Size([20, 40, 5, 5])\n",
      "model.r2_1.4.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.5.conv.weight\tcpu\ttorch.Size([10, 20, 5, 5])\n",
      "model.r2_1.5.conv.bias\tcpu\ttorch.Size([10])\n",
      "model.r2_2.0.conv.weight\tcpu\ttorch.Size([24, 3, 5, 5])\n",
      "model.r2_2.0.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.2.conv.weight\tcpu\ttorch.Size([48, 24, 3, 3])\n",
      "model.r2_2.2.conv.bias\tcpu\ttorch.Size([48])\n",
      "model.r2_2.4.conv.weight\tcpu\ttorch.Size([24, 48, 3, 3])\n",
      "model.r2_2.4.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.5.conv.weight\tcpu\ttorch.Size([12, 24, 3, 3])\n",
      "model.r2_2.5.conv.bias\tcpu\ttorch.Size([12])\n",
      "model.r3.0.conv.weight\tcpu\ttorch.Size([64, 3, 3, 3])\n",
      "model.r3.0.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.1.conv.weight\tcpu\ttorch.Size([64, 64, 3, 3])\n",
      "model.r3.1.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.3.conv.weight\tcpu\ttorch.Size([128, 64, 3, 3])\n",
      "model.r3.3.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.4.conv.weight\tcpu\ttorch.Size([128, 128, 3, 3])\n",
      "model.r3.4.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.6.conv.weight\tcpu\ttorch.Size([256, 128, 3, 3])\n",
      "model.r3.6.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.7.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.7.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.8.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.8.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.9.conv.weight\tcpu\ttorch.Size([512, 256, 3, 3])\n",
      "model.r3.9.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.10.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.10.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.11.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.11.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.12.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.12.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.13.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.13.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.14.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.14.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.15.conv.weight\tcpu\ttorch.Size([256, 512, 3, 3])\n",
      "model.r3.15.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.16.conv.weight\tcpu\ttorch.Size([128, 256, 3, 3])\n",
      "model.r3.16.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.17.conv.weight\tcpu\ttorch.Size([64, 128, 3, 3])\n",
      "model.r3.17.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.fuse.0.conv.weight\tcpu\ttorch.Size([1, 82, 1, 1])\n",
      "model.fuse.0.conv.bias\tcpu\ttorch.Size([1])\n",
      "\n",
      "Model's state_dict: \n",
      "\n",
      "model.r1.0.conv.weight \t torch.float32\n",
      "model.r1.0.conv.bias \t torch.float32\n",
      "model.r1.2.conv.weight \t torch.float32\n",
      "model.r1.2.conv.bias \t torch.float32\n",
      "model.r1.4.conv.weight \t torch.float32\n",
      "model.r1.4.conv.bias \t torch.float32\n",
      "model.r1.5.conv.weight \t torch.float32\n",
      "model.r1.5.conv.bias \t torch.float32\n",
      "model.r2_1.0.conv.weight \t torch.float32\n",
      "model.r2_1.0.conv.bias \t torch.float32\n",
      "model.r2_1.2.conv.weight \t torch.float32\n",
      "model.r2_1.2.conv.bias \t torch.float32\n",
      "model.r2_1.4.conv.weight \t torch.float32\n",
      "model.r2_1.4.conv.bias \t torch.float32\n",
      "model.r2_1.5.conv.weight \t torch.float32\n",
      "model.r2_1.5.conv.bias \t torch.float32\n",
      "model.r2_2.0.conv.weight \t torch.float32\n",
      "model.r2_2.0.conv.bias \t torch.float32\n",
      "model.r2_2.2.conv.weight \t torch.float32\n",
      "model.r2_2.2.conv.bias \t torch.float32\n",
      "model.r2_2.4.conv.weight \t torch.float32\n",
      "model.r2_2.4.conv.bias \t torch.float32\n",
      "model.r2_2.5.conv.weight \t torch.float32\n",
      "model.r2_2.5.conv.bias \t torch.float32\n",
      "model.r3.0.conv.weight \t torch.float32\n",
      "model.r3.0.conv.bias \t torch.float32\n",
      "model.r3.1.conv.weight \t torch.float32\n",
      "model.r3.1.conv.bias \t torch.float32\n",
      "model.r3.3.conv.weight \t torch.float32\n",
      "model.r3.3.conv.bias \t torch.float32\n",
      "model.r3.4.conv.weight \t torch.float32\n",
      "model.r3.4.conv.bias \t torch.float32\n",
      "model.r3.6.conv.weight \t torch.float32\n",
      "model.r3.6.conv.bias \t torch.float32\n",
      "model.r3.7.conv.weight \t torch.float32\n",
      "model.r3.7.conv.bias \t torch.float32\n",
      "model.r3.8.conv.weight \t torch.float32\n",
      "model.r3.8.conv.bias \t torch.float32\n",
      "model.r3.9.conv.weight \t torch.float32\n",
      "model.r3.9.conv.bias \t torch.float32\n",
      "model.r3.10.conv.weight \t torch.float32\n",
      "model.r3.10.conv.bias \t torch.float32\n",
      "model.r3.11.conv.weight \t torch.float32\n",
      "model.r3.11.conv.bias \t torch.float32\n",
      "model.r3.12.conv.weight \t torch.float32\n",
      "model.r3.12.conv.bias \t torch.float32\n",
      "model.r3.13.conv.weight \t torch.float32\n",
      "model.r3.13.conv.bias \t torch.float32\n",
      "model.r3.14.conv.weight \t torch.float32\n",
      "model.r3.14.conv.bias \t torch.float32\n",
      "model.r3.15.conv.weight \t torch.float32\n",
      "model.r3.15.conv.bias \t torch.float32\n",
      "model.r3.16.conv.weight \t torch.float32\n",
      "model.r3.16.conv.bias \t torch.float32\n",
      "model.r3.17.conv.weight \t torch.float32\n",
      "model.r3.17.conv.bias \t torch.float32\n",
      "model.fuse.0.conv.weight \t torch.float32\n",
      "model.fuse.0.conv.bias \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}\\t{param.device}\\t{param.shape}')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"\\nModel's state_dict: \\n\")\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, \"\\t\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing to cuda weights\n"
     ]
    }
   ],
   "source": [
    "# Change model weights tensors to be cuda tensors if is_cuda is true and cuda is available\n",
    "\n",
    "if is_cuda and torch.cuda.is_available():\n",
    "    print(\"Changing to cuda weights\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "disp_interval = 10\n",
    "\n",
    "train_loss = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "\n",
    "# Set initial values\n",
    "best_mae, best_mse, best_epoch, best_mape = 999999, 999999, 0, 9999999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 200\n",
      "Validation instances: 40\n",
      "Test instances: 40\n"
     ]
    }
   ],
   "source": [
    "# Load the images, take note the num_pool argument\n",
    "\n",
    "data_loader = ImageDataLoader(train_path, shuffle=False, pre_load=False, size = 200)\n",
    "data_loader_val = ImageDataLoader(val_path, shuffle=False, pre_load=False, size = 40)\n",
    "data_loader_test = ImageDataLoader(test_path, shuffle=False, pre_load=False, size= 40)\n",
    "\n",
    "print('Training instances: {}'.format(data_loader.get_num_samples()))\n",
    "print('Validation instances: {}'.format(data_loader_val.get_num_samples()))\n",
    "print('Test instances: {}'.format(data_loader_test.get_num_samples()))\n",
    "\n",
    "# Saved weights\n",
    "save_name = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "current_date = datetime.now()\n",
    " \n",
    "# dd/mm/YY H:M:S\n",
    "cd_string = current_date.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "#Tensorboard  config\n",
    "use_tensorboard = False\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs/{learning_rate}_{epochs}_{cd_string}')\n",
    "\n",
    "# Add model to tensorboard\n",
    "dummy_input = data_loader.get_test_input()\n",
    "\n",
    "#writer.add_graph(model.get_model(), Variable(dummy_input['data'].type(torch.FloatTensor)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 2.1806s, gt_cnt:  40.0, et_cnt:   0.1 train_loss: 43.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   10, Time: 28.1840s, gt_cnt: 120.0, et_cnt:  25.0 train_loss: 1626.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   20, Time: 21.2665s, gt_cnt:  47.0, et_cnt: 175.8 train_loss: 2174.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   40, Time: 32.8532s, gt_cnt:  38.0, et_cnt: 199.9 train_loss: 9483.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   50, Time: 16.2973s, gt_cnt:  62.0, et_cnt:  32.3 train_loss: 9961.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   60, Time: 22.5281s, gt_cnt: 560.0, et_cnt: 153.0 train_loss: 13320.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   70, Time: 13.7088s, gt_cnt:  76.0, et_cnt:  23.3 train_loss: 15070.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   90, Time: 27.7778s, gt_cnt:  85.0, et_cnt: 124.7 train_loss: 17578.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  100, Time: 15.5982s, gt_cnt:  61.0, et_cnt:  87.4 train_loss: 18173.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  110, Time: 15.4500s, gt_cnt:  31.0, et_cnt: 351.0 train_loss: 20877.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  120, Time: 10.0393s, gt_cnt: 196.0, et_cnt:  90.3 train_loss: 22668.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  130, Time: 20.1319s, gt_cnt:  42.0, et_cnt:  59.0 train_loss: 23372.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  140, Time: 22.1359s, gt_cnt: 678.0, et_cnt:  51.7 train_loss: 25604.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  150, Time: 20.3584s, gt_cnt: 1622.0, et_cnt: 149.3 train_loss: 28792.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  160, Time: 20.5227s, gt_cnt:  20.0, et_cnt:  64.4 train_loss: 30855.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  170, Time: 16.5148s, gt_cnt: 227.0, et_cnt:  87.9 train_loss: 32418.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  180, Time: 13.7685s, gt_cnt:  95.0, et_cnt:  72.9 train_loss: 35039.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  190, Time: 10.6599s, gt_cnt: 273.0, et_cnt: 231.4 train_loss: 36939.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 11.9966s, gt_cnt:  40.0, et_cnt: 174.5 train_loss: 43.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   10, Time: 30.9070s, gt_cnt: 120.0, et_cnt:  97.9 train_loss: 1628.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   20, Time: 21.8960s, gt_cnt:  47.0, et_cnt: 370.3 train_loss: 2179.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   40, Time: 36.5441s, gt_cnt:  38.0, et_cnt:  95.5 train_loss: 9480.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   50, Time: 19.3601s, gt_cnt:  62.0, et_cnt:  30.4 train_loss: 9953.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   60, Time: 22.2951s, gt_cnt: 560.0, et_cnt: 223.8 train_loss: 13311.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   70, Time: 13.7697s, gt_cnt:  76.0, et_cnt:  29.4 train_loss: 15060.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   90, Time: 32.3586s, gt_cnt:  85.0, et_cnt: 139.5 train_loss: 17568.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  100, Time: 15.8657s, gt_cnt:  61.0, et_cnt: 106.8 train_loss: 18163.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  110, Time: 15.0906s, gt_cnt:  31.0, et_cnt: 407.0 train_loss: 20866.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  120, Time: 9.7028s, gt_cnt: 196.0, et_cnt:  95.6 train_loss: 22657.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  130, Time: 19.7163s, gt_cnt:  42.0, et_cnt:  59.4 train_loss: 23361.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  140, Time: 21.9223s, gt_cnt: 678.0, et_cnt:  57.0 train_loss: 25593.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  150, Time: 19.8792s, gt_cnt: 1622.0, et_cnt: 176.8 train_loss: 28779.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  160, Time: 20.2271s, gt_cnt:  20.0, et_cnt:  74.5 train_loss: 30842.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  170, Time: 15.9638s, gt_cnt: 227.0, et_cnt:  99.1 train_loss: 32405.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  180, Time: 13.3191s, gt_cnt:  95.0, et_cnt: 103.3 train_loss: 35022.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  190, Time: 10.2737s, gt_cnt: 273.0, et_cnt: 257.4 train_loss: 36923.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    0, Time: 11.5439s, gt_cnt:  40.0, et_cnt: 149.8 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   10, Time: 31.0226s, gt_cnt: 120.0, et_cnt:  93.1 train_loss: 1626.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   20, Time: 22.0104s, gt_cnt:  47.0, et_cnt: 347.2 train_loss: 2177.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   40, Time: 35.1572s, gt_cnt:  38.0, et_cnt: 140.6 train_loss: 9479.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   50, Time: 18.8537s, gt_cnt:  62.0, et_cnt:  37.2 train_loss: 9954.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   60, Time: 22.2266s, gt_cnt: 560.0, et_cnt: 237.2 train_loss: 13311.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   70, Time: 13.7420s, gt_cnt:  76.0, et_cnt:  32.7 train_loss: 15060.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   90, Time: 32.3121s, gt_cnt:  85.0, et_cnt: 141.8 train_loss: 17568.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  100, Time: 15.9413s, gt_cnt:  61.0, et_cnt: 106.1 train_loss: 18163.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  110, Time: 15.0573s, gt_cnt:  31.0, et_cnt: 407.4 train_loss: 20865.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  120, Time: 9.6915s, gt_cnt: 196.0, et_cnt:  99.1 train_loss: 22655.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  130, Time: 19.4155s, gt_cnt:  42.0, et_cnt:  56.6 train_loss: 23360.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  140, Time: 21.5447s, gt_cnt: 678.0, et_cnt:  53.2 train_loss: 25592.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  150, Time: 19.9471s, gt_cnt: 1622.0, et_cnt: 175.4 train_loss: 28778.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  160, Time: 20.2435s, gt_cnt:  20.0, et_cnt:  77.8 train_loss: 30840.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  170, Time: 15.5524s, gt_cnt: 227.0, et_cnt:  95.5 train_loss: 32403.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  180, Time: 13.2249s, gt_cnt:  95.0, et_cnt:  88.0 train_loss: 35021.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  190, Time: 10.2306s, gt_cnt: 273.0, et_cnt: 278.2 train_loss: 36921.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    0, Time: 11.3535s, gt_cnt:  40.0, et_cnt: 159.8 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   10, Time: 30.4133s, gt_cnt: 120.0, et_cnt:  94.4 train_loss: 1626.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   20, Time: 21.3481s, gt_cnt:  47.0, et_cnt: 402.5 train_loss: 2178.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   40, Time: 35.2941s, gt_cnt:  38.0, et_cnt: 162.0 train_loss: 9474.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   50, Time: 19.1851s, gt_cnt:  62.0, et_cnt:  34.7 train_loss: 9950.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   60, Time: 22.0618s, gt_cnt: 560.0, et_cnt: 214.4 train_loss: 13307.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   70, Time: 13.4772s, gt_cnt:  76.0, et_cnt:  31.2 train_loss: 15055.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   90, Time: 32.0366s, gt_cnt:  85.0, et_cnt: 137.5 train_loss: 17562.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  100, Time: 16.0079s, gt_cnt:  61.0, et_cnt:  98.4 train_loss: 18156.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  110, Time: 14.6338s, gt_cnt:  31.0, et_cnt: 438.1 train_loss: 20856.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  120, Time: 9.3793s, gt_cnt: 196.0, et_cnt: 101.7 train_loss: 22645.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  130, Time: 19.2224s, gt_cnt:  42.0, et_cnt:  54.3 train_loss: 23351.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  140, Time: 25.8711s, gt_cnt: 678.0, et_cnt:  66.7 train_loss: 30747.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  150, Time: 19.7789s, gt_cnt: 1622.0, et_cnt: 380.1 train_loss: 33924.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  160, Time: 20.1338s, gt_cnt:  20.0, et_cnt:  97.0 train_loss: 35985.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  170, Time: 15.4383s, gt_cnt: 227.0, et_cnt: 126.3 train_loss: 37550.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  180, Time: 13.1428s, gt_cnt:  95.0, et_cnt: 101.1 train_loss: 40160.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  190, Time: 10.1577s, gt_cnt: 273.0, et_cnt: 275.9 train_loss: 42061.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    0, Time: 11.2876s, gt_cnt:  40.0, et_cnt: 163.2 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   10, Time: 30.2429s, gt_cnt: 120.0, et_cnt:  74.9 train_loss: 1626.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   20, Time: 21.3177s, gt_cnt:  47.0, et_cnt: 270.5 train_loss: 2175.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   40, Time: 35.2386s, gt_cnt:  38.0, et_cnt: 249.5 train_loss: 9472.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   50, Time: 19.1927s, gt_cnt:  62.0, et_cnt:  42.2 train_loss: 9952.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   60, Time: 21.9092s, gt_cnt: 560.0, et_cnt: 246.5 train_loss: 13304.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   70, Time: 13.3766s, gt_cnt:  76.0, et_cnt:  41.5 train_loss: 15051.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   90, Time: 31.8986s, gt_cnt:  85.0, et_cnt: 129.5 train_loss: 17555.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  100, Time: 15.9920s, gt_cnt:  61.0, et_cnt:  95.5 train_loss: 18148.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    4, step  110, Time: 14.9593s, gt_cnt:  31.0, et_cnt: 451.2 train_loss: 20843.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  120, Time: 9.5388s, gt_cnt: 196.0, et_cnt: 104.0 train_loss: 22628.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  130, Time: 19.3561s, gt_cnt:  42.0, et_cnt:  49.7 train_loss: 23339.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  140, Time: 25.8738s, gt_cnt: 678.0, et_cnt:  60.4 train_loss: 30726.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  150, Time: 19.7234s, gt_cnt: 1622.0, et_cnt: 566.2 train_loss: 33889.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  160, Time: 20.3668s, gt_cnt:  20.0, et_cnt: 101.1 train_loss: 35952.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  170, Time: 15.5530s, gt_cnt: 227.0, et_cnt: 140.5 train_loss: 37518.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  180, Time: 13.0742s, gt_cnt:  95.0, et_cnt: 107.0 train_loss: 40123.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step  190, Time: 10.1409s, gt_cnt: 273.0, et_cnt: 238.3 train_loss: 42021.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    0, Time: 11.3796s, gt_cnt:  40.0, et_cnt: 182.7 train_loss: 43.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   10, Time: 30.3483s, gt_cnt: 120.0, et_cnt:  63.2 train_loss: 1627.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   20, Time: 21.5805s, gt_cnt:  47.0, et_cnt: 193.3 train_loss: 2176.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   40, Time: 35.5809s, gt_cnt:  38.0, et_cnt: 279.5 train_loss: 9470.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   50, Time: 19.1333s, gt_cnt:  62.0, et_cnt:  49.6 train_loss: 9949.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   60, Time: 21.9910s, gt_cnt: 560.0, et_cnt: 274.9 train_loss: 13295.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   70, Time: 13.5657s, gt_cnt:  76.0, et_cnt:  50.7 train_loss: 15041.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   90, Time: 32.5955s, gt_cnt:  85.0, et_cnt: 120.2 train_loss: 17543.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  100, Time: 16.0311s, gt_cnt:  61.0, et_cnt:  79.1 train_loss: 18136.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  110, Time: 14.8559s, gt_cnt:  31.0, et_cnt: 346.8 train_loss: 20826.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  120, Time: 9.5834s, gt_cnt: 196.0, et_cnt: 131.9 train_loss: 22608.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  130, Time: 19.6742s, gt_cnt:  42.0, et_cnt:  56.8 train_loss: 23329.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  140, Time: 26.0648s, gt_cnt: 678.0, et_cnt:  53.2 train_loss: 30710.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  150, Time: 19.9533s, gt_cnt: 1622.0, et_cnt: 541.9 train_loss: 33870.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  160, Time: 20.3201s, gt_cnt:  20.0, et_cnt: 102.9 train_loss: 35930.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  170, Time: 15.5656s, gt_cnt: 227.0, et_cnt: 175.1 train_loss: 37497.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  180, Time: 13.0739s, gt_cnt:  95.0, et_cnt: 130.2 train_loss: 40095.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step  190, Time: 10.2039s, gt_cnt: 273.0, et_cnt: 215.1 train_loss: 41993.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    0, Time: 11.4343s, gt_cnt:  40.0, et_cnt: 207.3 train_loss: 44.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   10, Time: 30.5828s, gt_cnt: 120.0, et_cnt:  64.3 train_loss: 1630.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   20, Time: 21.7687s, gt_cnt:  47.0, et_cnt: 168.1 train_loss: 2178.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   40, Time: 35.6984s, gt_cnt:  38.0, et_cnt: 235.1 train_loss: 9471.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   50, Time: 19.4520s, gt_cnt:  62.0, et_cnt:  56.6 train_loss: 9946.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   60, Time: 22.1457s, gt_cnt: 560.0, et_cnt: 363.2 train_loss: 13288.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   70, Time: 13.6934s, gt_cnt:  76.0, et_cnt:  57.4 train_loss: 15034.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   90, Time: 32.6241s, gt_cnt:  85.0, et_cnt: 113.4 train_loss: 17535.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  100, Time: 16.4843s, gt_cnt:  61.0, et_cnt:  71.0 train_loss: 18128.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  110, Time: 14.9142s, gt_cnt:  31.0, et_cnt: 291.4 train_loss: 20816.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  120, Time: 9.6011s, gt_cnt: 196.0, et_cnt: 116.3 train_loss: 22598.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  130, Time: 19.6134s, gt_cnt:  42.0, et_cnt:  65.0 train_loss: 23318.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  140, Time: 26.2582s, gt_cnt: 678.0, et_cnt:  67.4 train_loss: 30686.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  150, Time: 19.8967s, gt_cnt: 1622.0, et_cnt: 668.8 train_loss: 33839.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  160, Time: 20.2050s, gt_cnt:  20.0, et_cnt:  94.5 train_loss: 35897.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  170, Time: 15.7074s, gt_cnt: 227.0, et_cnt: 193.2 train_loss: 37466.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  180, Time: 13.1490s, gt_cnt:  95.0, et_cnt: 140.9 train_loss: 40059.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step  190, Time: 10.1784s, gt_cnt: 273.0, et_cnt: 197.0 train_loss: 41956.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    0, Time: 11.4228s, gt_cnt:  40.0, et_cnt: 203.6 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   10, Time: 30.4473s, gt_cnt: 120.0, et_cnt:  53.5 train_loss: 1631.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   20, Time: 21.7866s, gt_cnt:  47.0, et_cnt: 132.2 train_loss: 2179.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   40, Time: 36.0860s, gt_cnt:  38.0, et_cnt: 239.7 train_loss: 9469.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   50, Time: 19.4119s, gt_cnt:  62.0, et_cnt:  56.0 train_loss: 9944.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   60, Time: 22.1274s, gt_cnt: 560.0, et_cnt: 353.8 train_loss: 13284.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   70, Time: 13.6754s, gt_cnt:  76.0, et_cnt:  57.1 train_loss: 15030.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   90, Time: 32.4669s, gt_cnt:  85.0, et_cnt: 112.3 train_loss: 17529.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  100, Time: 16.3051s, gt_cnt:  61.0, et_cnt:  70.1 train_loss: 18123.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  110, Time: 14.9223s, gt_cnt:  31.0, et_cnt: 280.0 train_loss: 20808.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  120, Time: 9.6023s, gt_cnt: 196.0, et_cnt: 113.7 train_loss: 22589.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  130, Time: 19.6686s, gt_cnt:  42.0, et_cnt:  68.5 train_loss: 23310.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  140, Time: 26.1048s, gt_cnt: 678.0, et_cnt:  74.3 train_loss: 30670.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  150, Time: 19.8421s, gt_cnt: 1622.0, et_cnt: 764.4 train_loss: 33817.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  160, Time: 20.1974s, gt_cnt:  20.0, et_cnt:  91.6 train_loss: 35875.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  170, Time: 15.7167s, gt_cnt: 227.0, et_cnt: 195.8 train_loss: 37445.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  180, Time: 13.2101s, gt_cnt:  95.0, et_cnt: 141.8 train_loss: 40035.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step  190, Time: 10.2024s, gt_cnt: 273.0, et_cnt: 186.1 train_loss: 41931.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    0, Time: 11.4129s, gt_cnt:  40.0, et_cnt: 213.2 train_loss: 44.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   10, Time: 30.4587s, gt_cnt: 120.0, et_cnt:  54.1 train_loss: 1632.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   20, Time: 21.7219s, gt_cnt:  47.0, et_cnt: 125.3 train_loss: 2180.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   40, Time: 35.8355s, gt_cnt:  38.0, et_cnt: 248.4 train_loss: 9466.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   50, Time: 19.3683s, gt_cnt:  62.0, et_cnt:  57.3 train_loss: 9942.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   60, Time: 22.0987s, gt_cnt: 560.0, et_cnt: 370.1 train_loss: 13278.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   70, Time: 13.6450s, gt_cnt:  76.0, et_cnt:  56.1 train_loss: 15024.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   90, Time: 32.3490s, gt_cnt:  85.0, et_cnt: 106.4 train_loss: 17522.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  100, Time: 16.6684s, gt_cnt:  61.0, et_cnt:  64.9 train_loss: 18115.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  110, Time: 14.9187s, gt_cnt:  31.0, et_cnt: 253.9 train_loss: 20798.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  120, Time: 9.5938s, gt_cnt: 196.0, et_cnt: 109.8 train_loss: 22578.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  130, Time: 19.9732s, gt_cnt:  42.0, et_cnt:  68.5 train_loss: 23299.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  140, Time: 26.1396s, gt_cnt: 678.0, et_cnt:  79.5 train_loss: 30655.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  150, Time: 20.0803s, gt_cnt: 1622.0, et_cnt: 824.8 train_loss: 33800.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  160, Time: 20.2246s, gt_cnt:  20.0, et_cnt:  88.3 train_loss: 35857.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  170, Time: 15.6184s, gt_cnt: 227.0, et_cnt: 188.8 train_loss: 37425.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  180, Time: 13.1544s, gt_cnt:  95.0, et_cnt: 142.3 train_loss: 40014.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step  190, Time: 10.1808s, gt_cnt: 273.0, et_cnt: 182.7 train_loss: 41909.7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    9, step    0, Time: 11.4119s, gt_cnt:  40.0, et_cnt: 215.8 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   10, Time: 30.6202s, gt_cnt: 120.0, et_cnt:  52.6 train_loss: 1632.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   20, Time: 21.7119s, gt_cnt:  47.0, et_cnt: 116.3 train_loss: 2180.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   40, Time: 35.9369s, gt_cnt:  38.0, et_cnt: 247.1 train_loss: 9463.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   50, Time: 19.4082s, gt_cnt:  62.0, et_cnt:  56.5 train_loss: 9938.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   60, Time: 22.1416s, gt_cnt: 560.0, et_cnt: 366.2 train_loss: 13272.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   70, Time: 13.6113s, gt_cnt:  76.0, et_cnt:  54.8 train_loss: 15018.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   90, Time: 32.4897s, gt_cnt:  85.0, et_cnt: 101.2 train_loss: 17515.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  100, Time: 16.4997s, gt_cnt:  61.0, et_cnt:  60.4 train_loss: 18107.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  110, Time: 14.9391s, gt_cnt:  31.0, et_cnt: 235.4 train_loss: 20788.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  120, Time: 9.5995s, gt_cnt: 196.0, et_cnt: 111.3 train_loss: 22567.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  130, Time: 19.9086s, gt_cnt:  42.0, et_cnt:  66.3 train_loss: 23289.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  140, Time: 26.1791s, gt_cnt: 678.0, et_cnt:  78.3 train_loss: 30646.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  150, Time: 20.0297s, gt_cnt: 1622.0, et_cnt: 866.6 train_loss: 33789.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  160, Time: 20.1759s, gt_cnt:  20.0, et_cnt:  86.8 train_loss: 35845.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  170, Time: 15.7292s, gt_cnt: 227.0, et_cnt: 195.0 train_loss: 37414.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  180, Time: 13.1523s, gt_cnt:  95.0, et_cnt: 146.5 train_loss: 40000.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step  190, Time: 10.1964s, gt_cnt: 273.0, et_cnt: 183.0 train_loss: 41894.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step    0, Time: 11.4079s, gt_cnt:  40.0, et_cnt: 222.2 train_loss: 44.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   10, Time: 30.4049s, gt_cnt: 120.0, et_cnt:  54.9 train_loss: 1633.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   20, Time: 21.6410s, gt_cnt:  47.0, et_cnt: 125.5 train_loss: 2181.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   40, Time: 35.9373s, gt_cnt:  38.0, et_cnt: 244.2 train_loss: 9459.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   50, Time: 19.1125s, gt_cnt:  62.0, et_cnt:  55.5 train_loss: 9934.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   60, Time: 22.1242s, gt_cnt: 560.0, et_cnt: 367.0 train_loss: 13265.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   70, Time: 13.6663s, gt_cnt:  76.0, et_cnt:  53.5 train_loss: 15011.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step   90, Time: 32.3164s, gt_cnt:  85.0, et_cnt:  97.5 train_loss: 17507.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  100, Time: 16.3088s, gt_cnt:  61.0, et_cnt:  58.3 train_loss: 18099.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  110, Time: 14.9370s, gt_cnt:  31.0, et_cnt: 219.3 train_loss: 20778.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  120, Time: 9.5999s, gt_cnt: 196.0, et_cnt: 106.2 train_loss: 22556.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  130, Time: 19.8659s, gt_cnt:  42.0, et_cnt:  69.5 train_loss: 23278.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  140, Time: 26.2472s, gt_cnt: 678.0, et_cnt:  86.2 train_loss: 30627.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  150, Time: 20.0981s, gt_cnt: 1622.0, et_cnt: 914.0 train_loss: 33768.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  160, Time: 20.2173s, gt_cnt:  20.0, et_cnt:  80.6 train_loss: 35823.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  170, Time: 15.7380s, gt_cnt: 227.0, et_cnt: 190.2 train_loss: 37391.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  180, Time: 13.2083s, gt_cnt:  95.0, et_cnt: 148.0 train_loss: 39974.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   10, step  190, Time: 10.2073s, gt_cnt: 273.0, et_cnt: 178.4 train_loss: 41868.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step    0, Time: 11.4371s, gt_cnt:  40.0, et_cnt: 218.8 train_loss: 44.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   10, Time: 30.6100s, gt_cnt: 120.0, et_cnt:  48.6 train_loss: 1632.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   20, Time: 21.5646s, gt_cnt:  47.0, et_cnt: 112.9 train_loss: 2180.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   40, Time: 35.9939s, gt_cnt:  38.0, et_cnt: 240.9 train_loss: 9456.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   50, Time: 19.3573s, gt_cnt:  62.0, et_cnt:  54.9 train_loss: 9932.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   60, Time: 22.1005s, gt_cnt: 560.0, et_cnt: 360.5 train_loss: 13260.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   70, Time: 13.6452s, gt_cnt:  76.0, et_cnt:  51.2 train_loss: 15005.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step   90, Time: 32.7105s, gt_cnt:  85.0, et_cnt:  91.7 train_loss: 17500.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  100, Time: 16.5447s, gt_cnt:  61.0, et_cnt:  55.1 train_loss: 18092.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  110, Time: 14.9003s, gt_cnt:  31.0, et_cnt: 208.9 train_loss: 20768.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  120, Time: 9.6195s, gt_cnt: 196.0, et_cnt: 113.0 train_loss: 22545.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  130, Time: 19.8986s, gt_cnt:  42.0, et_cnt:  64.4 train_loss: 23269.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  140, Time: 26.3599s, gt_cnt: 678.0, et_cnt:  80.3 train_loss: 30622.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  150, Time: 20.2197s, gt_cnt: 1622.0, et_cnt: 917.8 train_loss: 33761.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  160, Time: 20.4517s, gt_cnt:  20.0, et_cnt:  82.2 train_loss: 35816.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  170, Time: 15.9182s, gt_cnt: 227.0, et_cnt: 188.4 train_loss: 37385.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  180, Time: 13.2060s, gt_cnt:  95.0, et_cnt: 146.9 train_loss: 39966.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   11, step  190, Time: 10.1492s, gt_cnt: 273.0, et_cnt: 182.1 train_loss: 41860.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step    0, Time: 11.4005s, gt_cnt:  40.0, et_cnt: 227.9 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   10, Time: 30.6316s, gt_cnt: 120.0, et_cnt:  53.2 train_loss: 1633.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   20, Time: 21.6282s, gt_cnt:  47.0, et_cnt: 122.2 train_loss: 2181.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   40, Time: 36.2095s, gt_cnt:  38.0, et_cnt: 234.9 train_loss: 9452.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   50, Time: 19.6861s, gt_cnt:  62.0, et_cnt:  53.5 train_loss: 9927.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   60, Time: 22.1141s, gt_cnt: 560.0, et_cnt: 362.1 train_loss: 13253.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   70, Time: 13.6193s, gt_cnt:  76.0, et_cnt:  49.9 train_loss: 14998.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step   90, Time: 32.6854s, gt_cnt:  85.0, et_cnt:  89.3 train_loss: 17492.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  100, Time: 16.8147s, gt_cnt:  61.0, et_cnt:  53.8 train_loss: 18085.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  110, Time: 14.9257s, gt_cnt:  31.0, et_cnt: 194.2 train_loss: 20758.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  120, Time: 9.6342s, gt_cnt: 196.0, et_cnt: 109.2 train_loss: 22533.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  130, Time: 19.6491s, gt_cnt:  42.0, et_cnt:  67.5 train_loss: 23258.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  140, Time: 26.2294s, gt_cnt: 678.0, et_cnt:  87.5 train_loss: 30605.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  150, Time: 20.2602s, gt_cnt: 1622.0, et_cnt: 983.7 train_loss: 33742.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  160, Time: 20.2429s, gt_cnt:  20.0, et_cnt:  75.8 train_loss: 35796.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  170, Time: 15.8101s, gt_cnt: 227.0, et_cnt: 189.5 train_loss: 37363.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  180, Time: 13.2141s, gt_cnt:  95.0, et_cnt: 149.2 train_loss: 39942.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   12, step  190, Time: 10.1904s, gt_cnt: 273.0, et_cnt: 180.1 train_loss: 41835.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step    0, Time: 11.4204s, gt_cnt:  40.0, et_cnt: 228.3 train_loss: 45.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   10, Time: 30.6122s, gt_cnt: 120.0, et_cnt:  48.7 train_loss: 1632.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   20, Time: 21.6197s, gt_cnt:  47.0, et_cnt: 113.8 train_loss: 2180.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   40, Time: 35.9391s, gt_cnt:  38.0, et_cnt: 227.5 train_loss: 9450.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   50, Time: 19.3895s, gt_cnt:  62.0, et_cnt:  52.4 train_loss: 9926.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   60, Time: 22.1052s, gt_cnt: 560.0, et_cnt: 360.8 train_loss: 13249.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   70, Time: 13.7064s, gt_cnt:  76.0, et_cnt:  48.0 train_loss: 14994.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step   90, Time: 32.7901s, gt_cnt:  85.0, et_cnt:  85.4 train_loss: 17487.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  100, Time: 16.5808s, gt_cnt:  61.0, et_cnt:  51.7 train_loss: 18079.4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   13, step  110, Time: 14.8932s, gt_cnt:  31.0, et_cnt: 182.3 train_loss: 20749.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  120, Time: 9.5983s, gt_cnt: 196.0, et_cnt: 107.9 train_loss: 22524.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  130, Time: 19.8146s, gt_cnt:  42.0, et_cnt:  68.2 train_loss: 23249.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  140, Time: 26.2805s, gt_cnt: 678.0, et_cnt:  92.0 train_loss: 30592.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  150, Time: 19.9786s, gt_cnt: 1622.0, et_cnt: 1047.2 train_loss: 33727.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  160, Time: 20.2382s, gt_cnt:  20.0, et_cnt:  72.3 train_loss: 35780.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  170, Time: 15.7386s, gt_cnt: 227.0, et_cnt: 186.9 train_loss: 37347.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  180, Time: 13.2941s, gt_cnt:  95.0, et_cnt: 148.2 train_loss: 39924.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   13, step  190, Time: 10.2021s, gt_cnt: 273.0, et_cnt: 179.7 train_loss: 41816.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step    0, Time: 11.4009s, gt_cnt:  40.0, et_cnt: 230.6 train_loss: 45.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   10, Time: 30.5138s, gt_cnt: 120.0, et_cnt:  47.5 train_loss: 1633.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   20, Time: 21.6672s, gt_cnt:  47.0, et_cnt: 111.6 train_loss: 2180.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   40, Time: 36.2113s, gt_cnt:  38.0, et_cnt: 220.2 train_loss: 9448.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   50, Time: 19.2765s, gt_cnt:  62.0, et_cnt:  51.1 train_loss: 9923.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   60, Time: 22.1475s, gt_cnt: 560.0, et_cnt: 359.2 train_loss: 13244.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   70, Time: 13.6201s, gt_cnt:  76.0, et_cnt:  46.2 train_loss: 14989.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step   90, Time: 32.6659s, gt_cnt:  85.0, et_cnt:  82.1 train_loss: 17481.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  100, Time: 16.5418s, gt_cnt:  61.0, et_cnt:  50.0 train_loss: 18073.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  110, Time: 14.9175s, gt_cnt:  31.0, et_cnt: 174.1 train_loss: 20741.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  120, Time: 9.6111s, gt_cnt: 196.0, et_cnt: 107.6 train_loss: 22515.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  130, Time: 20.0619s, gt_cnt:  42.0, et_cnt:  70.3 train_loss: 23239.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  140, Time: 26.1229s, gt_cnt: 678.0, et_cnt:  96.9 train_loss: 30579.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  150, Time: 19.9990s, gt_cnt: 1622.0, et_cnt: 1101.3 train_loss: 33712.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  160, Time: 20.2304s, gt_cnt:  20.0, et_cnt:  67.7 train_loss: 35764.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  170, Time: 15.7001s, gt_cnt: 227.0, et_cnt: 185.3 train_loss: 37331.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  180, Time: 13.2611s, gt_cnt:  95.0, et_cnt: 148.6 train_loss: 39904.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   14, step  190, Time: 10.2185s, gt_cnt: 273.0, et_cnt: 180.4 train_loss: 41796.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step    0, Time: 11.4464s, gt_cnt:  40.0, et_cnt: 231.9 train_loss: 45.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   10, Time: 30.5074s, gt_cnt: 120.0, et_cnt:  44.0 train_loss: 1632.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   20, Time: 21.6147s, gt_cnt:  47.0, et_cnt: 106.9 train_loss: 2180.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   40, Time: 36.1431s, gt_cnt:  38.0, et_cnt: 215.0 train_loss: 9446.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   50, Time: 19.5547s, gt_cnt:  62.0, et_cnt:  50.7 train_loss: 9921.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   60, Time: 22.0874s, gt_cnt: 560.0, et_cnt: 358.8 train_loss: 13241.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   70, Time: 13.5624s, gt_cnt:  76.0, et_cnt:  44.6 train_loss: 14985.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step   90, Time: 32.9683s, gt_cnt:  85.0, et_cnt:  80.5 train_loss: 17476.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  100, Time: 16.5523s, gt_cnt:  61.0, et_cnt:  49.2 train_loss: 18068.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  110, Time: 14.8722s, gt_cnt:  31.0, et_cnt: 162.1 train_loss: 20734.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  120, Time: 9.6021s, gt_cnt: 196.0, et_cnt: 103.0 train_loss: 22507.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  130, Time: 20.0354s, gt_cnt:  42.0, et_cnt:  71.3 train_loss: 23231.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  140, Time: 26.2172s, gt_cnt: 678.0, et_cnt: 103.9 train_loss: 30565.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  150, Time: 20.2119s, gt_cnt: 1622.0, et_cnt: 1190.3 train_loss: 33696.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  160, Time: 20.2254s, gt_cnt:  20.0, et_cnt:  62.2 train_loss: 35746.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  170, Time: 15.8104s, gt_cnt: 227.0, et_cnt: 185.4 train_loss: 37312.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  180, Time: 13.0721s, gt_cnt:  95.0, et_cnt: 149.4 train_loss: 39884.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   15, step  190, Time: 9.9594s, gt_cnt: 273.0, et_cnt: 180.2 train_loss: 41775.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step    0, Time: 11.1584s, gt_cnt:  40.0, et_cnt: 230.9 train_loss: 45.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   10, Time: 29.8521s, gt_cnt: 120.0, et_cnt:  44.9 train_loss: 1633.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   20, Time: 21.3633s, gt_cnt:  47.0, et_cnt: 102.1 train_loss: 2180.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   40, Time: 35.9386s, gt_cnt:  38.0, et_cnt: 209.7 train_loss: 9444.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   50, Time: 19.3398s, gt_cnt:  62.0, et_cnt:  49.1 train_loss: 9919.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   60, Time: 21.7660s, gt_cnt: 560.0, et_cnt: 351.6 train_loss: 13236.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   70, Time: 13.4179s, gt_cnt:  76.0, et_cnt:  42.7 train_loss: 14980.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step   90, Time: 32.7341s, gt_cnt:  85.0, et_cnt:  76.7 train_loss: 17470.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  100, Time: 16.6123s, gt_cnt:  61.0, et_cnt:  46.8 train_loss: 18062.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  110, Time: 14.7602s, gt_cnt:  31.0, et_cnt: 156.4 train_loss: 20726.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  120, Time: 9.4984s, gt_cnt: 196.0, et_cnt: 103.6 train_loss: 22498.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  130, Time: 19.6129s, gt_cnt:  42.0, et_cnt:  73.0 train_loss: 23222.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  140, Time: 25.8215s, gt_cnt: 678.0, et_cnt: 107.2 train_loss: 30553.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  150, Time: 19.7927s, gt_cnt: 1622.0, et_cnt: 1236.9 train_loss: 33683.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  160, Time: 20.0955s, gt_cnt:  20.0, et_cnt:  58.0 train_loss: 35732.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  170, Time: 15.5905s, gt_cnt: 227.0, et_cnt: 181.7 train_loss: 37298.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  180, Time: 13.2402s, gt_cnt:  95.0, et_cnt: 149.0 train_loss: 39867.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   16, step  190, Time: 10.1177s, gt_cnt: 273.0, et_cnt: 180.3 train_loss: 41758.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step    0, Time: 11.3709s, gt_cnt:  40.0, et_cnt: 235.7 train_loss: 45.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   10, Time: 30.3181s, gt_cnt: 120.0, et_cnt:  42.6 train_loss: 1633.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   20, Time: 21.4934s, gt_cnt:  47.0, et_cnt:  99.2 train_loss: 2180.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   40, Time: 35.8713s, gt_cnt:  38.0, et_cnt: 204.1 train_loss: 9442.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   50, Time: 19.6971s, gt_cnt:  62.0, et_cnt:  48.6 train_loss: 9917.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   60, Time: 22.0580s, gt_cnt: 560.0, et_cnt: 347.0 train_loss: 13232.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   70, Time: 13.5221s, gt_cnt:  76.0, et_cnt:  39.1 train_loss: 14976.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step   90, Time: 32.2843s, gt_cnt:  85.0, et_cnt:  77.0 train_loss: 17466.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  100, Time: 16.6872s, gt_cnt:  61.0, et_cnt:  48.1 train_loss: 18058.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  110, Time: 15.0248s, gt_cnt:  31.0, et_cnt: 160.6 train_loss: 20718.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  120, Time: 9.5882s, gt_cnt: 196.0, et_cnt: 102.6 train_loss: 22490.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  130, Time: 19.5406s, gt_cnt:  42.0, et_cnt:  79.7 train_loss: 23214.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  140, Time: 25.8944s, gt_cnt: 678.0, et_cnt: 115.2 train_loss: 30537.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  150, Time: 19.7708s, gt_cnt: 1622.0, et_cnt: 1297.5 train_loss: 33665.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  160, Time: 20.3240s, gt_cnt:  20.0, et_cnt:  51.8 train_loss: 35713.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  170, Time: 15.6253s, gt_cnt: 227.0, et_cnt: 176.9 train_loss: 37278.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  180, Time: 13.2433s, gt_cnt:  95.0, et_cnt: 148.5 train_loss: 39844.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   17, step  190, Time: 10.2072s, gt_cnt: 273.0, et_cnt: 182.1 train_loss: 41734.3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   18, step    0, Time: 11.3767s, gt_cnt:  40.0, et_cnt: 232.6 train_loss: 45.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   10, Time: 30.2921s, gt_cnt: 120.0, et_cnt:  37.9 train_loss: 1632.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   20, Time: 21.4629s, gt_cnt:  47.0, et_cnt:  94.9 train_loss: 2180.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   40, Time: 35.9828s, gt_cnt:  38.0, et_cnt: 206.2 train_loss: 9439.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   50, Time: 19.4215s, gt_cnt:  62.0, et_cnt:  50.2 train_loss: 9915.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   60, Time: 22.1020s, gt_cnt: 560.0, et_cnt: 341.8 train_loss: 13230.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   70, Time: 13.6087s, gt_cnt:  76.0, et_cnt:  38.6 train_loss: 14973.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step   90, Time: 32.6410s, gt_cnt:  85.0, et_cnt:  74.4 train_loss: 17461.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  100, Time: 17.1723s, gt_cnt:  61.0, et_cnt:  46.0 train_loss: 18053.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  110, Time: 15.0095s, gt_cnt:  31.0, et_cnt: 145.5 train_loss: 20712.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  120, Time: 9.5916s, gt_cnt: 196.0, et_cnt:  98.7 train_loss: 22482.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  130, Time: 19.7550s, gt_cnt:  42.0, et_cnt:  79.4 train_loss: 23206.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  140, Time: 25.6858s, gt_cnt: 678.0, et_cnt: 120.7 train_loss: 30524.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  150, Time: 19.7664s, gt_cnt: 1622.0, et_cnt: 1373.3 train_loss: 33652.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  160, Time: 20.2328s, gt_cnt:  20.0, et_cnt:  48.0 train_loss: 35699.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  170, Time: 15.7538s, gt_cnt: 227.0, et_cnt: 175.8 train_loss: 37262.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  180, Time: 13.1019s, gt_cnt:  95.0, et_cnt: 147.7 train_loss: 39827.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   18, step  190, Time: 10.0772s, gt_cnt: 273.0, et_cnt: 183.5 train_loss: 41717.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step    0, Time: 11.2711s, gt_cnt:  40.0, et_cnt: 232.3 train_loss: 45.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   10, Time: 29.9887s, gt_cnt: 120.0, et_cnt:  41.2 train_loss: 1632.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   20, Time: 21.2829s, gt_cnt:  47.0, et_cnt:  90.8 train_loss: 2180.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   40, Time: 35.6572s, gt_cnt:  38.0, et_cnt: 201.8 train_loss: 9436.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   50, Time: 19.3228s, gt_cnt:  62.0, et_cnt:  47.4 train_loss: 9912.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   60, Time: 22.2487s, gt_cnt: 560.0, et_cnt: 334.4 train_loss: 13224.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   70, Time: 13.5888s, gt_cnt:  76.0, et_cnt:  35.3 train_loss: 14967.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step   90, Time: 32.5952s, gt_cnt:  85.0, et_cnt:  77.6 train_loss: 17456.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  100, Time: 16.6570s, gt_cnt:  61.0, et_cnt:  47.4 train_loss: 18048.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  110, Time: 14.9520s, gt_cnt:  31.0, et_cnt: 152.5 train_loss: 20703.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  120, Time: 9.5461s, gt_cnt: 196.0, et_cnt: 100.3 train_loss: 22473.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  130, Time: 19.7205s, gt_cnt:  42.0, et_cnt:  84.3 train_loss: 23198.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  140, Time: 25.5824s, gt_cnt: 678.0, et_cnt: 128.5 train_loss: 30510.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  150, Time: 19.6389s, gt_cnt: 1622.0, et_cnt: 1435.5 train_loss: 33637.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  160, Time: 20.2141s, gt_cnt:  20.0, et_cnt:  44.0 train_loss: 35683.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  170, Time: 15.7818s, gt_cnt: 227.0, et_cnt: 170.5 train_loss: 37246.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  180, Time: 13.1919s, gt_cnt:  95.0, et_cnt: 146.9 train_loss: 39808.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   19, step  190, Time: 10.0551s, gt_cnt: 273.0, et_cnt: 184.8 train_loss: 41697.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step    0, Time: 11.2566s, gt_cnt:  40.0, et_cnt: 239.0 train_loss: 45.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   10, Time: 29.9405s, gt_cnt: 120.0, et_cnt:  39.2 train_loss: 1632.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   20, Time: 21.3516s, gt_cnt:  47.0, et_cnt:  92.1 train_loss: 2180.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   40, Time: 35.6092s, gt_cnt:  38.0, et_cnt: 199.2 train_loss: 9434.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   50, Time: 19.7461s, gt_cnt:  62.0, et_cnt:  49.1 train_loss: 9910.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   60, Time: 22.1787s, gt_cnt: 560.0, et_cnt: 325.3 train_loss: 13221.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   70, Time: 13.5677s, gt_cnt:  76.0, et_cnt:  33.9 train_loss: 14964.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step   90, Time: 32.5910s, gt_cnt:  85.0, et_cnt:  76.9 train_loss: 17451.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  100, Time: 16.8371s, gt_cnt:  61.0, et_cnt:  48.1 train_loss: 18042.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  110, Time: 14.8549s, gt_cnt:  31.0, et_cnt: 149.8 train_loss: 20696.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  120, Time: 9.6060s, gt_cnt: 196.0, et_cnt:  97.7 train_loss: 22465.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  130, Time: 19.8895s, gt_cnt:  42.0, et_cnt:  87.2 train_loss: 23189.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  140, Time: 26.1148s, gt_cnt: 678.0, et_cnt: 133.2 train_loss: 30495.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  150, Time: 20.1065s, gt_cnt: 1622.0, et_cnt: 1479.9 train_loss: 33622.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  160, Time: 20.2566s, gt_cnt:  20.0, et_cnt:  40.9 train_loss: 35666.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  170, Time: 15.8090s, gt_cnt: 227.0, et_cnt: 168.1 train_loss: 37228.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  180, Time: 13.2030s, gt_cnt:  95.0, et_cnt: 145.8 train_loss: 39789.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   20, step  190, Time: 10.0876s, gt_cnt: 273.0, et_cnt: 186.9 train_loss: 41678.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step    0, Time: 11.3132s, gt_cnt:  40.0, et_cnt: 235.3 train_loss: 45.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   10, Time: 30.2749s, gt_cnt: 120.0, et_cnt:  40.9 train_loss: 1632.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   20, Time: 21.4503s, gt_cnt:  47.0, et_cnt:  88.5 train_loss: 2179.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   40, Time: 35.7450s, gt_cnt:  38.0, et_cnt: 198.6 train_loss: 9429.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   50, Time: 19.6357s, gt_cnt:  62.0, et_cnt:  48.1 train_loss: 9906.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   60, Time: 21.9396s, gt_cnt: 560.0, et_cnt: 323.5 train_loss: 13215.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   70, Time: 13.5537s, gt_cnt:  76.0, et_cnt:  35.2 train_loss: 14957.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step   90, Time: 32.6053s, gt_cnt:  85.0, et_cnt:  77.5 train_loss: 17444.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  100, Time: 16.5464s, gt_cnt:  61.0, et_cnt:  47.0 train_loss: 18035.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  110, Time: 14.8486s, gt_cnt:  31.0, et_cnt: 134.6 train_loss: 20688.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  120, Time: 9.5246s, gt_cnt: 196.0, et_cnt:  94.6 train_loss: 22457.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  130, Time: 19.7536s, gt_cnt:  42.0, et_cnt:  87.7 train_loss: 23179.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  140, Time: 25.9765s, gt_cnt: 678.0, et_cnt: 139.1 train_loss: 30479.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  150, Time: 20.1179s, gt_cnt: 1622.0, et_cnt: 1511.7 train_loss: 33606.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  160, Time: 20.3246s, gt_cnt:  20.0, et_cnt:  38.3 train_loss: 35650.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  170, Time: 15.8386s, gt_cnt: 227.0, et_cnt: 162.1 train_loss: 37210.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  180, Time: 13.1522s, gt_cnt:  95.0, et_cnt: 140.5 train_loss: 39771.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   21, step  190, Time: 9.9649s, gt_cnt: 273.0, et_cnt: 189.4 train_loss: 41660.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step    0, Time: 11.1034s, gt_cnt:  40.0, et_cnt: 232.0 train_loss: 45.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   10, Time: 29.7273s, gt_cnt: 120.0, et_cnt:  42.9 train_loss: 1631.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   20, Time: 21.4467s, gt_cnt:  47.0, et_cnt:  81.7 train_loss: 2179.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   40, Time: 35.9421s, gt_cnt:  38.0, et_cnt: 195.1 train_loss: 9428.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   50, Time: 19.2074s, gt_cnt:  62.0, et_cnt:  45.4 train_loss: 9903.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   60, Time: 22.1024s, gt_cnt: 560.0, et_cnt: 293.6 train_loss: 13212.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   70, Time: 13.6483s, gt_cnt:  76.0, et_cnt:  38.6 train_loss: 14955.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step   90, Time: 32.6793s, gt_cnt:  85.0, et_cnt:  61.0 train_loss: 17440.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  100, Time: 16.6692s, gt_cnt:  61.0, et_cnt:  38.4 train_loss: 18031.4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   22, step  110, Time: 14.8675s, gt_cnt:  31.0, et_cnt: 109.1 train_loss: 20683.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  120, Time: 9.6209s, gt_cnt: 196.0, et_cnt: 102.7 train_loss: 22451.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  130, Time: 19.9845s, gt_cnt:  42.0, et_cnt:  77.9 train_loss: 23175.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  140, Time: 26.1176s, gt_cnt: 678.0, et_cnt: 129.3 train_loss: 30482.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  150, Time: 20.0656s, gt_cnt: 1622.0, et_cnt: 1632.3 train_loss: 33612.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  160, Time: 20.2306s, gt_cnt:  20.0, et_cnt:  36.7 train_loss: 35656.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  170, Time: 15.7188s, gt_cnt: 227.0, et_cnt: 133.8 train_loss: 37217.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  180, Time: 13.2748s, gt_cnt:  95.0, et_cnt: 132.8 train_loss: 39784.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   22, step  190, Time: 10.1963s, gt_cnt: 273.0, et_cnt: 204.4 train_loss: 41674.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step    0, Time: 11.4177s, gt_cnt:  40.0, et_cnt: 254.9 train_loss: 46.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   10, Time: 30.4418s, gt_cnt: 120.0, et_cnt:  47.8 train_loss: 1632.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   20, Time: 21.6114s, gt_cnt:  47.0, et_cnt:  83.1 train_loss: 2179.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   40, Time: 36.0509s, gt_cnt:  38.0, et_cnt: 184.1 train_loss: 9432.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   50, Time: 19.4394s, gt_cnt:  62.0, et_cnt:  45.5 train_loss: 9906.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   60, Time: 22.1842s, gt_cnt: 560.0, et_cnt: 324.2 train_loss: 13214.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   70, Time: 13.6813s, gt_cnt:  76.0, et_cnt:  34.1 train_loss: 14957.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step   90, Time: 32.7334s, gt_cnt:  85.0, et_cnt:  79.6 train_loss: 17444.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  100, Time: 17.0144s, gt_cnt:  61.0, et_cnt:  49.4 train_loss: 18035.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  110, Time: 14.8687s, gt_cnt:  31.0, et_cnt: 120.5 train_loss: 20685.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  120, Time: 9.6110s, gt_cnt: 196.0, et_cnt:  87.9 train_loss: 22453.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  130, Time: 19.8881s, gt_cnt:  42.0, et_cnt:  96.2 train_loss: 23175.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  140, Time: 26.1012s, gt_cnt: 678.0, et_cnt: 153.3 train_loss: 30461.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  150, Time: 20.0766s, gt_cnt: 1622.0, et_cnt: 1622.7 train_loss: 33587.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  160, Time: 20.3020s, gt_cnt:  20.0, et_cnt:  31.5 train_loss: 35630.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  170, Time: 15.8507s, gt_cnt: 227.0, et_cnt: 157.8 train_loss: 37190.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  180, Time: 13.2334s, gt_cnt:  95.0, et_cnt: 142.9 train_loss: 39747.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   23, step  190, Time: 10.1503s, gt_cnt: 273.0, et_cnt: 189.6 train_loss: 41634.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step    0, Time: 11.3648s, gt_cnt:  40.0, et_cnt: 244.9 train_loss: 46.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   10, Time: 30.4795s, gt_cnt: 120.0, et_cnt:  20.0 train_loss: 1632.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   20, Time: 21.4909s, gt_cnt:  47.0, et_cnt:  33.9 train_loss: 2180.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   40, Time: 36.2426s, gt_cnt:  38.0, et_cnt: 142.8 train_loss: 9445.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   50, Time: 19.5923s, gt_cnt:  62.0, et_cnt:  41.9 train_loss: 9918.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   60, Time: 21.9874s, gt_cnt: 560.0, et_cnt: 314.3 train_loss: 13222.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   70, Time: 13.6222s, gt_cnt:  76.0, et_cnt:  33.8 train_loss: 14964.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step   90, Time: 32.8121s, gt_cnt:  85.0, et_cnt:  83.5 train_loss: 17451.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  100, Time: 16.7825s, gt_cnt:  61.0, et_cnt:  51.4 train_loss: 18042.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  110, Time: 14.9006s, gt_cnt:  31.0, et_cnt: 127.4 train_loss: 20689.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  120, Time: 9.6150s, gt_cnt: 196.0, et_cnt:  96.2 train_loss: 22456.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  130, Time: 20.0235s, gt_cnt:  42.0, et_cnt:  92.6 train_loss: 23177.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  140, Time: 26.0887s, gt_cnt: 678.0, et_cnt: 156.2 train_loss: 30460.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  150, Time: 20.2189s, gt_cnt: 1622.0, et_cnt: 1559.0 train_loss: 33586.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  160, Time: 20.5177s, gt_cnt:  20.0, et_cnt:  34.2 train_loss: 35629.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  170, Time: 15.7892s, gt_cnt: 227.0, et_cnt: 152.9 train_loss: 37188.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  180, Time: 13.0690s, gt_cnt:  95.0, et_cnt: 145.9 train_loss: 39744.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   24, step  190, Time: 10.0282s, gt_cnt: 273.0, et_cnt: 189.9 train_loss: 41631.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step    0, Time: 11.2416s, gt_cnt:  40.0, et_cnt: 230.8 train_loss: 45.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   10, Time: 30.1831s, gt_cnt: 120.0, et_cnt:  31.1 train_loss: 1630.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   20, Time: 21.1744s, gt_cnt:  47.0, et_cnt:  66.2 train_loss: 2178.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   40, Time: 35.4149s, gt_cnt:  38.0, et_cnt: 186.5 train_loss: 9420.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   50, Time: 19.7758s, gt_cnt:  62.0, et_cnt:  48.8 train_loss: 9896.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   60, Time: 22.1372s, gt_cnt: 560.0, et_cnt: 314.3 train_loss: 13199.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   70, Time: 13.4838s, gt_cnt:  76.0, et_cnt:  32.5 train_loss: 14941.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step   90, Time: 32.1967s, gt_cnt:  85.0, et_cnt:  78.9 train_loss: 17426.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  100, Time: 16.0132s, gt_cnt:  61.0, et_cnt:  51.1 train_loss: 18017.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  110, Time: 14.6941s, gt_cnt:  31.0, et_cnt: 108.5 train_loss: 20663.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  120, Time: 9.5403s, gt_cnt: 196.0, et_cnt:  92.0 train_loss: 22430.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  130, Time: 19.9802s, gt_cnt:  42.0, et_cnt:  92.3 train_loss: 23151.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  140, Time: 26.0970s, gt_cnt: 678.0, et_cnt: 142.2 train_loss: 30443.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  150, Time: 20.0196s, gt_cnt: 1622.0, et_cnt: 1552.0 train_loss: 33572.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  160, Time: 20.3578s, gt_cnt:  20.0, et_cnt:  36.3 train_loss: 35617.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  170, Time: 15.7992s, gt_cnt: 227.0, et_cnt: 149.1 train_loss: 37174.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  180, Time: 13.1159s, gt_cnt:  95.0, et_cnt: 137.1 train_loss: 39732.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   25, step  190, Time: 10.1862s, gt_cnt: 273.0, et_cnt: 174.5 train_loss: 41619.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step    0, Time: 11.4141s, gt_cnt:  40.0, et_cnt: 220.6 train_loss: 45.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   10, Time: 30.3924s, gt_cnt: 120.0, et_cnt:  20.8 train_loss: 1630.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   20, Time: 21.5261s, gt_cnt:  47.0, et_cnt:  52.0 train_loss: 2177.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   40, Time: 36.0136s, gt_cnt:  38.0, et_cnt: 206.2 train_loss: 9409.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   50, Time: 19.2824s, gt_cnt:  62.0, et_cnt:  50.0 train_loss: 9887.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   60, Time: 22.0916s, gt_cnt: 560.0, et_cnt: 288.6 train_loss: 13190.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   70, Time: 13.5914s, gt_cnt:  76.0, et_cnt:  31.3 train_loss: 14932.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step   90, Time: 32.7158s, gt_cnt:  85.0, et_cnt:  70.9 train_loss: 17415.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  100, Time: 16.7778s, gt_cnt:  61.0, et_cnt:  54.1 train_loss: 18006.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  110, Time: 14.9155s, gt_cnt:  31.0, et_cnt: 111.0 train_loss: 20649.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  120, Time: 9.6290s, gt_cnt: 196.0, et_cnt:  97.2 train_loss: 22415.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  130, Time: 19.8160s, gt_cnt:  42.0, et_cnt:  89.5 train_loss: 23137.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  140, Time: 26.1580s, gt_cnt: 678.0, et_cnt: 146.8 train_loss: 30416.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  150, Time: 20.0994s, gt_cnt: 1622.0, et_cnt: 1563.4 train_loss: 33543.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  160, Time: 20.2984s, gt_cnt:  20.0, et_cnt:  33.0 train_loss: 35586.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  170, Time: 15.7155s, gt_cnt: 227.0, et_cnt: 150.7 train_loss: 37143.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  180, Time: 13.3022s, gt_cnt:  95.0, et_cnt: 139.6 train_loss: 39698.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   26, step  190, Time: 10.1976s, gt_cnt: 273.0, et_cnt: 189.9 train_loss: 41584.8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   27, step    0, Time: 11.4096s, gt_cnt:  40.0, et_cnt: 232.3 train_loss: 45.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   10, Time: 30.0589s, gt_cnt: 120.0, et_cnt:  42.6 train_loss: 1630.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   20, Time: 21.5068s, gt_cnt:  47.0, et_cnt:  70.3 train_loss: 2178.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   40, Time: 36.0561s, gt_cnt:  38.0, et_cnt: 171.6 train_loss: 9415.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   50, Time: 19.4725s, gt_cnt:  62.0, et_cnt:  48.0 train_loss: 9890.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   60, Time: 22.0576s, gt_cnt: 560.0, et_cnt: 302.5 train_loss: 13191.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   70, Time: 13.5795s, gt_cnt:  76.0, et_cnt:  29.4 train_loss: 14932.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step   90, Time: 32.5510s, gt_cnt:  85.0, et_cnt:  75.5 train_loss: 17416.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  100, Time: 16.9644s, gt_cnt:  61.0, et_cnt:  41.7 train_loss: 18007.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  110, Time: 14.8299s, gt_cnt:  31.0, et_cnt: 101.9 train_loss: 20652.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  120, Time: 9.5656s, gt_cnt: 196.0, et_cnt:  93.4 train_loss: 22417.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  130, Time: 19.6710s, gt_cnt:  42.0, et_cnt:  95.3 train_loss: 23138.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  140, Time: 25.9824s, gt_cnt: 678.0, et_cnt: 157.1 train_loss: 30410.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  150, Time: 20.2989s, gt_cnt: 1622.0, et_cnt: 1541.4 train_loss: 33535.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  160, Time: 20.2979s, gt_cnt:  20.0, et_cnt:  31.7 train_loss: 35579.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  170, Time: 15.8438s, gt_cnt: 227.0, et_cnt: 159.1 train_loss: 37135.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  180, Time: 13.1162s, gt_cnt:  95.0, et_cnt: 141.2 train_loss: 39687.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   27, step  190, Time: 10.0576s, gt_cnt: 273.0, et_cnt: 192.3 train_loss: 41573.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step    0, Time: 11.2499s, gt_cnt:  40.0, et_cnt: 225.4 train_loss: 45.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   10, Time: 29.9623s, gt_cnt: 120.0, et_cnt:  21.6 train_loss: 1629.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   20, Time: 21.1269s, gt_cnt:  47.0, et_cnt:  48.5 train_loss: 2176.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   40, Time: 35.5282s, gt_cnt:  38.0, et_cnt: 199.9 train_loss: 9405.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   50, Time: 19.7420s, gt_cnt:  62.0, et_cnt:  51.4 train_loss: 9882.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   60, Time: 22.0192s, gt_cnt: 560.0, et_cnt: 289.6 train_loss: 13184.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   70, Time: 13.4499s, gt_cnt:  76.0, et_cnt:  33.3 train_loss: 14925.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step   90, Time: 32.5656s, gt_cnt:  85.0, et_cnt:  73.2 train_loss: 17406.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  100, Time: 16.8894s, gt_cnt:  61.0, et_cnt:  48.4 train_loss: 17996.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  110, Time: 14.7652s, gt_cnt:  31.0, et_cnt:  85.5 train_loss: 20640.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  120, Time: 9.4981s, gt_cnt: 196.0, et_cnt:  86.8 train_loss: 22404.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  130, Time: 19.9116s, gt_cnt:  42.0, et_cnt:  96.1 train_loss: 23125.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  140, Time: 25.8395s, gt_cnt: 678.0, et_cnt: 166.1 train_loss: 30390.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  150, Time: 19.9231s, gt_cnt: 1622.0, et_cnt: 1598.3 train_loss: 33516.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  160, Time: 20.1554s, gt_cnt:  20.0, et_cnt:  27.7 train_loss: 35558.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  170, Time: 15.6854s, gt_cnt: 227.0, et_cnt: 142.9 train_loss: 37113.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  180, Time: 13.2483s, gt_cnt:  95.0, et_cnt: 136.0 train_loss: 39665.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   28, step  190, Time: 10.1876s, gt_cnt: 273.0, et_cnt: 194.3 train_loss: 41551.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step    0, Time: 11.3682s, gt_cnt:  40.0, et_cnt: 228.6 train_loss: 45.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   10, Time: 30.7682s, gt_cnt: 120.0, et_cnt:  44.2 train_loss: 1630.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   20, Time: 21.5709s, gt_cnt:  47.0, et_cnt:  71.0 train_loss: 2177.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   40, Time: 36.3019s, gt_cnt:  38.0, et_cnt: 188.7 train_loss: 9405.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   50, Time: 19.6369s, gt_cnt:  62.0, et_cnt:  51.0 train_loss: 9881.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   60, Time: 22.2386s, gt_cnt: 560.0, et_cnt: 291.7 train_loss: 13182.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   70, Time: 13.6419s, gt_cnt:  76.0, et_cnt:  31.1 train_loss: 14922.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step   90, Time: 32.3416s, gt_cnt:  85.0, et_cnt:  75.3 train_loss: 17403.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  100, Time: 17.1069s, gt_cnt:  61.0, et_cnt:  49.7 train_loss: 17993.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  110, Time: 14.9722s, gt_cnt:  31.0, et_cnt:  93.4 train_loss: 20635.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  120, Time: 9.5795s, gt_cnt: 196.0, et_cnt:  92.9 train_loss: 22398.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  130, Time: 19.6290s, gt_cnt:  42.0, et_cnt:  91.1 train_loss: 23119.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  140, Time: 25.6799s, gt_cnt: 678.0, et_cnt: 167.6 train_loss: 30384.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  150, Time: 19.8453s, gt_cnt: 1622.0, et_cnt: 1650.2 train_loss: 33511.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  160, Time: 20.2864s, gt_cnt:  20.0, et_cnt:  27.0 train_loss: 35553.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  170, Time: 15.7765s, gt_cnt: 227.0, et_cnt: 147.1 train_loss: 37109.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  180, Time: 12.9699s, gt_cnt:  95.0, et_cnt: 132.8 train_loss: 39659.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   29, step  190, Time: 10.1250s, gt_cnt: 273.0, et_cnt: 191.7 train_loss: 41543.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step    0, Time: 11.2867s, gt_cnt:  40.0, et_cnt: 237.5 train_loss: 46.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   10, Time: 30.0706s, gt_cnt: 120.0, et_cnt:  46.5 train_loss: 1630.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   20, Time: 21.3560s, gt_cnt:  47.0, et_cnt:  69.7 train_loss: 2177.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   40, Time: 35.8992s, gt_cnt:  38.0, et_cnt: 180.1 train_loss: 9403.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   50, Time: 19.2130s, gt_cnt:  62.0, et_cnt:  50.5 train_loss: 9879.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   60, Time: 22.1148s, gt_cnt: 560.0, et_cnt: 292.8 train_loss: 13178.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   70, Time: 13.6295s, gt_cnt:  76.0, et_cnt:  32.7 train_loss: 14918.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step   90, Time: 32.6668s, gt_cnt:  85.0, et_cnt:  72.8 train_loss: 17399.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  100, Time: 17.1614s, gt_cnt:  61.0, et_cnt:  47.0 train_loss: 17989.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  110, Time: 14.8194s, gt_cnt:  31.0, et_cnt:  87.4 train_loss: 20630.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  120, Time: 9.6102s, gt_cnt: 196.0, et_cnt:  88.1 train_loss: 22393.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  130, Time: 19.6521s, gt_cnt:  42.0, et_cnt:  97.4 train_loss: 23114.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  140, Time: 26.1348s, gt_cnt: 678.0, et_cnt: 179.2 train_loss: 30369.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  150, Time: 19.8407s, gt_cnt: 1622.0, et_cnt: 1574.1 train_loss: 33494.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  160, Time: 20.2743s, gt_cnt:  20.0, et_cnt:  26.1 train_loss: 35535.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  170, Time: 15.7121s, gt_cnt: 227.0, et_cnt: 151.5 train_loss: 37090.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  180, Time: 12.9884s, gt_cnt:  95.0, et_cnt: 136.4 train_loss: 39637.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   30, step  190, Time: 9.9720s, gt_cnt: 273.0, et_cnt: 191.3 train_loss: 41522.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step    0, Time: 11.3007s, gt_cnt:  40.0, et_cnt: 199.9 train_loss: 45.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   10, Time: 30.5038s, gt_cnt: 120.0, et_cnt:  18.1 train_loss: 1626.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   20, Time: 21.4964s, gt_cnt:  47.0, et_cnt:  31.2 train_loss: 2173.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   40, Time: 36.1010s, gt_cnt:  38.0, et_cnt: 253.6 train_loss: 9392.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   50, Time: 19.4826s, gt_cnt:  62.0, et_cnt:  54.2 train_loss: 9871.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   60, Time: 21.9643s, gt_cnt: 560.0, et_cnt: 274.9 train_loss: 13179.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   70, Time: 13.5243s, gt_cnt:  76.0, et_cnt:  44.1 train_loss: 14920.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step   90, Time: 32.4371s, gt_cnt:  85.0, et_cnt:  70.9 train_loss: 17395.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  100, Time: 16.6769s, gt_cnt:  61.0, et_cnt:  50.3 train_loss: 17986.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   31, step  110, Time: 14.7841s, gt_cnt:  31.0, et_cnt:  86.6 train_loss: 20628.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  120, Time: 9.5691s, gt_cnt: 196.0, et_cnt:  86.0 train_loss: 22391.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  130, Time: 19.8672s, gt_cnt:  42.0, et_cnt:  92.9 train_loss: 23112.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  140, Time: 26.0337s, gt_cnt: 678.0, et_cnt: 169.2 train_loss: 30364.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  150, Time: 20.1506s, gt_cnt: 1622.0, et_cnt: 1557.2 train_loss: 33487.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  160, Time: 20.3120s, gt_cnt:  20.0, et_cnt:  24.6 train_loss: 35529.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  170, Time: 15.5461s, gt_cnt: 227.0, et_cnt: 151.0 train_loss: 37083.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  180, Time: 13.0601s, gt_cnt:  95.0, et_cnt: 147.5 train_loss: 39631.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   31, step  190, Time: 10.1278s, gt_cnt: 273.0, et_cnt: 200.7 train_loss: 41519.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step    0, Time: 11.3750s, gt_cnt:  40.0, et_cnt: 201.9 train_loss: 45.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   10, Time: 30.4627s, gt_cnt: 120.0, et_cnt:  42.9 train_loss: 1627.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   20, Time: 21.5994s, gt_cnt:  47.0, et_cnt:  69.1 train_loss: 2174.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   40, Time: 36.1821s, gt_cnt:  38.0, et_cnt: 196.0 train_loss: 9398.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   50, Time: 19.4343s, gt_cnt:  62.0, et_cnt:  46.9 train_loss: 9873.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   60, Time: 21.9672s, gt_cnt: 560.0, et_cnt: 254.2 train_loss: 13172.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   70, Time: 13.3105s, gt_cnt:  76.0, et_cnt:  27.9 train_loss: 14912.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step   90, Time: 32.0638s, gt_cnt:  85.0, et_cnt:  69.6 train_loss: 17391.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  100, Time: 16.7749s, gt_cnt:  61.0, et_cnt:  43.7 train_loss: 17981.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  110, Time: 14.5344s, gt_cnt:  31.0, et_cnt:  86.5 train_loss: 20618.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  120, Time: 9.3593s, gt_cnt: 196.0, et_cnt:  87.2 train_loss: 22382.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  130, Time: 19.5195s, gt_cnt:  42.0, et_cnt: 102.6 train_loss: 23103.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  140, Time: 25.4450s, gt_cnt: 678.0, et_cnt: 182.1 train_loss: 30350.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  150, Time: 19.9357s, gt_cnt: 1622.0, et_cnt: 1560.2 train_loss: 33474.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  160, Time: 20.0834s, gt_cnt:  20.0, et_cnt:  22.4 train_loss: 35516.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  170, Time: 15.4390s, gt_cnt: 227.0, et_cnt: 167.2 train_loss: 37070.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  180, Time: 13.0277s, gt_cnt:  95.0, et_cnt: 137.3 train_loss: 39614.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   32, step  190, Time: 10.0877s, gt_cnt: 273.0, et_cnt: 190.9 train_loss: 41495.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step    0, Time: 11.2998s, gt_cnt:  40.0, et_cnt: 219.4 train_loss: 45.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   10, Time: 30.2683s, gt_cnt: 120.0, et_cnt:  40.1 train_loss: 1628.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   20, Time: 21.5506s, gt_cnt:  47.0, et_cnt:  37.5 train_loss: 2174.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   40, Time: 36.2929s, gt_cnt:  38.0, et_cnt: 200.6 train_loss: 9389.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   50, Time: 19.5868s, gt_cnt:  62.0, et_cnt:  49.9 train_loss: 9866.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   60, Time: 21.9489s, gt_cnt: 560.0, et_cnt: 262.4 train_loss: 13169.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   70, Time: 13.5706s, gt_cnt:  76.0, et_cnt:  44.6 train_loss: 14912.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step   90, Time: 32.9243s, gt_cnt:  85.0, et_cnt:  59.7 train_loss: 17388.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  100, Time: 16.7563s, gt_cnt:  61.0, et_cnt:  40.8 train_loss: 17978.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  110, Time: 14.7288s, gt_cnt:  31.0, et_cnt:  61.1 train_loss: 20619.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  120, Time: 9.5251s, gt_cnt: 196.0, et_cnt:  70.7 train_loss: 22382.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  130, Time: 19.8875s, gt_cnt:  42.0, et_cnt: 103.0 train_loss: 23099.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  140, Time: 25.9059s, gt_cnt: 678.0, et_cnt: 205.5 train_loss: 30339.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  150, Time: 20.1329s, gt_cnt: 1622.0, et_cnt: 1434.0 train_loss: 33463.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  160, Time: 20.1344s, gt_cnt:  20.0, et_cnt:  21.9 train_loss: 35504.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  170, Time: 15.6862s, gt_cnt: 227.0, et_cnt: 156.2 train_loss: 37058.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  180, Time: 13.0692s, gt_cnt:  95.0, et_cnt: 144.6 train_loss: 39598.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   33, step  190, Time: 10.1092s, gt_cnt: 273.0, et_cnt: 192.7 train_loss: 41480.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step    0, Time: 11.3317s, gt_cnt:  40.0, et_cnt: 205.7 train_loss: 45.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   10, Time: 30.2858s, gt_cnt: 120.0, et_cnt:  46.8 train_loss: 1627.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   20, Time: 21.4809s, gt_cnt:  47.0, et_cnt:  56.5 train_loss: 2173.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   40, Time: 36.0314s, gt_cnt:  38.0, et_cnt: 208.8 train_loss: 9387.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   50, Time: 19.3908s, gt_cnt:  62.0, et_cnt:  48.8 train_loss: 9864.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   60, Time: 21.7642s, gt_cnt: 560.0, et_cnt: 253.5 train_loss: 13165.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   70, Time: 13.4611s, gt_cnt:  76.0, et_cnt:  37.5 train_loss: 14906.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step   90, Time: 32.6700s, gt_cnt:  85.0, et_cnt:  67.2 train_loss: 17382.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  100, Time: 16.9344s, gt_cnt:  61.0, et_cnt:  40.5 train_loss: 17972.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  110, Time: 14.6904s, gt_cnt:  31.0, et_cnt:  64.6 train_loss: 20610.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  120, Time: 9.3471s, gt_cnt: 196.0, et_cnt:  72.9 train_loss: 22373.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  130, Time: 19.7039s, gt_cnt:  42.0, et_cnt: 105.3 train_loss: 23091.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  140, Time: 25.4327s, gt_cnt: 678.0, et_cnt: 210.3 train_loss: 30327.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  150, Time: 19.7052s, gt_cnt: 1622.0, et_cnt: 1512.3 train_loss: 33450.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  160, Time: 19.9467s, gt_cnt:  20.0, et_cnt:  20.4 train_loss: 35491.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  170, Time: 15.7290s, gt_cnt: 227.0, et_cnt: 159.6 train_loss: 37044.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  180, Time: 13.1627s, gt_cnt:  95.0, et_cnt: 145.2 train_loss: 39583.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   34, step  190, Time: 9.9089s, gt_cnt: 273.0, et_cnt: 192.2 train_loss: 41464.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step    0, Time: 11.0289s, gt_cnt:  40.0, et_cnt: 204.8 train_loss: 45.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   10, Time: 29.4610s, gt_cnt: 120.0, et_cnt:  46.4 train_loss: 1626.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   20, Time: 21.0186s, gt_cnt:  47.0, et_cnt:  48.9 train_loss: 2173.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   40, Time: 35.4581s, gt_cnt:  38.0, et_cnt: 205.3 train_loss: 9383.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   50, Time: 19.1620s, gt_cnt:  62.0, et_cnt:  49.8 train_loss: 9860.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   60, Time: 21.7045s, gt_cnt: 560.0, et_cnt: 255.7 train_loss: 13161.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   70, Time: 13.3423s, gt_cnt:  76.0, et_cnt:  41.2 train_loss: 14903.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step   90, Time: 31.6922s, gt_cnt:  85.0, et_cnt:  62.4 train_loss: 17379.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  100, Time: 16.6584s, gt_cnt:  61.0, et_cnt:  39.0 train_loss: 17969.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  110, Time: 14.5301s, gt_cnt:  31.0, et_cnt:  58.1 train_loss: 20606.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  120, Time: 9.4338s, gt_cnt: 196.0, et_cnt:  82.7 train_loss: 22368.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  130, Time: 19.7950s, gt_cnt:  42.0, et_cnt: 100.6 train_loss: 23086.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  140, Time: 25.6106s, gt_cnt: 678.0, et_cnt: 221.9 train_loss: 30317.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  150, Time: 19.9877s, gt_cnt: 1622.0, et_cnt: 1493.0 train_loss: 33440.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  160, Time: 20.0626s, gt_cnt:  20.0, et_cnt:  19.1 train_loss: 35480.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  170, Time: 15.5160s, gt_cnt: 227.0, et_cnt: 160.3 train_loss: 37033.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  180, Time: 13.1047s, gt_cnt:  95.0, et_cnt: 145.3 train_loss: 39570.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   35, step  190, Time: 10.0440s, gt_cnt: 273.0, et_cnt: 188.4 train_loss: 41450.7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   36, step    0, Time: 11.2606s, gt_cnt:  40.0, et_cnt: 193.7 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   10, Time: 30.2161s, gt_cnt: 120.0, et_cnt:  46.8 train_loss: 1626.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   20, Time: 21.4634s, gt_cnt:  47.0, et_cnt:  54.1 train_loss: 2172.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   40, Time: 36.1146s, gt_cnt:  38.0, et_cnt: 215.2 train_loss: 9378.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   50, Time: 19.2602s, gt_cnt:  62.0, et_cnt:  50.7 train_loss: 9856.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   60, Time: 21.5205s, gt_cnt: 560.0, et_cnt: 241.6 train_loss: 13158.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   70, Time: 13.2773s, gt_cnt:  76.0, et_cnt:  41.5 train_loss: 14899.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step   90, Time: 32.1847s, gt_cnt:  85.0, et_cnt:  63.2 train_loss: 17374.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  100, Time: 16.5179s, gt_cnt:  61.0, et_cnt:  39.4 train_loss: 17964.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  110, Time: 14.7146s, gt_cnt:  31.0, et_cnt:  55.2 train_loss: 20599.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  120, Time: 9.3608s, gt_cnt: 196.0, et_cnt:  67.9 train_loss: 22361.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  130, Time: 19.3938s, gt_cnt:  42.0, et_cnt: 104.6 train_loss: 23078.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  140, Time: 25.4732s, gt_cnt: 678.0, et_cnt: 226.0 train_loss: 30304.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  150, Time: 19.8119s, gt_cnt: 1622.0, et_cnt: 1487.0 train_loss: 33426.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  160, Time: 20.0413s, gt_cnt:  20.0, et_cnt:  18.9 train_loss: 35465.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  170, Time: 15.4498s, gt_cnt: 227.0, et_cnt: 165.6 train_loss: 37017.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  180, Time: 12.9336s, gt_cnt:  95.0, et_cnt: 146.4 train_loss: 39553.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   36, step  190, Time: 9.9624s, gt_cnt: 273.0, et_cnt: 188.6 train_loss: 41431.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step    0, Time: 11.0296s, gt_cnt:  40.0, et_cnt: 185.9 train_loss: 45.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   10, Time: 29.4527s, gt_cnt: 120.0, et_cnt:  45.7 train_loss: 1625.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   20, Time: 21.0468s, gt_cnt:  47.0, et_cnt:  54.6 train_loss: 2171.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   40, Time: 35.3695s, gt_cnt:  38.0, et_cnt: 228.8 train_loss: 9373.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   50, Time: 18.9134s, gt_cnt:  62.0, et_cnt:  51.7 train_loss: 9851.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   60, Time: 21.7713s, gt_cnt: 560.0, et_cnt: 234.9 train_loss: 13155.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   70, Time: 13.3509s, gt_cnt:  76.0, et_cnt:  43.4 train_loss: 14896.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step   90, Time: 31.9636s, gt_cnt:  85.0, et_cnt:  60.7 train_loss: 17369.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  100, Time: 17.3367s, gt_cnt:  61.0, et_cnt:  37.7 train_loss: 17959.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  110, Time: 14.9007s, gt_cnt:  31.0, et_cnt:  52.5 train_loss: 20593.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  120, Time: 9.6005s, gt_cnt: 196.0, et_cnt:  68.0 train_loss: 22355.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  130, Time: 19.9271s, gt_cnt:  42.0, et_cnt: 104.4 train_loss: 23072.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  140, Time: 25.2080s, gt_cnt: 678.0, et_cnt: 230.3 train_loss: 30293.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  150, Time: 19.4396s, gt_cnt: 1622.0, et_cnt: 1527.3 train_loss: 33415.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  160, Time: 20.0157s, gt_cnt:  20.0, et_cnt:  18.8 train_loss: 35453.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  170, Time: 15.4283s, gt_cnt: 227.0, et_cnt: 165.8 train_loss: 37005.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  180, Time: 12.9468s, gt_cnt:  95.0, et_cnt: 146.1 train_loss: 39540.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   37, step  190, Time: 9.8669s, gt_cnt: 273.0, et_cnt: 190.7 train_loss: 41418.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step    0, Time: 11.0454s, gt_cnt:  40.0, et_cnt: 188.7 train_loss: 45.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   10, Time: 29.6166s, gt_cnt: 120.0, et_cnt:  48.0 train_loss: 1625.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   20, Time: 21.0511s, gt_cnt:  47.0, et_cnt:  59.6 train_loss: 2171.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   40, Time: 35.0575s, gt_cnt:  38.0, et_cnt: 226.4 train_loss: 9371.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   50, Time: 18.8904s, gt_cnt:  62.0, et_cnt:  51.2 train_loss: 9848.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   60, Time: 21.9755s, gt_cnt: 560.0, et_cnt: 189.0 train_loss: 13149.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   70, Time: 13.6181s, gt_cnt:  76.0, et_cnt:  32.6 train_loss: 14888.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step   90, Time: 32.0412s, gt_cnt:  85.0, et_cnt:  55.1 train_loss: 17361.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  100, Time: 16.5466s, gt_cnt:  61.0, et_cnt:  38.8 train_loss: 17951.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  110, Time: 14.6774s, gt_cnt:  31.0, et_cnt:  60.8 train_loss: 20580.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  120, Time: 9.3160s, gt_cnt: 196.0, et_cnt:  80.4 train_loss: 22340.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  130, Time: 19.4462s, gt_cnt:  42.0, et_cnt: 100.3 train_loss: 23060.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  140, Time: 25.2416s, gt_cnt: 678.0, et_cnt: 221.4 train_loss: 30283.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  150, Time: 20.1271s, gt_cnt: 1622.0, et_cnt: 1752.4 train_loss: 33409.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  160, Time: 20.1150s, gt_cnt:  20.0, et_cnt:  16.3 train_loss: 35447.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  170, Time: 15.3354s, gt_cnt: 227.0, et_cnt: 141.6 train_loss: 37000.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  180, Time: 12.9408s, gt_cnt:  95.0, et_cnt: 131.7 train_loss: 39537.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   38, step  190, Time: 9.8621s, gt_cnt: 273.0, et_cnt: 199.8 train_loss: 41413.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step    0, Time: 11.1808s, gt_cnt:  40.0, et_cnt: 212.9 train_loss: 45.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   10, Time: 30.1182s, gt_cnt: 120.0, et_cnt:  50.0 train_loss: 1626.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   20, Time: 21.2954s, gt_cnt:  47.0, et_cnt:  62.2 train_loss: 2172.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   40, Time: 35.4632s, gt_cnt:  38.0, et_cnt: 206.5 train_loss: 9372.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   50, Time: 19.6027s, gt_cnt:  62.0, et_cnt:  51.1 train_loss: 9847.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   60, Time: 21.5266s, gt_cnt: 560.0, et_cnt: 208.9 train_loss: 13144.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   70, Time: 13.2265s, gt_cnt:  76.0, et_cnt:  29.4 train_loss: 14883.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step   90, Time: 31.7866s, gt_cnt:  85.0, et_cnt:  56.8 train_loss: 17357.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  100, Time: 16.3168s, gt_cnt:  61.0, et_cnt:  36.9 train_loss: 17947.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  110, Time: 14.7155s, gt_cnt:  31.0, et_cnt:  59.7 train_loss: 20574.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  120, Time: 9.5006s, gt_cnt: 196.0, et_cnt:  79.8 train_loss: 22333.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  130, Time: 19.4772s, gt_cnt:  42.0, et_cnt: 102.8 train_loss: 23053.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  140, Time: 25.7266s, gt_cnt: 678.0, et_cnt: 233.9 train_loss: 30270.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  150, Time: 19.8490s, gt_cnt: 1622.0, et_cnt: 1749.5 train_loss: 33394.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  160, Time: 20.2412s, gt_cnt:  20.0, et_cnt:  16.6 train_loss: 35431.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  170, Time: 15.4559s, gt_cnt: 227.0, et_cnt: 149.4 train_loss: 36984.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  180, Time: 13.0215s, gt_cnt:  95.0, et_cnt: 135.0 train_loss: 39520.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   39, step  190, Time: 10.0416s, gt_cnt: 273.0, et_cnt: 201.6 train_loss: 41396.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step    0, Time: 11.1692s, gt_cnt:  40.0, et_cnt: 208.6 train_loss: 45.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   10, Time: 29.8995s, gt_cnt: 120.0, et_cnt:  52.4 train_loss: 1626.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   20, Time: 21.0901s, gt_cnt:  47.0, et_cnt:  66.4 train_loss: 2172.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   40, Time: 35.3411s, gt_cnt:  38.0, et_cnt: 207.7 train_loss: 9368.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   50, Time: 19.0177s, gt_cnt:  62.0, et_cnt:  51.3 train_loss: 9844.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   60, Time: 21.5772s, gt_cnt: 560.0, et_cnt: 187.7 train_loss: 13141.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   70, Time: 13.6488s, gt_cnt:  76.0, et_cnt:  27.6 train_loss: 14878.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step   90, Time: 32.2520s, gt_cnt:  85.0, et_cnt:  53.9 train_loss: 17351.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  100, Time: 16.6443s, gt_cnt:  61.0, et_cnt:  38.4 train_loss: 17940.7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   40, step  110, Time: 14.7816s, gt_cnt:  31.0, et_cnt:  61.2 train_loss: 20564.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  120, Time: 9.3939s, gt_cnt: 196.0, et_cnt:  79.0 train_loss: 22324.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  130, Time: 19.5819s, gt_cnt:  42.0, et_cnt: 103.8 train_loss: 23043.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  140, Time: 25.5883s, gt_cnt: 678.0, et_cnt: 235.1 train_loss: 30254.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  150, Time: 19.8189s, gt_cnt: 1622.0, et_cnt: 1697.9 train_loss: 33376.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  160, Time: 19.9948s, gt_cnt:  20.0, et_cnt:  16.5 train_loss: 35412.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  170, Time: 15.4675s, gt_cnt: 227.0, et_cnt: 119.4 train_loss: 36972.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  180, Time: 12.9227s, gt_cnt:  95.0, et_cnt: 129.3 train_loss: 39506.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   40, step  190, Time: 9.9788s, gt_cnt: 273.0, et_cnt: 189.7 train_loss: 41380.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step    0, Time: 11.2306s, gt_cnt:  40.0, et_cnt: 190.4 train_loss: 45.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   10, Time: 29.9663s, gt_cnt: 120.0, et_cnt:  46.6 train_loss: 1625.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   20, Time: 21.0851s, gt_cnt:  47.0, et_cnt:  63.7 train_loss: 2171.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   40, Time: 35.3839s, gt_cnt:  38.0, et_cnt: 223.8 train_loss: 9363.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   50, Time: 19.3394s, gt_cnt:  62.0, et_cnt:  50.9 train_loss: 9840.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   60, Time: 21.6375s, gt_cnt: 560.0, et_cnt: 160.8 train_loss: 13138.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   70, Time: 13.2302s, gt_cnt:  76.0, et_cnt:  30.6 train_loss: 14875.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step   90, Time: 32.0948s, gt_cnt:  85.0, et_cnt:  58.9 train_loss: 17346.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  100, Time: 16.7637s, gt_cnt:  61.0, et_cnt:  37.2 train_loss: 17935.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  110, Time: 14.4786s, gt_cnt:  31.0, et_cnt:  52.9 train_loss: 20559.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  120, Time: 9.3357s, gt_cnt: 196.0, et_cnt:  72.3 train_loss: 22319.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  130, Time: 19.4492s, gt_cnt:  42.0, et_cnt: 105.7 train_loss: 23037.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  140, Time: 25.4170s, gt_cnt: 678.0, et_cnt: 248.6 train_loss: 30239.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  150, Time: 19.8612s, gt_cnt: 1622.0, et_cnt: 1669.4 train_loss: 33360.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  160, Time: 19.9500s, gt_cnt:  20.0, et_cnt:  16.2 train_loss: 35394.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  170, Time: 15.3632s, gt_cnt: 227.0, et_cnt: 156.7 train_loss: 36945.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  180, Time: 12.9221s, gt_cnt:  95.0, et_cnt: 140.9 train_loss: 39475.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   41, step  190, Time: 9.9382s, gt_cnt: 273.0, et_cnt: 194.9 train_loss: 41348.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step    0, Time: 11.1200s, gt_cnt:  40.0, et_cnt: 188.2 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   10, Time: 29.8181s, gt_cnt: 120.0, et_cnt:  49.2 train_loss: 1625.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   20, Time: 21.2873s, gt_cnt:  47.0, et_cnt:  60.6 train_loss: 2170.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   40, Time: 35.3808s, gt_cnt:  38.0, et_cnt: 213.7 train_loss: 9359.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   50, Time: 18.9528s, gt_cnt:  62.0, et_cnt:  48.3 train_loss: 9835.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   60, Time: 21.4126s, gt_cnt: 560.0, et_cnt: 139.1 train_loss: 13135.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   70, Time: 13.2899s, gt_cnt:  76.0, et_cnt:  40.8 train_loss: 14874.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step   90, Time: 32.2796s, gt_cnt:  85.0, et_cnt:  53.7 train_loss: 17344.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  100, Time: 16.7470s, gt_cnt:  61.0, et_cnt:  30.4 train_loss: 17934.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  110, Time: 14.6952s, gt_cnt:  31.0, et_cnt:  43.4 train_loss: 20560.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  120, Time: 9.3595s, gt_cnt: 196.0, et_cnt:  63.2 train_loss: 22319.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  130, Time: 19.2802s, gt_cnt:  42.0, et_cnt: 110.3 train_loss: 23036.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  140, Time: 25.1237s, gt_cnt: 678.0, et_cnt: 258.5 train_loss: 30233.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  150, Time: 19.3237s, gt_cnt: 1622.0, et_cnt: 1524.4 train_loss: 33353.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  160, Time: 20.0587s, gt_cnt:  20.0, et_cnt:  16.9 train_loss: 35388.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  170, Time: 15.4985s, gt_cnt: 227.0, et_cnt: 149.2 train_loss: 36938.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  180, Time: 13.0007s, gt_cnt:  95.0, et_cnt: 145.6 train_loss: 39465.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   42, step  190, Time: 9.8812s, gt_cnt: 273.0, et_cnt: 191.4 train_loss: 41338.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step    0, Time: 11.0745s, gt_cnt:  40.0, et_cnt: 178.3 train_loss: 44.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   10, Time: 29.7482s, gt_cnt: 120.0, et_cnt:  45.3 train_loss: 1624.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   20, Time: 21.0223s, gt_cnt:  47.0, et_cnt:  53.9 train_loss: 2170.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   40, Time: 35.2621s, gt_cnt:  38.0, et_cnt: 217.3 train_loss: 9356.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   50, Time: 19.2423s, gt_cnt:  62.0, et_cnt:  41.8 train_loss: 9833.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   60, Time: 21.4832s, gt_cnt: 560.0, et_cnt: 116.8 train_loss: 13138.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   70, Time: 13.2874s, gt_cnt:  76.0, et_cnt:  53.5 train_loss: 14886.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step   90, Time: 31.9511s, gt_cnt:  85.0, et_cnt:  44.2 train_loss: 17360.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  100, Time: 16.8525s, gt_cnt:  61.0, et_cnt:  26.1 train_loss: 17950.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  110, Time: 14.6712s, gt_cnt:  31.0, et_cnt:  37.1 train_loss: 20579.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  120, Time: 9.4015s, gt_cnt: 196.0, et_cnt:  71.9 train_loss: 22339.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  130, Time: 19.5695s, gt_cnt:  42.0, et_cnt: 104.5 train_loss: 23058.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  140, Time: 25.5092s, gt_cnt: 678.0, et_cnt: 246.4 train_loss: 30253.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  150, Time: 19.7643s, gt_cnt: 1622.0, et_cnt: 1622.2 train_loss: 33379.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  160, Time: 20.0346s, gt_cnt:  20.0, et_cnt:  15.8 train_loss: 35417.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  170, Time: 15.3582s, gt_cnt: 227.0, et_cnt: 138.7 train_loss: 36967.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  180, Time: 13.0300s, gt_cnt:  95.0, et_cnt: 135.0 train_loss: 39495.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   43, step  190, Time: 9.9816s, gt_cnt: 273.0, et_cnt: 190.2 train_loss: 41367.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step    0, Time: 11.1847s, gt_cnt:  40.0, et_cnt: 176.2 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   10, Time: 30.0209s, gt_cnt: 120.0, et_cnt:  43.7 train_loss: 1624.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   20, Time: 21.0778s, gt_cnt:  47.0, et_cnt:  58.8 train_loss: 2170.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   40, Time: 35.1220s, gt_cnt:  38.0, et_cnt: 207.0 train_loss: 9359.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   50, Time: 19.3886s, gt_cnt:  62.0, et_cnt:  49.2 train_loss: 9836.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   60, Time: 21.6528s, gt_cnt: 560.0, et_cnt: 248.4 train_loss: 13134.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   70, Time: 13.3103s, gt_cnt:  76.0, et_cnt:  42.1 train_loss: 14874.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step   90, Time: 32.0995s, gt_cnt:  85.0, et_cnt:  61.3 train_loss: 17346.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  100, Time: 17.0942s, gt_cnt:  61.0, et_cnt:  35.9 train_loss: 17935.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  110, Time: 14.6057s, gt_cnt:  31.0, et_cnt:  48.2 train_loss: 20558.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  120, Time: 9.2957s, gt_cnt: 196.0, et_cnt:  66.2 train_loss: 22318.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  130, Time: 19.8968s, gt_cnt:  42.0, et_cnt: 108.9 train_loss: 23034.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  140, Time: 25.3271s, gt_cnt: 678.0, et_cnt: 266.9 train_loss: 30219.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  150, Time: 19.6773s, gt_cnt: 1622.0, et_cnt: 1469.8 train_loss: 33339.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  160, Time: 19.9176s, gt_cnt:  20.0, et_cnt:  17.7 train_loss: 35374.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  170, Time: 15.3918s, gt_cnt: 227.0, et_cnt: 163.0 train_loss: 36923.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  180, Time: 12.9334s, gt_cnt:  95.0, et_cnt: 147.1 train_loss: 39445.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   44, step  190, Time: 9.9006s, gt_cnt: 273.0, et_cnt: 188.2 train_loss: 41315.3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   45, step    0, Time: 11.0517s, gt_cnt:  40.0, et_cnt: 165.5 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   10, Time: 29.7964s, gt_cnt: 120.0, et_cnt:  45.8 train_loss: 1623.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   20, Time: 21.3695s, gt_cnt:  47.0, et_cnt:  12.1 train_loss: 2168.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   40, Time: 35.4242s, gt_cnt:  38.0, et_cnt: 205.6 train_loss: 9362.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   50, Time: 19.1710s, gt_cnt:  62.0, et_cnt:  47.2 train_loss: 9839.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   60, Time: 21.4828s, gt_cnt: 560.0, et_cnt: 214.7 train_loss: 13136.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   70, Time: 13.2900s, gt_cnt:  76.0, et_cnt:  40.6 train_loss: 14878.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step   90, Time: 31.8544s, gt_cnt:  85.0, et_cnt:  55.4 train_loss: 17348.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  100, Time: 16.2785s, gt_cnt:  61.0, et_cnt:  31.6 train_loss: 17938.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  110, Time: 14.5198s, gt_cnt:  31.0, et_cnt:  54.5 train_loss: 20561.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  120, Time: 9.3333s, gt_cnt: 196.0, et_cnt:  70.4 train_loss: 22320.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  130, Time: 19.4919s, gt_cnt:  42.0, et_cnt: 109.1 train_loss: 23038.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  140, Time: 25.4941s, gt_cnt: 678.0, et_cnt: 261.5 train_loss: 30223.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  150, Time: 19.6524s, gt_cnt: 1622.0, et_cnt: 1501.2 train_loss: 33340.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  160, Time: 20.0874s, gt_cnt:  20.0, et_cnt:  19.4 train_loss: 35374.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  170, Time: 15.4291s, gt_cnt: 227.0, et_cnt: 174.5 train_loss: 36922.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  180, Time: 12.9843s, gt_cnt:  95.0, et_cnt: 149.4 train_loss: 39443.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   45, step  190, Time: 9.9230s, gt_cnt: 273.0, et_cnt: 184.7 train_loss: 41311.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step    0, Time: 11.1253s, gt_cnt:  40.0, et_cnt: 164.2 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   10, Time: 29.8670s, gt_cnt: 120.0, et_cnt:  47.7 train_loss: 1624.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   20, Time: 21.2070s, gt_cnt:  47.0, et_cnt:  60.6 train_loss: 2170.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   40, Time: 35.4256s, gt_cnt:  38.0, et_cnt: 263.4 train_loss: 9342.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   50, Time: 19.2383s, gt_cnt:  62.0, et_cnt:  48.5 train_loss: 9821.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   60, Time: 21.4969s, gt_cnt: 560.0, et_cnt: 182.1 train_loss: 13122.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   70, Time: 13.2855s, gt_cnt:  76.0, et_cnt:  48.4 train_loss: 14864.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step   90, Time: 32.1209s, gt_cnt:  85.0, et_cnt:  51.3 train_loss: 17331.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  100, Time: 16.8663s, gt_cnt:  61.0, et_cnt:  29.9 train_loss: 17920.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  110, Time: 14.5199s, gt_cnt:  31.0, et_cnt:  40.1 train_loss: 20542.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  120, Time: 9.3474s, gt_cnt: 196.0, et_cnt:  60.0 train_loss: 22301.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  130, Time: 19.5045s, gt_cnt:  42.0, et_cnt: 106.8 train_loss: 23016.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  140, Time: 25.5821s, gt_cnt: 678.0, et_cnt: 270.7 train_loss: 30193.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  150, Time: 19.5663s, gt_cnt: 1622.0, et_cnt: 1403.4 train_loss: 33309.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  160, Time: 20.1817s, gt_cnt:  20.0, et_cnt:  19.9 train_loss: 35341.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  170, Time: 15.5575s, gt_cnt: 227.0, et_cnt: 173.5 train_loss: 36888.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  180, Time: 13.0816s, gt_cnt:  95.0, et_cnt: 154.3 train_loss: 39406.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   46, step  190, Time: 10.0584s, gt_cnt: 273.0, et_cnt: 175.4 train_loss: 41273.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step    0, Time: 11.2183s, gt_cnt:  40.0, et_cnt: 155.5 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   10, Time: 29.8591s, gt_cnt: 120.0, et_cnt:  47.3 train_loss: 1623.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   20, Time: 21.1737s, gt_cnt:  47.0, et_cnt:  54.0 train_loss: 2168.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   40, Time: 35.2582s, gt_cnt:  38.0, et_cnt: 245.8 train_loss: 9338.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   50, Time: 19.3263s, gt_cnt:  62.0, et_cnt:  47.7 train_loss: 9817.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   60, Time: 21.5489s, gt_cnt: 560.0, et_cnt: 170.5 train_loss: 13115.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   70, Time: 13.2231s, gt_cnt:  76.0, et_cnt:  41.3 train_loss: 14856.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step   90, Time: 31.8751s, gt_cnt:  85.0, et_cnt:  50.0 train_loss: 17324.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  100, Time: 16.9341s, gt_cnt:  61.0, et_cnt:  27.5 train_loss: 17913.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  110, Time: 14.7016s, gt_cnt:  31.0, et_cnt:  40.2 train_loss: 20532.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  120, Time: 9.4130s, gt_cnt: 196.0, et_cnt:  63.3 train_loss: 22290.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  130, Time: 19.5472s, gt_cnt:  42.0, et_cnt: 109.1 train_loss: 23006.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  140, Time: 25.2173s, gt_cnt: 678.0, et_cnt: 278.7 train_loss: 30177.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  150, Time: 19.5152s, gt_cnt: 1622.0, et_cnt: 1508.8 train_loss: 33293.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  160, Time: 20.0160s, gt_cnt:  20.0, et_cnt:  18.4 train_loss: 35323.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  170, Time: 15.5962s, gt_cnt: 227.0, et_cnt: 163.9 train_loss: 36869.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  180, Time: 12.8990s, gt_cnt:  95.0, et_cnt: 150.5 train_loss: 39387.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   47, step  190, Time: 9.8923s, gt_cnt: 273.0, et_cnt: 179.9 train_loss: 41253.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step    0, Time: 11.1009s, gt_cnt:  40.0, et_cnt: 155.1 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   10, Time: 29.7624s, gt_cnt: 120.0, et_cnt:  46.4 train_loss: 1623.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   20, Time: 21.1450s, gt_cnt:  47.0, et_cnt:  52.3 train_loss: 2168.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   40, Time: 35.4243s, gt_cnt:  38.0, et_cnt: 241.2 train_loss: 9335.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   50, Time: 18.8934s, gt_cnt:  62.0, et_cnt:  48.5 train_loss: 9814.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   60, Time: 21.2182s, gt_cnt: 560.0, et_cnt: 160.2 train_loss: 13109.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   70, Time: 13.1937s, gt_cnt:  76.0, et_cnt:  38.6 train_loss: 14848.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step   90, Time: 32.0381s, gt_cnt:  85.0, et_cnt:  50.6 train_loss: 17316.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  100, Time: 16.8639s, gt_cnt:  61.0, et_cnt:  27.0 train_loss: 17904.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  110, Time: 14.6657s, gt_cnt:  31.0, et_cnt:  41.1 train_loss: 20522.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  120, Time: 9.3756s, gt_cnt: 196.0, et_cnt:  66.1 train_loss: 22279.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  130, Time: 19.4700s, gt_cnt:  42.0, et_cnt: 109.9 train_loss: 22996.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  140, Time: 25.4600s, gt_cnt: 678.0, et_cnt: 278.2 train_loss: 30163.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  150, Time: 19.5610s, gt_cnt: 1622.0, et_cnt: 1546.9 train_loss: 33278.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  160, Time: 20.1374s, gt_cnt:  20.0, et_cnt:  17.7 train_loss: 35308.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  170, Time: 15.4940s, gt_cnt: 227.0, et_cnt: 162.0 train_loss: 36854.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  180, Time: 12.9978s, gt_cnt:  95.0, et_cnt: 150.3 train_loss: 39370.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   48, step  190, Time: 9.9321s, gt_cnt: 273.0, et_cnt: 180.5 train_loss: 41236.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step    0, Time: 11.1084s, gt_cnt:  40.0, et_cnt: 155.5 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   10, Time: 29.9078s, gt_cnt: 120.0, et_cnt:  45.7 train_loss: 1623.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   20, Time: 21.2684s, gt_cnt:  47.0, et_cnt:  49.9 train_loss: 2168.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   40, Time: 35.3013s, gt_cnt:  38.0, et_cnt: 230.0 train_loss: 9332.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   50, Time: 19.5530s, gt_cnt:  62.0, et_cnt:  48.1 train_loss: 9811.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   60, Time: 21.5302s, gt_cnt: 560.0, et_cnt: 151.5 train_loss: 13104.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   70, Time: 13.3425s, gt_cnt:  76.0, et_cnt:  34.9 train_loss: 14842.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step   90, Time: 31.9959s, gt_cnt:  85.0, et_cnt:  53.0 train_loss: 17309.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  100, Time: 16.5598s, gt_cnt:  61.0, et_cnt:  27.7 train_loss: 17897.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   49, step  110, Time: 14.5488s, gt_cnt:  31.0, et_cnt:  45.1 train_loss: 20512.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  120, Time: 9.3768s, gt_cnt: 196.0, et_cnt:  71.6 train_loss: 22267.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  130, Time: 19.7476s, gt_cnt:  42.0, et_cnt: 110.4 train_loss: 22987.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  140, Time: 25.4509s, gt_cnt: 678.0, et_cnt: 273.9 train_loss: 30150.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  150, Time: 18.9995s, gt_cnt: 1622.0, et_cnt: 1619.1 train_loss: 33265.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  160, Time: 19.9501s, gt_cnt:  20.0, et_cnt:  16.8 train_loss: 35294.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  170, Time: 15.4334s, gt_cnt: 227.0, et_cnt: 152.2 train_loss: 36839.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  180, Time: 12.8928s, gt_cnt:  95.0, et_cnt: 148.6 train_loss: 39355.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   49, step  190, Time: 9.8670s, gt_cnt: 273.0, et_cnt: 188.8 train_loss: 41222.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step    0, Time: 11.0473s, gt_cnt:  40.0, et_cnt: 158.0 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   10, Time: 29.5737s, gt_cnt: 120.0, et_cnt:  43.4 train_loss: 1623.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   20, Time: 20.9545s, gt_cnt:  47.0, et_cnt:  46.1 train_loss: 2168.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   40, Time: 34.9398s, gt_cnt:  38.0, et_cnt: 220.3 train_loss: 9331.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   50, Time: 19.3672s, gt_cnt:  62.0, et_cnt:  47.5 train_loss: 9809.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   60, Time: 21.5704s, gt_cnt: 560.0, et_cnt: 142.2 train_loss: 13101.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   70, Time: 13.2508s, gt_cnt:  76.0, et_cnt:  32.2 train_loss: 14838.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step   90, Time: 32.1347s, gt_cnt:  85.0, et_cnt:  55.5 train_loss: 17305.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  100, Time: 16.7922s, gt_cnt:  61.0, et_cnt:  30.1 train_loss: 17893.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  110, Time: 14.4704s, gt_cnt:  31.0, et_cnt:  48.6 train_loss: 20506.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  120, Time: 9.3246s, gt_cnt: 196.0, et_cnt:  74.5 train_loss: 22260.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  130, Time: 19.6728s, gt_cnt:  42.0, et_cnt: 109.7 train_loss: 22981.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  140, Time: 25.5336s, gt_cnt: 678.0, et_cnt: 271.4 train_loss: 30139.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  150, Time: 19.5348s, gt_cnt: 1622.0, et_cnt: 1618.0 train_loss: 33252.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  160, Time: 20.0324s, gt_cnt:  20.0, et_cnt:  16.6 train_loss: 35281.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  170, Time: 15.5089s, gt_cnt: 227.0, et_cnt: 160.2 train_loss: 36825.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  180, Time: 13.0064s, gt_cnt:  95.0, et_cnt: 147.8 train_loss: 39340.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   50, step  190, Time: 9.8795s, gt_cnt: 273.0, et_cnt: 187.8 train_loss: 41204.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step    0, Time: 11.0262s, gt_cnt:  40.0, et_cnt: 166.7 train_loss: 44.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   10, Time: 29.5588s, gt_cnt: 120.0, et_cnt:  46.2 train_loss: 1624.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   20, Time: 20.9784s, gt_cnt:  47.0, et_cnt:  45.5 train_loss: 2169.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   40, Time: 34.9565s, gt_cnt:  38.0, et_cnt: 207.9 train_loss: 9328.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   50, Time: 19.5760s, gt_cnt:  62.0, et_cnt:  44.5 train_loss: 9806.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   60, Time: 21.5341s, gt_cnt: 560.0, et_cnt: 130.4 train_loss: 13097.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   70, Time: 13.2117s, gt_cnt:  76.0, et_cnt:  33.1 train_loss: 14833.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step   90, Time: 32.1630s, gt_cnt:  85.0, et_cnt:  55.8 train_loss: 17300.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  100, Time: 16.6386s, gt_cnt:  61.0, et_cnt:  30.5 train_loss: 17889.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  110, Time: 14.6887s, gt_cnt:  31.0, et_cnt:  50.2 train_loss: 20500.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  120, Time: 9.3833s, gt_cnt: 196.0, et_cnt:  75.9 train_loss: 22253.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  130, Time: 19.7389s, gt_cnt:  42.0, et_cnt: 109.5 train_loss: 22975.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  140, Time: 25.5841s, gt_cnt: 678.0, et_cnt: 266.4 train_loss: 30128.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  150, Time: 19.5717s, gt_cnt: 1622.0, et_cnt: 1617.8 train_loss: 33241.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  160, Time: 19.9852s, gt_cnt:  20.0, et_cnt:  16.5 train_loss: 35269.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  170, Time: 15.4889s, gt_cnt: 227.0, et_cnt: 164.9 train_loss: 36813.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  180, Time: 12.9805s, gt_cnt:  95.0, et_cnt: 148.7 train_loss: 39325.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   51, step  190, Time: 9.9891s, gt_cnt: 273.0, et_cnt: 191.8 train_loss: 41189.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step    0, Time: 11.1483s, gt_cnt:  40.0, et_cnt: 175.5 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   10, Time: 30.1903s, gt_cnt: 120.0, et_cnt:  47.9 train_loss: 1624.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   20, Time: 21.3962s, gt_cnt:  47.0, et_cnt:  46.5 train_loss: 2169.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   40, Time: 35.5694s, gt_cnt:  38.0, et_cnt: 199.0 train_loss: 9325.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   50, Time: 19.5314s, gt_cnt:  62.0, et_cnt:  43.0 train_loss: 9803.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   60, Time: 21.5668s, gt_cnt: 560.0, et_cnt: 121.6 train_loss: 13093.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   70, Time: 13.3640s, gt_cnt:  76.0, et_cnt:  34.4 train_loss: 14829.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step   90, Time: 32.2466s, gt_cnt:  85.0, et_cnt:  55.8 train_loss: 17295.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  100, Time: 16.2972s, gt_cnt:  61.0, et_cnt:  29.4 train_loss: 17883.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  110, Time: 14.6011s, gt_cnt:  31.0, et_cnt:  52.7 train_loss: 20494.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  120, Time: 9.3757s, gt_cnt: 196.0, et_cnt:  78.6 train_loss: 22245.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  130, Time: 19.5982s, gt_cnt:  42.0, et_cnt: 109.1 train_loss: 22968.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  140, Time: 25.6875s, gt_cnt: 678.0, et_cnt: 266.4 train_loss: 30114.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  150, Time: 19.7968s, gt_cnt: 1622.0, et_cnt: 1668.6 train_loss: 33228.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  160, Time: 20.0076s, gt_cnt:  20.0, et_cnt:  15.7 train_loss: 35254.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  170, Time: 15.4110s, gt_cnt: 227.0, et_cnt: 157.3 train_loss: 36798.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  180, Time: 13.0148s, gt_cnt:  95.0, et_cnt: 145.9 train_loss: 39310.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   52, step  190, Time: 9.9614s, gt_cnt: 273.0, et_cnt: 202.0 train_loss: 41172.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step    0, Time: 11.1738s, gt_cnt:  40.0, et_cnt: 177.4 train_loss: 44.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   10, Time: 30.2093s, gt_cnt: 120.0, et_cnt:  47.1 train_loss: 1624.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   20, Time: 21.3542s, gt_cnt:  47.0, et_cnt:  44.0 train_loss: 2169.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   40, Time: 35.6669s, gt_cnt:  38.0, et_cnt: 196.0 train_loss: 9322.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   50, Time: 19.3626s, gt_cnt:  62.0, et_cnt:  44.5 train_loss: 9799.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   60, Time: 21.5610s, gt_cnt: 560.0, et_cnt: 126.4 train_loss: 13089.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   70, Time: 13.2968s, gt_cnt:  76.0, et_cnt:  27.3 train_loss: 14823.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step   90, Time: 32.2616s, gt_cnt:  85.0, et_cnt:  55.2 train_loss: 17287.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  100, Time: 16.7838s, gt_cnt:  61.0, et_cnt:  29.7 train_loss: 17876.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  110, Time: 14.5962s, gt_cnt:  31.0, et_cnt:  52.5 train_loss: 20482.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  120, Time: 9.3959s, gt_cnt: 196.0, et_cnt:  81.1 train_loss: 22232.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  130, Time: 19.4165s, gt_cnt:  42.0, et_cnt: 107.4 train_loss: 22956.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  140, Time: 25.2090s, gt_cnt: 678.0, et_cnt: 264.1 train_loss: 30096.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  150, Time: 19.3009s, gt_cnt: 1622.0, et_cnt: 1674.9 train_loss: 33208.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  160, Time: 19.9041s, gt_cnt:  20.0, et_cnt:  15.6 train_loss: 35234.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  170, Time: 15.4045s, gt_cnt: 227.0, et_cnt: 161.4 train_loss: 36776.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  180, Time: 12.9549s, gt_cnt:  95.0, et_cnt: 146.8 train_loss: 39285.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   53, step  190, Time: 9.8881s, gt_cnt: 273.0, et_cnt: 194.8 train_loss: 41146.8\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   54, step    0, Time: 11.0263s, gt_cnt:  40.0, et_cnt: 178.9 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   10, Time: 29.7842s, gt_cnt: 120.0, et_cnt:  49.1 train_loss: 1624.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   20, Time: 21.0739s, gt_cnt:  47.0, et_cnt:  44.6 train_loss: 2169.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   40, Time: 35.0639s, gt_cnt:  38.0, et_cnt: 199.4 train_loss: 9316.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   50, Time: 18.9685s, gt_cnt:  62.0, et_cnt:  42.2 train_loss: 9794.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   60, Time: 21.4421s, gt_cnt: 560.0, et_cnt: 115.4 train_loss: 13084.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   70, Time: 13.3806s, gt_cnt:  76.0, et_cnt:  32.9 train_loss: 14820.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step   90, Time: 32.1790s, gt_cnt:  85.0, et_cnt:  53.8 train_loss: 17284.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  100, Time: 16.6517s, gt_cnt:  61.0, et_cnt:  28.3 train_loss: 17872.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  110, Time: 14.6987s, gt_cnt:  31.0, et_cnt:  55.4 train_loss: 20480.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  120, Time: 9.3575s, gt_cnt: 196.0, et_cnt:  82.6 train_loss: 22230.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  130, Time: 19.5173s, gt_cnt:  42.0, et_cnt: 109.5 train_loss: 22954.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  140, Time: 25.2550s, gt_cnt: 678.0, et_cnt: 264.9 train_loss: 30089.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  150, Time: 19.6594s, gt_cnt: 1622.0, et_cnt: 1642.4 train_loss: 33200.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  160, Time: 19.8191s, gt_cnt:  20.0, et_cnt:  15.5 train_loss: 35224.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  170, Time: 15.2667s, gt_cnt: 227.0, et_cnt: 161.9 train_loss: 36766.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  180, Time: 12.9339s, gt_cnt:  95.0, et_cnt: 147.2 train_loss: 39274.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   54, step  190, Time: 9.8817s, gt_cnt: 273.0, et_cnt: 194.8 train_loss: 41134.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step    0, Time: 11.0156s, gt_cnt:  40.0, et_cnt: 169.0 train_loss: 44.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   10, Time: 29.5054s, gt_cnt: 120.0, et_cnt:  48.1 train_loss: 1624.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   20, Time: 20.9860s, gt_cnt:  47.0, et_cnt:  42.1 train_loss: 2169.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   40, Time: 35.0415s, gt_cnt:  38.0, et_cnt: 202.6 train_loss: 9313.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   50, Time: 18.8774s, gt_cnt:  62.0, et_cnt:  44.1 train_loss: 9792.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   60, Time: 21.6021s, gt_cnt: 560.0, et_cnt: 120.4 train_loss: 13080.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   70, Time: 13.2096s, gt_cnt:  76.0, et_cnt:  24.3 train_loss: 14814.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step   90, Time: 32.1060s, gt_cnt:  85.0, et_cnt:  52.7 train_loss: 17276.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  100, Time: 16.9310s, gt_cnt:  61.0, et_cnt:  27.7 train_loss: 17864.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  110, Time: 14.6741s, gt_cnt:  31.0, et_cnt:  52.3 train_loss: 20467.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  120, Time: 9.3728s, gt_cnt: 196.0, et_cnt:  84.2 train_loss: 22216.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  130, Time: 19.4322s, gt_cnt:  42.0, et_cnt: 105.8 train_loss: 22940.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  140, Time: 25.0785s, gt_cnt: 678.0, et_cnt: 263.4 train_loss: 30069.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  150, Time: 19.5250s, gt_cnt: 1622.0, et_cnt: 1678.8 train_loss: 33179.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  160, Time: 19.9435s, gt_cnt:  20.0, et_cnt:  15.3 train_loss: 35202.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  170, Time: 15.4399s, gt_cnt: 227.0, et_cnt: 160.6 train_loss: 36743.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  180, Time: 12.8709s, gt_cnt:  95.0, et_cnt: 147.0 train_loss: 39249.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   55, step  190, Time: 9.8848s, gt_cnt: 273.0, et_cnt: 193.4 train_loss: 41107.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step    0, Time: 11.0746s, gt_cnt:  40.0, et_cnt: 173.7 train_loss: 44.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   10, Time: 29.8909s, gt_cnt: 120.0, et_cnt:  51.8 train_loss: 1624.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   20, Time: 21.2380s, gt_cnt:  47.0, et_cnt:  46.6 train_loss: 2168.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   40, Time: 35.4371s, gt_cnt:  38.0, et_cnt: 198.6 train_loss: 9311.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   50, Time: 19.2904s, gt_cnt:  62.0, et_cnt:  43.6 train_loss: 9788.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   60, Time: 21.5897s, gt_cnt: 560.0, et_cnt: 114.5 train_loss: 13076.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   70, Time: 13.3576s, gt_cnt:  76.0, et_cnt:  29.7 train_loss: 14811.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step   90, Time: 32.2836s, gt_cnt:  85.0, et_cnt:  52.7 train_loss: 17272.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  100, Time: 16.4407s, gt_cnt:  61.0, et_cnt:  27.0 train_loss: 17860.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  110, Time: 14.6330s, gt_cnt:  31.0, et_cnt:  54.8 train_loss: 20462.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  120, Time: 9.3967s, gt_cnt: 196.0, et_cnt:  86.0 train_loss: 22209.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  130, Time: 19.8666s, gt_cnt:  42.0, et_cnt: 102.0 train_loss: 22935.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  140, Time: 25.7589s, gt_cnt: 678.0, et_cnt: 256.5 train_loss: 30058.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  150, Time: 19.8019s, gt_cnt: 1622.0, et_cnt: 1816.1 train_loss: 33169.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  160, Time: 19.9543s, gt_cnt:  20.0, et_cnt:  13.8 train_loss: 35191.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  170, Time: 15.2982s, gt_cnt: 227.0, et_cnt: 155.5 train_loss: 36732.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  180, Time: 12.7246s, gt_cnt:  95.0, et_cnt: 139.8 train_loss: 39239.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   56, step  190, Time: 9.7991s, gt_cnt: 273.0, et_cnt: 214.1 train_loss: 41098.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step    0, Time: 10.9723s, gt_cnt:  40.0, et_cnt: 185.4 train_loss: 44.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   10, Time: 29.4915s, gt_cnt: 120.0, et_cnt:  51.4 train_loss: 1624.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   20, Time: 20.7609s, gt_cnt:  47.0, et_cnt:  44.0 train_loss: 2169.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   40, Time: 34.8468s, gt_cnt:  38.0, et_cnt: 194.5 train_loss: 9309.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   50, Time: 19.1012s, gt_cnt:  62.0, et_cnt:  44.3 train_loss: 9787.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   60, Time: 21.4918s, gt_cnt: 560.0, et_cnt: 113.9 train_loss: 13073.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   70, Time: 13.2021s, gt_cnt:  76.0, et_cnt:  27.4 train_loss: 14806.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step   90, Time: 31.8288s, gt_cnt:  85.0, et_cnt:  80.3 train_loss: 17278.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  100, Time: 16.4796s, gt_cnt:  61.0, et_cnt:  65.9 train_loss: 17868.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  110, Time: 14.6929s, gt_cnt:  31.0, et_cnt:  80.5 train_loss: 20447.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  120, Time: 9.3780s, gt_cnt: 196.0, et_cnt:  85.2 train_loss: 22190.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  130, Time: 19.6391s, gt_cnt:  42.0, et_cnt:  84.4 train_loss: 22909.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  140, Time: 25.5459s, gt_cnt: 678.0, et_cnt: 248.5 train_loss: 30023.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  150, Time: 19.7785s, gt_cnt: 1622.0, et_cnt: 1805.1 train_loss: 33142.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  160, Time: 19.9475s, gt_cnt:  20.0, et_cnt:  14.0 train_loss: 35166.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  170, Time: 15.4577s, gt_cnt: 227.0, et_cnt: 135.9 train_loss: 36704.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  180, Time: 12.9698s, gt_cnt:  95.0, et_cnt: 143.7 train_loss: 39211.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   57, step  190, Time: 9.9574s, gt_cnt: 273.0, et_cnt: 185.8 train_loss: 41070.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step    0, Time: 11.1612s, gt_cnt:  40.0, et_cnt: 156.9 train_loss: 44.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   10, Time: 29.7709s, gt_cnt: 120.0, et_cnt:  50.3 train_loss: 1624.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   20, Time: 21.0009s, gt_cnt:  47.0, et_cnt:  39.7 train_loss: 2169.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   40, Time: 35.1307s, gt_cnt:  38.0, et_cnt: 242.1 train_loss: 9305.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   50, Time: 19.3692s, gt_cnt:  62.0, et_cnt:  30.0 train_loss: 9784.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   60, Time: 21.3588s, gt_cnt: 560.0, et_cnt: 108.0 train_loss: 13066.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   70, Time: 13.1285s, gt_cnt:  76.0, et_cnt:  33.5 train_loss: 14804.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step   90, Time: 31.9990s, gt_cnt:  85.0, et_cnt:  44.2 train_loss: 17264.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  100, Time: 16.7900s, gt_cnt:  61.0, et_cnt:  20.3 train_loss: 17851.6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   58, step  110, Time: 14.6470s, gt_cnt:  31.0, et_cnt:  43.4 train_loss: 20452.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  120, Time: 9.3640s, gt_cnt: 196.0, et_cnt:  82.6 train_loss: 22198.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  130, Time: 19.4020s, gt_cnt:  42.0, et_cnt: 104.6 train_loss: 22924.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  140, Time: 25.3409s, gt_cnt: 678.0, et_cnt: 259.8 train_loss: 30031.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  150, Time: 19.4358s, gt_cnt: 1622.0, et_cnt: 1695.2 train_loss: 33139.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  160, Time: 19.9187s, gt_cnt:  20.0, et_cnt:  13.7 train_loss: 35161.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  170, Time: 15.2883s, gt_cnt: 227.0, et_cnt: 158.1 train_loss: 36700.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  180, Time: 13.0136s, gt_cnt:  95.0, et_cnt: 143.0 train_loss: 39204.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   58, step  190, Time: 9.9386s, gt_cnt: 273.0, et_cnt: 203.6 train_loss: 41059.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step    0, Time: 11.1148s, gt_cnt:  40.0, et_cnt: 167.9 train_loss: 44.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   10, Time: 29.9310s, gt_cnt: 120.0, et_cnt:  47.4 train_loss: 1624.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   20, Time: 21.2000s, gt_cnt:  47.0, et_cnt:  42.9 train_loss: 2169.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   40, Time: 35.4899s, gt_cnt:  38.0, et_cnt: 188.1 train_loss: 9301.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   50, Time: 18.8077s, gt_cnt:  62.0, et_cnt:  43.7 train_loss: 9779.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   60, Time: 21.4697s, gt_cnt: 560.0, et_cnt: 101.3 train_loss: 13065.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   70, Time: 13.2611s, gt_cnt:  76.0, et_cnt:  30.5 train_loss: 14798.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step   90, Time: 32.0422s, gt_cnt:  85.0, et_cnt:  51.9 train_loss: 17256.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  100, Time: 16.4402s, gt_cnt:  61.0, et_cnt:  25.8 train_loss: 17844.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  110, Time: 14.5563s, gt_cnt:  31.0, et_cnt:  60.3 train_loss: 20439.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  120, Time: 9.3720s, gt_cnt: 196.0, et_cnt:  88.5 train_loss: 22182.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  130, Time: 19.4101s, gt_cnt:  42.0, et_cnt:  97.7 train_loss: 22909.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  140, Time: 25.6399s, gt_cnt: 678.0, et_cnt: 247.2 train_loss: 30010.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  150, Time: 19.5887s, gt_cnt: 1622.0, et_cnt: 1843.7 train_loss: 33119.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  160, Time: 20.1402s, gt_cnt:  20.0, et_cnt:  13.3 train_loss: 35139.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  170, Time: 15.3894s, gt_cnt: 227.0, et_cnt: 148.8 train_loss: 36677.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  180, Time: 12.9656s, gt_cnt:  95.0, et_cnt: 133.5 train_loss: 39183.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   59, step  190, Time: 9.9300s, gt_cnt: 273.0, et_cnt: 216.6 train_loss: 41038.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step    0, Time: 11.1069s, gt_cnt:  40.0, et_cnt: 175.7 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   10, Time: 29.6889s, gt_cnt: 120.0, et_cnt:  48.7 train_loss: 1625.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   20, Time: 21.2376s, gt_cnt:  47.0, et_cnt:  42.5 train_loss: 2170.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   40, Time: 35.3376s, gt_cnt:  38.0, et_cnt: 187.7 train_loss: 9299.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   50, Time: 19.2350s, gt_cnt:  62.0, et_cnt:  45.3 train_loss: 9777.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   60, Time: 21.4792s, gt_cnt: 560.0, et_cnt: 111.6 train_loss: 13060.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   70, Time: 13.2410s, gt_cnt:  76.0, et_cnt:  25.5 train_loss: 14792.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step   90, Time: 32.2593s, gt_cnt:  85.0, et_cnt:  58.2 train_loss: 17247.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  100, Time: 16.1652s, gt_cnt:  61.0, et_cnt:  28.0 train_loss: 17834.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  110, Time: 14.5764s, gt_cnt:  31.0, et_cnt:  61.8 train_loss: 20424.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  120, Time: 9.3799s, gt_cnt: 196.0, et_cnt:  91.8 train_loss: 22166.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  130, Time: 19.3817s, gt_cnt:  42.0, et_cnt:  96.0 train_loss: 22894.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  140, Time: 25.5681s, gt_cnt: 678.0, et_cnt: 242.3 train_loss: 29986.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  150, Time: 19.5496s, gt_cnt: 1622.0, et_cnt: 1818.8 train_loss: 33094.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  160, Time: 20.0005s, gt_cnt:  20.0, et_cnt:  13.1 train_loss: 35113.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  170, Time: 15.3412s, gt_cnt: 227.0, et_cnt: 151.8 train_loss: 36650.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  180, Time: 12.9277s, gt_cnt:  95.0, et_cnt: 132.6 train_loss: 39154.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   60, step  190, Time: 9.9360s, gt_cnt: 273.0, et_cnt: 213.5 train_loss: 41007.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step    0, Time: 11.1401s, gt_cnt:  40.0, et_cnt: 175.6 train_loss: 45.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   10, Time: 30.0059s, gt_cnt: 120.0, et_cnt:  48.2 train_loss: 1625.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   20, Time: 21.2726s, gt_cnt:  47.0, et_cnt:  41.5 train_loss: 2170.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   40, Time: 35.4374s, gt_cnt:  38.0, et_cnt: 182.0 train_loss: 9293.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   50, Time: 18.9643s, gt_cnt:  62.0, et_cnt:  42.7 train_loss: 9771.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   60, Time: 21.4957s, gt_cnt: 560.0, et_cnt:  97.0 train_loss: 13056.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   70, Time: 13.3361s, gt_cnt:  76.0, et_cnt:  32.8 train_loss: 14788.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step   90, Time: 32.1900s, gt_cnt:  85.0, et_cnt:  52.9 train_loss: 17244.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  100, Time: 16.6065s, gt_cnt:  61.0, et_cnt:  25.8 train_loss: 17831.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  110, Time: 14.5401s, gt_cnt:  31.0, et_cnt:  61.7 train_loss: 20422.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  120, Time: 9.3480s, gt_cnt: 196.0, et_cnt:  92.2 train_loss: 22164.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  130, Time: 19.3036s, gt_cnt:  42.0, et_cnt: 100.1 train_loss: 22892.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  140, Time: 25.4875s, gt_cnt: 678.0, et_cnt: 245.8 train_loss: 29977.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  150, Time: 19.7623s, gt_cnt: 1622.0, et_cnt: 1787.6 train_loss: 33083.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  160, Time: 19.9812s, gt_cnt:  20.0, et_cnt:  13.4 train_loss: 35102.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  170, Time: 15.4293s, gt_cnt: 227.0, et_cnt: 151.9 train_loss: 36639.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  180, Time: 12.9926s, gt_cnt:  95.0, et_cnt: 132.0 train_loss: 39142.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   61, step  190, Time: 9.9330s, gt_cnt: 273.0, et_cnt: 209.9 train_loss: 40994.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step    0, Time: 11.1159s, gt_cnt:  40.0, et_cnt: 171.6 train_loss: 45.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   10, Time: 29.9168s, gt_cnt: 120.0, et_cnt:  47.3 train_loss: 1626.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   20, Time: 21.2927s, gt_cnt:  47.0, et_cnt:  41.3 train_loss: 2170.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   40, Time: 35.4098s, gt_cnt:  38.0, et_cnt: 183.8 train_loss: 9288.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   50, Time: 19.1537s, gt_cnt:  62.0, et_cnt:  48.2 train_loss: 9767.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   60, Time: 21.4691s, gt_cnt: 560.0, et_cnt: 128.2 train_loss: 13049.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   70, Time: 13.2407s, gt_cnt:  76.0, et_cnt:  11.9 train_loss: 14778.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step   90, Time: 32.2004s, gt_cnt:  85.0, et_cnt:  59.3 train_loss: 17230.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  100, Time: 16.8928s, gt_cnt:  61.0, et_cnt:  29.7 train_loss: 17817.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  110, Time: 14.6104s, gt_cnt:  31.0, et_cnt:  57.1 train_loss: 20395.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  120, Time: 9.3730s, gt_cnt: 196.0, et_cnt:  95.6 train_loss: 22134.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  130, Time: 19.5882s, gt_cnt:  42.0, et_cnt:  90.2 train_loss: 22862.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  140, Time: 25.5141s, gt_cnt: 678.0, et_cnt: 241.5 train_loss: 29938.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  150, Time: 19.7304s, gt_cnt: 1622.0, et_cnt: 1833.3 train_loss: 33046.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  160, Time: 19.9755s, gt_cnt:  20.0, et_cnt:  12.6 train_loss: 35064.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  170, Time: 15.4760s, gt_cnt: 227.0, et_cnt: 145.7 train_loss: 36598.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  180, Time: 13.0537s, gt_cnt:  95.0, et_cnt: 130.0 train_loss: 39101.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   62, step  190, Time: 9.9045s, gt_cnt: 273.0, et_cnt: 213.6 train_loss: 40952.3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   63, step    0, Time: 11.0612s, gt_cnt:  40.0, et_cnt: 171.9 train_loss: 45.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   10, Time: 29.5899s, gt_cnt: 120.0, et_cnt:  45.9 train_loss: 1626.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   20, Time: 20.9983s, gt_cnt:  47.0, et_cnt:  39.4 train_loss: 2170.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   40, Time: 34.9137s, gt_cnt:  38.0, et_cnt: 183.8 train_loss: 9287.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   50, Time: 19.1064s, gt_cnt:  62.0, et_cnt:  47.4 train_loss: 9766.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   60, Time: 21.5362s, gt_cnt: 560.0, et_cnt: 122.7 train_loss: 13047.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   70, Time: 13.2825s, gt_cnt:  76.0, et_cnt:  13.9 train_loss: 14776.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step   90, Time: 32.0152s, gt_cnt:  85.0, et_cnt:  61.3 train_loss: 17228.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  100, Time: 16.8272s, gt_cnt:  61.0, et_cnt:  29.9 train_loss: 17815.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  110, Time: 14.5351s, gt_cnt:  31.0, et_cnt:  58.9 train_loss: 20392.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  120, Time: 9.3715s, gt_cnt: 196.0, et_cnt:  96.6 train_loss: 22131.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  130, Time: 19.7075s, gt_cnt:  42.0, et_cnt:  90.9 train_loss: 22859.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  140, Time: 25.5145s, gt_cnt: 678.0, et_cnt: 240.1 train_loss: 29927.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  150, Time: 19.6863s, gt_cnt: 1622.0, et_cnt: 1770.9 train_loss: 33030.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  160, Time: 20.0235s, gt_cnt:  20.0, et_cnt:  13.1 train_loss: 35049.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  170, Time: 15.4864s, gt_cnt: 227.0, et_cnt: 152.9 train_loss: 36583.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  180, Time: 12.9150s, gt_cnt:  95.0, et_cnt: 133.2 train_loss: 39082.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   63, step  190, Time: 9.9381s, gt_cnt: 273.0, et_cnt: 201.4 train_loss: 40932.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step    0, Time: 11.1275s, gt_cnt:  40.0, et_cnt: 161.3 train_loss: 44.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   10, Time: 29.5373s, gt_cnt: 120.0, et_cnt:  45.7 train_loss: 1624.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   20, Time: 20.9061s, gt_cnt:  47.0, et_cnt:  24.6 train_loss: 2168.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   40, Time: 34.7703s, gt_cnt:  38.0, et_cnt: 173.2 train_loss: 9286.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   50, Time: 18.8999s, gt_cnt:  62.0, et_cnt:  41.8 train_loss: 9765.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   60, Time: 21.5947s, gt_cnt: 560.0, et_cnt:  90.4 train_loss: 13049.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   70, Time: 13.3412s, gt_cnt:  76.0, et_cnt:  31.8 train_loss: 14781.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step   90, Time: 31.8368s, gt_cnt:  85.0, et_cnt:  55.9 train_loss: 17233.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  100, Time: 16.5774s, gt_cnt:  61.0, et_cnt:  26.3 train_loss: 17821.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  110, Time: 14.7066s, gt_cnt:  31.0, et_cnt:  66.9 train_loss: 20404.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  120, Time: 9.4057s, gt_cnt: 196.0, et_cnt:  96.1 train_loss: 22143.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  130, Time: 19.4509s, gt_cnt:  42.0, et_cnt:  99.3 train_loss: 22873.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  140, Time: 25.0629s, gt_cnt: 678.0, et_cnt: 241.2 train_loss: 29934.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  150, Time: 19.2742s, gt_cnt: 1622.0, et_cnt: 1704.8 train_loss: 33036.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  160, Time: 19.7904s, gt_cnt:  20.0, et_cnt:  13.2 train_loss: 35054.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  170, Time: 15.5269s, gt_cnt: 227.0, et_cnt: 140.2 train_loss: 36589.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  180, Time: 12.9513s, gt_cnt:  95.0, et_cnt: 132.9 train_loss: 39087.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   64, step  190, Time: 9.9066s, gt_cnt: 273.0, et_cnt: 198.4 train_loss: 40937.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step    0, Time: 11.1215s, gt_cnt:  40.0, et_cnt: 146.5 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   10, Time: 30.1864s, gt_cnt: 120.0, et_cnt:  46.2 train_loss: 1624.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   20, Time: 21.3036s, gt_cnt:  47.0, et_cnt:  38.5 train_loss: 2168.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   40, Time: 35.5788s, gt_cnt:  38.0, et_cnt: 177.5 train_loss: 9272.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   50, Time: 18.8261s, gt_cnt:  62.0, et_cnt:  46.5 train_loss: 9752.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   60, Time: 21.3717s, gt_cnt: 560.0, et_cnt: 112.4 train_loss: 13034.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   70, Time: 13.2992s, gt_cnt:  76.0, et_cnt:  14.1 train_loss: 14762.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step   90, Time: 31.9946s, gt_cnt:  85.0, et_cnt:  54.1 train_loss: 17211.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  100, Time: 16.3670s, gt_cnt:  61.0, et_cnt:  26.0 train_loss: 17798.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  110, Time: 14.6979s, gt_cnt:  31.0, et_cnt:  61.0 train_loss: 20372.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  120, Time: 9.4240s, gt_cnt: 196.0, et_cnt: 101.2 train_loss: 22109.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  130, Time: 19.3064s, gt_cnt:  42.0, et_cnt:  88.7 train_loss: 22837.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  140, Time: 25.5643s, gt_cnt: 678.0, et_cnt: 236.8 train_loss: 29890.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  150, Time: 19.6001s, gt_cnt: 1622.0, et_cnt: 1766.7 train_loss: 32992.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  160, Time: 19.9195s, gt_cnt:  20.0, et_cnt:  12.6 train_loss: 35009.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  170, Time: 15.3747s, gt_cnt: 227.0, et_cnt: 143.9 train_loss: 36541.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  180, Time: 13.0345s, gt_cnt:  95.0, et_cnt: 131.5 train_loss: 39038.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   65, step  190, Time: 9.9282s, gt_cnt: 273.0, et_cnt: 204.2 train_loss: 40886.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step    0, Time: 11.1440s, gt_cnt:  40.0, et_cnt: 144.0 train_loss: 44.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   10, Time: 30.1178s, gt_cnt: 120.0, et_cnt:  45.1 train_loss: 1625.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   20, Time: 21.4103s, gt_cnt:  47.0, et_cnt:  40.1 train_loss: 2168.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   40, Time: 35.7134s, gt_cnt:  38.0, et_cnt: 179.8 train_loss: 9271.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   50, Time: 19.6125s, gt_cnt:  62.0, et_cnt:  46.3 train_loss: 9751.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   60, Time: 21.4880s, gt_cnt: 560.0, et_cnt: 105.8 train_loss: 13030.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   70, Time: 13.2662s, gt_cnt:  76.0, et_cnt:  18.1 train_loss: 14758.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step   90, Time: 32.2638s, gt_cnt:  85.0, et_cnt:  60.6 train_loss: 17205.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  100, Time: 16.7146s, gt_cnt:  61.0, et_cnt:  28.2 train_loss: 17792.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  110, Time: 14.5891s, gt_cnt:  31.0, et_cnt:  57.7 train_loss: 20362.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  120, Time: 9.3849s, gt_cnt: 196.0, et_cnt:  99.9 train_loss: 22097.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  130, Time: 19.4791s, gt_cnt:  42.0, et_cnt:  88.4 train_loss: 22825.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  140, Time: 25.5153s, gt_cnt: 678.0, et_cnt: 242.1 train_loss: 29870.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  150, Time: 19.8173s, gt_cnt: 1622.0, et_cnt: 1883.4 train_loss: 32973.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  160, Time: 19.9703s, gt_cnt:  20.0, et_cnt:  10.8 train_loss: 34988.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  170, Time: 15.3799s, gt_cnt: 227.0, et_cnt: 133.8 train_loss: 36521.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  180, Time: 13.0102s, gt_cnt:  95.0, et_cnt: 126.2 train_loss: 39022.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   66, step  190, Time: 9.9481s, gt_cnt: 273.0, et_cnt: 203.4 train_loss: 40868.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step    0, Time: 11.1569s, gt_cnt:  40.0, et_cnt: 145.9 train_loss: 44.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   10, Time: 30.0499s, gt_cnt: 120.0, et_cnt:  41.6 train_loss: 1626.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   20, Time: 21.2331s, gt_cnt:  47.0, et_cnt:  36.9 train_loss: 2169.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   40, Time: 35.6582s, gt_cnt:  38.0, et_cnt: 188.6 train_loss: 9273.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   50, Time: 19.2250s, gt_cnt:  62.0, et_cnt:  50.8 train_loss: 9754.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   60, Time: 21.4995s, gt_cnt: 560.0, et_cnt: 112.6 train_loss: 13042.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   70, Time: 13.3214s, gt_cnt:  76.0, et_cnt:  11.8 train_loss: 14770.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step   90, Time: 32.0631s, gt_cnt:  85.0, et_cnt:  52.5 train_loss: 17220.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  100, Time: 16.7876s, gt_cnt:  61.0, et_cnt:  29.6 train_loss: 17807.7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   67, step  110, Time: 14.5335s, gt_cnt:  31.0, et_cnt:  67.0 train_loss: 20368.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  120, Time: 9.3543s, gt_cnt: 196.0, et_cnt: 101.5 train_loss: 22104.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  130, Time: 19.4243s, gt_cnt:  42.0, et_cnt:  81.2 train_loss: 22830.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  140, Time: 25.5727s, gt_cnt: 678.0, et_cnt: 240.6 train_loss: 29870.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  150, Time: 19.6704s, gt_cnt: 1622.0, et_cnt: 1847.5 train_loss: 32972.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  160, Time: 19.9500s, gt_cnt:  20.0, et_cnt:  11.8 train_loss: 34990.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  170, Time: 15.4381s, gt_cnt: 227.0, et_cnt: 149.5 train_loss: 36521.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  180, Time: 12.9547s, gt_cnt:  95.0, et_cnt: 125.3 train_loss: 39021.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   67, step  190, Time: 9.9632s, gt_cnt: 273.0, et_cnt: 199.4 train_loss: 40869.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step    0, Time: 11.1897s, gt_cnt:  40.0, et_cnt: 149.3 train_loss: 45.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   10, Time: 30.0019s, gt_cnt: 120.0, et_cnt:  42.8 train_loss: 1626.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   20, Time: 21.3491s, gt_cnt:  47.0, et_cnt:  40.5 train_loss: 2169.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   40, Time: 35.5928s, gt_cnt:  38.0, et_cnt: 173.7 train_loss: 9267.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   50, Time: 19.4661s, gt_cnt:  62.0, et_cnt:  50.1 train_loss: 9747.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   60, Time: 21.5089s, gt_cnt: 560.0, et_cnt: 141.3 train_loss: 13025.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   70, Time: 13.3039s, gt_cnt:  76.0, et_cnt:  12.3 train_loss: 14750.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step   90, Time: 32.3030s, gt_cnt:  85.0, et_cnt:  59.0 train_loss: 17194.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  100, Time: 16.8096s, gt_cnt:  61.0, et_cnt:  29.8 train_loss: 17781.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  110, Time: 14.5465s, gt_cnt:  31.0, et_cnt:  52.6 train_loss: 20340.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  120, Time: 9.3828s, gt_cnt: 196.0, et_cnt: 102.3 train_loss: 22072.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  130, Time: 19.7756s, gt_cnt:  42.0, et_cnt:  82.6 train_loss: 22800.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  140, Time: 25.5486s, gt_cnt: 678.0, et_cnt: 244.0 train_loss: 29826.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  150, Time: 19.5031s, gt_cnt: 1622.0, et_cnt: 1803.5 train_loss: 32926.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  160, Time: 20.0052s, gt_cnt:  20.0, et_cnt:  10.1 train_loss: 34940.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  170, Time: 15.4375s, gt_cnt: 227.0, et_cnt: 136.5 train_loss: 36471.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  180, Time: 12.9655s, gt_cnt:  95.0, et_cnt: 127.4 train_loss: 38968.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   68, step  190, Time: 9.9920s, gt_cnt: 273.0, et_cnt: 203.6 train_loss: 40814.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step    0, Time: 11.1315s, gt_cnt:  40.0, et_cnt: 143.2 train_loss: 44.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   10, Time: 30.0402s, gt_cnt: 120.0, et_cnt:  45.4 train_loss: 1624.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   20, Time: 21.2764s, gt_cnt:  47.0, et_cnt:  37.6 train_loss: 2167.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   40, Time: 35.5157s, gt_cnt:  38.0, et_cnt: 170.8 train_loss: 9263.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   50, Time: 19.2653s, gt_cnt:  62.0, et_cnt:  48.8 train_loss: 9743.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   60, Time: 21.5001s, gt_cnt: 560.0, et_cnt: 114.8 train_loss: 13020.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   70, Time: 13.3307s, gt_cnt:  76.0, et_cnt:  14.0 train_loss: 14745.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step   90, Time: 32.1951s, gt_cnt:  85.0, et_cnt:  65.0 train_loss: 17187.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  100, Time: 16.7224s, gt_cnt:  61.0, et_cnt:  31.6 train_loss: 17774.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  110, Time: 14.5891s, gt_cnt:  31.0, et_cnt:  53.7 train_loss: 20333.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  120, Time: 9.3710s, gt_cnt: 196.0, et_cnt: 102.1 train_loss: 22064.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  130, Time: 19.6743s, gt_cnt:  42.0, et_cnt:  79.6 train_loss: 22791.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  140, Time: 25.4770s, gt_cnt: 678.0, et_cnt: 245.2 train_loss: 29810.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  150, Time: 19.7790s, gt_cnt: 1622.0, et_cnt: 1747.2 train_loss: 32907.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  160, Time: 19.9694s, gt_cnt:  20.0, et_cnt:  11.1 train_loss: 34922.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  170, Time: 15.3512s, gt_cnt: 227.0, et_cnt: 146.1 train_loss: 36451.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  180, Time: 12.8396s, gt_cnt:  95.0, et_cnt: 126.0 train_loss: 38946.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   69, step  190, Time: 9.9195s, gt_cnt: 273.0, et_cnt: 202.6 train_loss: 40793.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step    0, Time: 11.1008s, gt_cnt:  40.0, et_cnt: 138.1 train_loss: 44.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   10, Time: 29.9134s, gt_cnt: 120.0, et_cnt:  47.3 train_loss: 1623.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   20, Time: 21.2959s, gt_cnt:  47.0, et_cnt:  40.4 train_loss: 2166.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   40, Time: 35.5230s, gt_cnt:  38.0, et_cnt: 165.6 train_loss: 9257.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   50, Time: 19.0764s, gt_cnt:  62.0, et_cnt:  44.0 train_loss: 9737.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   60, Time: 21.5709s, gt_cnt: 560.0, et_cnt:  92.4 train_loss: 13014.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   70, Time: 13.3602s, gt_cnt:  76.0, et_cnt:  27.5 train_loss: 14743.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step   90, Time: 32.1430s, gt_cnt:  85.0, et_cnt:  61.9 train_loss: 17185.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  100, Time: 16.6870s, gt_cnt:  61.0, et_cnt:  28.1 train_loss: 17772.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  110, Time: 14.5800s, gt_cnt:  31.0, et_cnt:  65.5 train_loss: 20337.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  120, Time: 9.3654s, gt_cnt: 196.0, et_cnt: 102.5 train_loss: 22068.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  130, Time: 19.5020s, gt_cnt:  42.0, et_cnt:  91.4 train_loss: 22799.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  140, Time: 25.4841s, gt_cnt: 678.0, et_cnt: 234.7 train_loss: 29813.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  150, Time: 19.6490s, gt_cnt: 1622.0, et_cnt: 1682.2 train_loss: 32904.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  160, Time: 20.0068s, gt_cnt:  20.0, et_cnt:  11.4 train_loss: 34919.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  170, Time: 15.4449s, gt_cnt: 227.0, et_cnt: 140.9 train_loss: 36449.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  180, Time: 12.9144s, gt_cnt:  95.0, et_cnt: 128.2 train_loss: 38942.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   70, step  190, Time: 9.9286s, gt_cnt: 273.0, et_cnt: 183.0 train_loss: 40789.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step    0, Time: 11.1333s, gt_cnt:  40.0, et_cnt:  94.1 train_loss: 43.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   10, Time: 29.8691s, gt_cnt: 120.0, et_cnt:  19.9 train_loss: 1621.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   20, Time: 21.2448s, gt_cnt:  47.0, et_cnt:  23.4 train_loss: 2164.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   40, Time: 35.6021s, gt_cnt:  38.0, et_cnt: 162.2 train_loss: 9240.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   50, Time: 19.1411s, gt_cnt:  62.0, et_cnt:  41.9 train_loss: 9720.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   60, Time: 21.4804s, gt_cnt: 560.0, et_cnt:  82.8 train_loss: 13001.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   70, Time: 13.2618s, gt_cnt:  76.0, et_cnt:  26.7 train_loss: 14731.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step   90, Time: 32.2142s, gt_cnt:  85.0, et_cnt:  52.1 train_loss: 17171.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  100, Time: 16.6481s, gt_cnt:  61.0, et_cnt:  22.4 train_loss: 17758.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  110, Time: 14.5886s, gt_cnt:  31.0, et_cnt:  62.9 train_loss: 20322.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  120, Time: 9.3798s, gt_cnt: 196.0, et_cnt: 105.2 train_loss: 22053.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  130, Time: 19.6147s, gt_cnt:  42.0, et_cnt:  91.3 train_loss: 22784.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  140, Time: 25.5502s, gt_cnt: 678.0, et_cnt: 237.1 train_loss: 29791.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  150, Time: 19.6450s, gt_cnt: 1622.0, et_cnt: 1794.7 train_loss: 32887.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  160, Time: 19.9401s, gt_cnt:  20.0, et_cnt:   9.6 train_loss: 34899.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  170, Time: 15.3495s, gt_cnt: 227.0, et_cnt: 117.4 train_loss: 36430.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  180, Time: 12.9726s, gt_cnt:  95.0, et_cnt: 139.7 train_loss: 38926.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   71, step  190, Time: 9.9408s, gt_cnt: 273.0, et_cnt: 188.2 train_loss: 40769.9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   72, step    0, Time: 11.1351s, gt_cnt:  40.0, et_cnt: 115.0 train_loss: 44.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   10, Time: 29.9175s, gt_cnt: 120.0, et_cnt:  41.5 train_loss: 1625.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   20, Time: 21.2477s, gt_cnt:  47.0, et_cnt:  36.7 train_loss: 2167.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   40, Time: 35.5984s, gt_cnt:  38.0, et_cnt: 166.2 train_loss: 9249.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   50, Time: 19.4035s, gt_cnt:  62.0, et_cnt:  53.0 train_loss: 9730.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   60, Time: 21.5105s, gt_cnt: 560.0, et_cnt: 151.0 train_loss: 13009.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   70, Time: 13.2807s, gt_cnt:  76.0, et_cnt:  12.4 train_loss: 14734.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step   90, Time: 32.0374s, gt_cnt:  85.0, et_cnt:  58.0 train_loss: 17173.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  100, Time: 16.7870s, gt_cnt:  61.0, et_cnt:  27.0 train_loss: 17760.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  110, Time: 14.6222s, gt_cnt:  31.0, et_cnt:  48.0 train_loss: 20310.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  120, Time: 9.3709s, gt_cnt: 196.0, et_cnt: 101.0 train_loss: 22039.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  130, Time: 19.4311s, gt_cnt:  42.0, et_cnt:  76.4 train_loss: 22765.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  140, Time: 25.5218s, gt_cnt: 678.0, et_cnt: 250.0 train_loss: 29763.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  150, Time: 19.8609s, gt_cnt: 1622.0, et_cnt: 1807.4 train_loss: 32857.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  160, Time: 19.9653s, gt_cnt:  20.0, et_cnt:   9.1 train_loss: 34868.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  170, Time: 15.5148s, gt_cnt: 227.0, et_cnt: 135.8 train_loss: 36395.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  180, Time: 12.9443s, gt_cnt:  95.0, et_cnt: 123.9 train_loss: 38889.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   72, step  190, Time: 9.9602s, gt_cnt: 273.0, et_cnt: 195.0 train_loss: 40734.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step    0, Time: 11.1473s, gt_cnt:  40.0, et_cnt: 121.1 train_loss: 44.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   10, Time: 30.1392s, gt_cnt: 120.0, et_cnt:  43.7 train_loss: 1623.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   20, Time: 21.2264s, gt_cnt:  47.0, et_cnt:  38.3 train_loss: 2166.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   40, Time: 35.3660s, gt_cnt:  38.0, et_cnt: 162.6 train_loss: 9245.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   50, Time: 19.3439s, gt_cnt:  62.0, et_cnt:  48.8 train_loss: 9725.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   60, Time: 21.5824s, gt_cnt: 560.0, et_cnt: 118.0 train_loss: 13000.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   70, Time: 13.2791s, gt_cnt:  76.0, et_cnt:  14.1 train_loss: 14723.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step   90, Time: 31.7413s, gt_cnt:  85.0, et_cnt:  63.3 train_loss: 17160.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  100, Time: 16.4967s, gt_cnt:  61.0, et_cnt:  29.4 train_loss: 17746.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  110, Time: 14.6719s, gt_cnt:  31.0, et_cnt:  50.4 train_loss: 20295.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  120, Time: 9.4332s, gt_cnt: 196.0, et_cnt: 100.6 train_loss: 22023.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  130, Time: 19.4128s, gt_cnt:  42.0, et_cnt:  77.2 train_loss: 22750.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  140, Time: 25.3225s, gt_cnt: 678.0, et_cnt: 251.8 train_loss: 29740.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  150, Time: 19.7784s, gt_cnt: 1622.0, et_cnt: 1672.3 train_loss: 32828.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  160, Time: 19.9445s, gt_cnt:  20.0, et_cnt:  10.3 train_loss: 34840.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  170, Time: 15.2972s, gt_cnt: 227.0, et_cnt: 150.1 train_loss: 36366.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  180, Time: 13.0697s, gt_cnt:  95.0, et_cnt: 127.7 train_loss: 38855.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   73, step  190, Time: 9.9657s, gt_cnt: 273.0, et_cnt: 185.9 train_loss: 40699.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step    0, Time: 11.0490s, gt_cnt:  40.0, et_cnt: 114.7 train_loss: 44.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   10, Time: 29.5492s, gt_cnt: 120.0, et_cnt:  44.4 train_loss: 1622.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   20, Time: 21.2370s, gt_cnt:  47.0, et_cnt:  39.3 train_loss: 2165.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   40, Time: 35.2761s, gt_cnt:  38.0, et_cnt: 161.9 train_loss: 9236.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   50, Time: 19.3939s, gt_cnt:  62.0, et_cnt:  43.6 train_loss: 9716.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   60, Time: 21.4586s, gt_cnt: 560.0, et_cnt:  89.9 train_loss: 12994.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   70, Time: 13.2579s, gt_cnt:  76.0, et_cnt:  22.9 train_loss: 14720.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step   90, Time: 32.1039s, gt_cnt:  85.0, et_cnt:  54.9 train_loss: 17156.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  100, Time: 16.4929s, gt_cnt:  61.0, et_cnt:  23.4 train_loss: 17742.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  110, Time: 14.5681s, gt_cnt:  31.0, et_cnt:  55.0 train_loss: 20297.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  120, Time: 9.3699s, gt_cnt: 196.0, et_cnt: 103.6 train_loss: 22024.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  130, Time: 19.6211s, gt_cnt:  42.0, et_cnt:  85.8 train_loss: 22754.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  140, Time: 25.5512s, gt_cnt: 678.0, et_cnt: 248.9 train_loss: 29738.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  150, Time: 19.7037s, gt_cnt: 1622.0, et_cnt: 1769.7 train_loss: 32827.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  160, Time: 20.0523s, gt_cnt:  20.0, et_cnt:   8.3 train_loss: 34838.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  170, Time: 15.5984s, gt_cnt: 227.0, et_cnt: 121.8 train_loss: 36365.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  180, Time: 12.9522s, gt_cnt:  95.0, et_cnt: 132.4 train_loss: 38855.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   74, step  190, Time: 9.8845s, gt_cnt: 273.0, et_cnt: 191.4 train_loss: 40699.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step    0, Time: 11.1006s, gt_cnt:  40.0, et_cnt: 103.9 train_loss: 44.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   10, Time: 29.8135s, gt_cnt: 120.0, et_cnt:  38.5 train_loss: 1623.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   20, Time: 21.2126s, gt_cnt:  47.0, et_cnt:  37.8 train_loss: 2165.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   40, Time: 35.5390s, gt_cnt:  38.0, et_cnt: 162.5 train_loss: 9233.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   50, Time: 19.2411s, gt_cnt:  62.0, et_cnt:  54.2 train_loss: 9715.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   60, Time: 21.3310s, gt_cnt: 560.0, et_cnt: 140.7 train_loss: 12993.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   70, Time: 13.1750s, gt_cnt:  76.0, et_cnt:  15.0 train_loss: 14719.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step   90, Time: 31.8243s, gt_cnt:  85.0, et_cnt:  53.4 train_loss: 17155.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  100, Time: 16.2976s, gt_cnt:  61.0, et_cnt:  22.6 train_loss: 17742.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  110, Time: 14.7186s, gt_cnt:  31.0, et_cnt:  45.6 train_loss: 20289.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  120, Time: 9.3460s, gt_cnt: 196.0, et_cnt: 102.7 train_loss: 22016.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  130, Time: 19.4575s, gt_cnt:  42.0, et_cnt:  80.4 train_loss: 22744.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  140, Time: 25.3302s, gt_cnt: 678.0, et_cnt: 250.5 train_loss: 29720.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  150, Time: 19.4897s, gt_cnt: 1622.0, et_cnt: 1725.5 train_loss: 32806.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  160, Time: 19.7717s, gt_cnt:  20.0, et_cnt:   9.0 train_loss: 34815.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  170, Time: 15.3942s, gt_cnt: 227.0, et_cnt: 142.9 train_loss: 36341.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  180, Time: 12.9882s, gt_cnt:  95.0, et_cnt: 126.7 train_loss: 38830.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   75, step  190, Time: 9.9977s, gt_cnt: 273.0, et_cnt: 188.6 train_loss: 40673.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step    0, Time: 11.0687s, gt_cnt:  40.0, et_cnt: 115.5 train_loss: 44.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   10, Time: 29.6397s, gt_cnt: 120.0, et_cnt:  44.2 train_loss: 1622.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   20, Time: 20.7507s, gt_cnt:  47.0, et_cnt:  39.9 train_loss: 2165.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   40, Time: 34.9003s, gt_cnt:  38.0, et_cnt: 154.7 train_loss: 9229.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   50, Time: 19.1833s, gt_cnt:  62.0, et_cnt:  45.9 train_loss: 9709.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   60, Time: 21.6120s, gt_cnt: 560.0, et_cnt:  94.7 train_loss: 12986.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   70, Time: 13.2382s, gt_cnt:  76.0, et_cnt:  20.5 train_loss: 14710.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step   90, Time: 32.0200s, gt_cnt:  85.0, et_cnt:  55.5 train_loss: 17143.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  100, Time: 16.2748s, gt_cnt:  61.0, et_cnt:  23.8 train_loss: 17729.4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   76, step  110, Time: 14.6568s, gt_cnt:  31.0, et_cnt:  47.3 train_loss: 20277.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  120, Time: 9.3568s, gt_cnt: 196.0, et_cnt:  97.9 train_loss: 22002.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  130, Time: 19.4024s, gt_cnt:  42.0, et_cnt:  80.7 train_loss: 22730.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  140, Time: 25.3459s, gt_cnt: 678.0, et_cnt: 256.9 train_loss: 29698.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  150, Time: 19.5308s, gt_cnt: 1622.0, et_cnt: 1680.3 train_loss: 32781.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  160, Time: 20.0414s, gt_cnt:  20.0, et_cnt:   8.5 train_loss: 34789.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  170, Time: 15.4940s, gt_cnt: 227.0, et_cnt: 135.8 train_loss: 36314.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  180, Time: 12.9921s, gt_cnt:  95.0, et_cnt: 131.0 train_loss: 38800.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   76, step  190, Time: 9.9353s, gt_cnt: 273.0, et_cnt: 185.5 train_loss: 40643.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step    0, Time: 11.1789s, gt_cnt:  40.0, et_cnt: 101.1 train_loss: 44.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   10, Time: 30.2022s, gt_cnt: 120.0, et_cnt:  41.2 train_loss: 1621.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   20, Time: 21.2676s, gt_cnt:  47.0, et_cnt:  40.6 train_loss: 2164.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   40, Time: 35.7265s, gt_cnt:  38.0, et_cnt: 158.3 train_loss: 9222.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   50, Time: 19.0202s, gt_cnt:  62.0, et_cnt:  48.9 train_loss: 9703.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   60, Time: 21.5185s, gt_cnt: 560.0, et_cnt: 111.9 train_loss: 12975.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   70, Time: 13.2780s, gt_cnt:  76.0, et_cnt:  13.1 train_loss: 14697.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step   90, Time: 32.0728s, gt_cnt:  85.0, et_cnt:  57.7 train_loss: 17128.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  100, Time: 16.7818s, gt_cnt:  61.0, et_cnt:  27.4 train_loss: 17714.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  110, Time: 14.5672s, gt_cnt:  31.0, et_cnt:  46.9 train_loss: 20254.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  120, Time: 9.3491s, gt_cnt: 196.0, et_cnt:  95.0 train_loss: 21979.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  130, Time: 19.2947s, gt_cnt:  42.0, et_cnt:  76.7 train_loss: 22705.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  140, Time: 24.8948s, gt_cnt: 678.0, et_cnt: 262.2 train_loss: 29664.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  150, Time: 19.4365s, gt_cnt: 1622.0, et_cnt: 1623.2 train_loss: 32747.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  160, Time: 19.9904s, gt_cnt:  20.0, et_cnt:  10.0 train_loss: 34756.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  170, Time: 15.4066s, gt_cnt: 227.0, et_cnt: 153.8 train_loss: 36279.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  180, Time: 12.9174s, gt_cnt:  95.0, et_cnt: 130.3 train_loss: 38763.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   77, step  190, Time: 9.8896s, gt_cnt: 273.0, et_cnt: 178.2 train_loss: 40605.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step    0, Time: 11.0560s, gt_cnt:  40.0, et_cnt:  99.9 train_loss: 43.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   10, Time: 29.8304s, gt_cnt: 120.0, et_cnt:  42.3 train_loss: 1621.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   20, Time: 21.2205s, gt_cnt:  47.0, et_cnt:  41.1 train_loss: 2163.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   40, Time: 35.2505s, gt_cnt:  38.0, et_cnt: 157.7 train_loss: 9217.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   50, Time: 19.3916s, gt_cnt:  62.0, et_cnt:  45.5 train_loss: 9699.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   60, Time: 21.2094s, gt_cnt: 560.0, et_cnt:  91.2 train_loss: 12973.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   70, Time: 12.9921s, gt_cnt:  76.0, et_cnt:  19.6 train_loss: 14697.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step   90, Time: 31.8490s, gt_cnt:  85.0, et_cnt:  53.2 train_loss: 17127.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  100, Time: 16.7258s, gt_cnt:  61.0, et_cnt:  23.4 train_loss: 17713.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  110, Time: 14.6428s, gt_cnt:  31.0, et_cnt:  47.0 train_loss: 20256.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  120, Time: 9.4006s, gt_cnt: 196.0, et_cnt:  97.6 train_loss: 21980.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  130, Time: 19.6225s, gt_cnt:  42.0, et_cnt:  80.2 train_loss: 22708.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  140, Time: 25.2546s, gt_cnt: 678.0, et_cnt: 260.1 train_loss: 29661.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  150, Time: 19.6817s, gt_cnt: 1622.0, et_cnt: 1745.6 train_loss: 32744.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  160, Time: 19.8354s, gt_cnt:  20.0, et_cnt:   7.7 train_loss: 34750.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  170, Time: 15.4125s, gt_cnt: 227.0, et_cnt: 125.2 train_loss: 36274.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  180, Time: 12.9972s, gt_cnt:  95.0, et_cnt: 126.4 train_loss: 38760.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   78, step  190, Time: 9.9609s, gt_cnt: 273.0, et_cnt: 192.8 train_loss: 40603.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step    0, Time: 11.1164s, gt_cnt:  40.0, et_cnt:  97.0 train_loss: 43.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   10, Time: 29.9364s, gt_cnt: 120.0, et_cnt:  39.7 train_loss: 1621.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   20, Time: 21.3472s, gt_cnt:  47.0, et_cnt:  42.3 train_loss: 2164.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   40, Time: 35.4073s, gt_cnt:  38.0, et_cnt: 158.0 train_loss: 9216.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   50, Time: 19.3963s, gt_cnt:  62.0, et_cnt:  49.0 train_loss: 9698.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   60, Time: 21.4500s, gt_cnt: 560.0, et_cnt: 120.7 train_loss: 12967.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   70, Time: 13.3086s, gt_cnt:  76.0, et_cnt:  11.4 train_loss: 14687.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step   90, Time: 32.2779s, gt_cnt:  85.0, et_cnt:  57.2 train_loss: 17115.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  100, Time: 16.6050s, gt_cnt:  61.0, et_cnt:  25.5 train_loss: 17701.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  110, Time: 14.5281s, gt_cnt:  31.0, et_cnt:  44.4 train_loss: 20238.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  120, Time: 9.3581s, gt_cnt: 196.0, et_cnt:  97.2 train_loss: 21962.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  130, Time: 19.7434s, gt_cnt:  42.0, et_cnt:  71.8 train_loss: 22688.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  140, Time: 25.4206s, gt_cnt: 678.0, et_cnt: 262.0 train_loss: 29639.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  150, Time: 19.7940s, gt_cnt: 1622.0, et_cnt: 1613.7 train_loss: 32718.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  160, Time: 20.1924s, gt_cnt:  20.0, et_cnt:  12.1 train_loss: 34730.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  170, Time: 15.5974s, gt_cnt: 227.0, et_cnt: 163.3 train_loss: 36254.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  180, Time: 12.8622s, gt_cnt:  95.0, et_cnt: 132.5 train_loss: 38737.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   79, step  190, Time: 9.9349s, gt_cnt: 273.0, et_cnt: 178.5 train_loss: 40578.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step    0, Time: 11.1252s, gt_cnt:  40.0, et_cnt:  84.0 train_loss: 43.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   10, Time: 29.8397s, gt_cnt: 120.0, et_cnt:  35.8 train_loss: 1624.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   20, Time: 21.2803s, gt_cnt:  47.0, et_cnt:  44.2 train_loss: 2167.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   40, Time: 35.2738s, gt_cnt:  38.0, et_cnt: 157.9 train_loss: 9203.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   50, Time: 19.2405s, gt_cnt:  62.0, et_cnt:  42.6 train_loss: 9684.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   60, Time: 21.4621s, gt_cnt: 560.0, et_cnt:  92.3 train_loss: 12955.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   70, Time: 13.3094s, gt_cnt:  76.0, et_cnt:  18.8 train_loss: 14679.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step   90, Time: 32.1872s, gt_cnt:  85.0, et_cnt:  50.0 train_loss: 17106.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  100, Time: 16.4581s, gt_cnt:  61.0, et_cnt:  20.0 train_loss: 17692.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  110, Time: 14.5316s, gt_cnt:  31.0, et_cnt:  45.9 train_loss: 20233.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  120, Time: 9.3281s, gt_cnt: 196.0, et_cnt: 102.3 train_loss: 21954.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  130, Time: 19.6955s, gt_cnt:  42.0, et_cnt:  75.8 train_loss: 22681.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  140, Time: 25.4767s, gt_cnt: 678.0, et_cnt: 260.4 train_loss: 29625.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  150, Time: 19.7467s, gt_cnt: 1622.0, et_cnt: 1946.9 train_loss: 32713.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  160, Time: 19.9384s, gt_cnt:  20.0, et_cnt:   6.2 train_loss: 34717.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  170, Time: 15.4528s, gt_cnt: 227.0, et_cnt: 101.5 train_loss: 36243.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  180, Time: 12.9838s, gt_cnt:  95.0, et_cnt: 116.0 train_loss: 38738.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   80, step  190, Time: 9.9251s, gt_cnt: 273.0, et_cnt: 210.2 train_loss: 40578.7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   81, step    0, Time: 11.1261s, gt_cnt:  40.0, et_cnt: 107.0 train_loss: 44.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   10, Time: 29.8078s, gt_cnt: 120.0, et_cnt:  37.3 train_loss: 1624.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   20, Time: 21.2789s, gt_cnt:  47.0, et_cnt:  41.1 train_loss: 2167.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   40, Time: 35.4005s, gt_cnt:  38.0, et_cnt: 150.7 train_loss: 9224.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   50, Time: 19.4179s, gt_cnt:  62.0, et_cnt:  52.6 train_loss: 9704.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   60, Time: 21.4592s, gt_cnt: 560.0, et_cnt:  89.1 train_loss: 12986.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   70, Time: 13.2529s, gt_cnt:  76.0, et_cnt:  37.3 train_loss: 14728.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step   90, Time: 31.9025s, gt_cnt:  85.0, et_cnt:  46.8 train_loss: 17164.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  100, Time: 16.4612s, gt_cnt:  61.0, et_cnt:  18.1 train_loss: 17750.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  110, Time: 14.5243s, gt_cnt:  31.0, et_cnt:  41.0 train_loss: 20302.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  120, Time: 9.3279s, gt_cnt: 196.0, et_cnt:  95.0 train_loss: 22027.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  130, Time: 19.6549s, gt_cnt:  42.0, et_cnt:  89.5 train_loss: 22756.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  140, Time: 25.6006s, gt_cnt: 678.0, et_cnt: 272.9 train_loss: 29698.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  150, Time: 19.5775s, gt_cnt: 1622.0, et_cnt: 1602.2 train_loss: 32772.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  160, Time: 20.0891s, gt_cnt:  20.0, et_cnt:   9.9 train_loss: 34778.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  170, Time: 15.5147s, gt_cnt: 227.0, et_cnt: 160.9 train_loss: 36301.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  180, Time: 12.9213s, gt_cnt:  95.0, et_cnt: 124.7 train_loss: 38784.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   81, step  190, Time: 9.8575s, gt_cnt: 273.0, et_cnt: 182.9 train_loss: 40625.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step    0, Time: 11.0231s, gt_cnt:  40.0, et_cnt: 111.1 train_loss: 44.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   10, Time: 29.8315s, gt_cnt: 120.0, et_cnt:  38.6 train_loss: 1622.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   20, Time: 21.2125s, gt_cnt:  47.0, et_cnt:  37.0 train_loss: 2164.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   40, Time: 35.2960s, gt_cnt:  38.0, et_cnt: 135.1 train_loss: 9206.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   50, Time: 19.2272s, gt_cnt:  62.0, et_cnt:  51.2 train_loss: 9686.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   60, Time: 21.6034s, gt_cnt: 560.0, et_cnt: 117.2 train_loss: 12959.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   70, Time: 13.2403s, gt_cnt:  76.0, et_cnt:  14.7 train_loss: 14681.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step   90, Time: 31.8710s, gt_cnt:  85.0, et_cnt:  51.3 train_loss: 17109.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  100, Time: 16.7858s, gt_cnt:  61.0, et_cnt:  23.6 train_loss: 17695.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  110, Time: 14.5252s, gt_cnt:  31.0, et_cnt:  38.8 train_loss: 20226.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  120, Time: 9.3553s, gt_cnt: 196.0, et_cnt:  88.2 train_loss: 21948.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  130, Time: 19.5694s, gt_cnt:  42.0, et_cnt:  70.1 train_loss: 22672.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  140, Time: 25.6176s, gt_cnt: 678.0, et_cnt: 272.2 train_loss: 29599.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  150, Time: 19.5716s, gt_cnt: 1622.0, et_cnt: 1576.8 train_loss: 32673.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  160, Time: 19.9738s, gt_cnt:  20.0, et_cnt:   9.4 train_loss: 34678.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  170, Time: 15.4923s, gt_cnt: 227.0, et_cnt: 158.5 train_loss: 36198.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  180, Time: 13.0045s, gt_cnt:  95.0, et_cnt: 128.9 train_loss: 38676.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   82, step  190, Time: 9.9165s, gt_cnt: 273.0, et_cnt: 183.2 train_loss: 40514.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step    0, Time: 11.1225s, gt_cnt:  40.0, et_cnt: 100.0 train_loss: 44.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   10, Time: 29.9483s, gt_cnt: 120.0, et_cnt:  39.9 train_loss: 1620.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   20, Time: 21.2733s, gt_cnt:  47.0, et_cnt:  41.2 train_loss: 2163.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   40, Time: 35.6260s, gt_cnt:  38.0, et_cnt: 143.2 train_loss: 9198.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   50, Time: 18.9065s, gt_cnt:  62.0, et_cnt:  46.9 train_loss: 9679.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   60, Time: 21.5696s, gt_cnt: 560.0, et_cnt:  99.2 train_loss: 12948.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   70, Time: 13.3452s, gt_cnt:  76.0, et_cnt:  15.6 train_loss: 14670.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step   90, Time: 32.4710s, gt_cnt:  85.0, et_cnt:  53.5 train_loss: 17094.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  100, Time: 16.7899s, gt_cnt:  61.0, et_cnt:  24.1 train_loss: 17679.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  110, Time: 14.5604s, gt_cnt:  31.0, et_cnt:  41.4 train_loss: 20210.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  120, Time: 9.3578s, gt_cnt: 196.0, et_cnt:  92.9 train_loss: 21930.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  130, Time: 19.7345s, gt_cnt:  42.0, et_cnt:  75.2 train_loss: 22656.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  140, Time: 25.5242s, gt_cnt: 678.0, et_cnt: 269.8 train_loss: 29575.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  150, Time: 19.7541s, gt_cnt: 1622.0, et_cnt: 1601.4 train_loss: 32648.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  160, Time: 20.0785s, gt_cnt:  20.0, et_cnt:   9.6 train_loss: 34652.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  170, Time: 15.3971s, gt_cnt: 227.0, et_cnt: 149.1 train_loss: 36172.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  180, Time: 12.9740s, gt_cnt:  95.0, et_cnt: 124.0 train_loss: 38651.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   83, step  190, Time: 9.9313s, gt_cnt: 273.0, et_cnt: 188.1 train_loss: 40489.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step    0, Time: 11.1461s, gt_cnt:  40.0, et_cnt:  96.3 train_loss: 43.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   10, Time: 29.9744s, gt_cnt: 120.0, et_cnt:  40.3 train_loss: 1620.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   20, Time: 21.2719s, gt_cnt:  47.0, et_cnt:  41.6 train_loss: 2163.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   40, Time: 35.5063s, gt_cnt:  38.0, et_cnt: 141.6 train_loss: 9195.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   50, Time: 19.4304s, gt_cnt:  62.0, et_cnt:  45.6 train_loss: 9675.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   60, Time: 21.5439s, gt_cnt: 560.0, et_cnt:  88.7 train_loss: 12946.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   70, Time: 13.2944s, gt_cnt:  76.0, et_cnt:  19.6 train_loss: 14669.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step   90, Time: 32.5257s, gt_cnt:  85.0, et_cnt:  50.4 train_loss: 17092.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  100, Time: 16.4948s, gt_cnt:  61.0, et_cnt:  22.5 train_loss: 17678.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  110, Time: 14.6238s, gt_cnt:  31.0, et_cnt:  42.8 train_loss: 20209.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  120, Time: 9.3851s, gt_cnt: 196.0, et_cnt:  91.2 train_loss: 21930.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  130, Time: 19.5501s, gt_cnt:  42.0, et_cnt:  77.7 train_loss: 22656.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  140, Time: 25.5555s, gt_cnt: 678.0, et_cnt: 272.3 train_loss: 29567.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  150, Time: 20.0146s, gt_cnt: 1622.0, et_cnt: 1635.4 train_loss: 32639.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  160, Time: 20.0184s, gt_cnt:  20.0, et_cnt:   8.5 train_loss: 34640.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  170, Time: 15.3479s, gt_cnt: 227.0, et_cnt: 139.7 train_loss: 36160.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  180, Time: 12.9379s, gt_cnt:  95.0, et_cnt: 124.7 train_loss: 38638.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   84, step  190, Time: 9.9487s, gt_cnt: 273.0, et_cnt: 187.7 train_loss: 40476.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step    0, Time: 11.1616s, gt_cnt:  40.0, et_cnt:  93.8 train_loss: 43.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   10, Time: 30.0770s, gt_cnt: 120.0, et_cnt:  39.0 train_loss: 1620.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   20, Time: 21.3590s, gt_cnt:  47.0, et_cnt:  43.2 train_loss: 2162.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   40, Time: 35.5677s, gt_cnt:  38.0, et_cnt: 136.9 train_loss: 9191.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   50, Time: 19.3722s, gt_cnt:  62.0, et_cnt:  45.4 train_loss: 9671.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   60, Time: 21.5778s, gt_cnt: 560.0, et_cnt:  91.0 train_loss: 12940.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   70, Time: 13.3342s, gt_cnt:  76.0, et_cnt:  18.8 train_loss: 14662.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step   90, Time: 32.2374s, gt_cnt:  85.0, et_cnt:  49.2 train_loss: 17084.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  100, Time: 16.3882s, gt_cnt:  61.0, et_cnt:  21.8 train_loss: 17670.2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   85, step  110, Time: 14.6178s, gt_cnt:  31.0, et_cnt:  42.0 train_loss: 20198.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  120, Time: 9.4046s, gt_cnt: 196.0, et_cnt:  91.3 train_loss: 21918.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  130, Time: 19.6514s, gt_cnt:  42.0, et_cnt:  77.0 train_loss: 22644.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  140, Time: 25.6200s, gt_cnt: 678.0, et_cnt: 274.1 train_loss: 29549.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  150, Time: 19.6378s, gt_cnt: 1622.0, et_cnt: 1687.9 train_loss: 32621.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  160, Time: 20.0299s, gt_cnt:  20.0, et_cnt:   7.9 train_loss: 34621.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  170, Time: 15.3609s, gt_cnt: 227.0, et_cnt: 134.1 train_loss: 36141.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  180, Time: 12.9455s, gt_cnt:  95.0, et_cnt: 122.4 train_loss: 38620.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   85, step  190, Time: 9.9514s, gt_cnt: 273.0, et_cnt: 196.8 train_loss: 40457.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step    0, Time: 11.1642s, gt_cnt:  40.0, et_cnt:  92.2 train_loss: 43.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   10, Time: 29.7009s, gt_cnt: 120.0, et_cnt:  37.7 train_loss: 1620.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   20, Time: 21.0109s, gt_cnt:  47.0, et_cnt:  42.2 train_loss: 2163.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   40, Time: 35.0873s, gt_cnt:  38.0, et_cnt: 132.7 train_loss: 9190.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   50, Time: 19.3691s, gt_cnt:  62.0, et_cnt:  45.3 train_loss: 9670.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   60, Time: 21.6483s, gt_cnt: 560.0, et_cnt:  92.9 train_loss: 12940.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   70, Time: 13.2207s, gt_cnt:  76.0, et_cnt:  24.2 train_loss: 14661.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step   90, Time: 32.2012s, gt_cnt:  85.0, et_cnt:  51.2 train_loss: 17081.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  100, Time: 16.8009s, gt_cnt:  61.0, et_cnt:  20.2 train_loss: 17666.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  110, Time: 14.4803s, gt_cnt:  31.0, et_cnt:  40.2 train_loss: 20196.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  120, Time: 9.1905s, gt_cnt: 196.0, et_cnt:  91.8 train_loss: 21916.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  130, Time: 18.9047s, gt_cnt:  42.0, et_cnt:  77.0 train_loss: 22643.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  140, Time: 25.0140s, gt_cnt: 678.0, et_cnt: 275.7 train_loss: 29546.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  150, Time: 19.5074s, gt_cnt: 1622.0, et_cnt: 1522.4 train_loss: 32609.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  160, Time: 20.0498s, gt_cnt:  20.0, et_cnt:   9.4 train_loss: 34608.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  170, Time: 15.5700s, gt_cnt: 227.0, et_cnt: 148.4 train_loss: 36127.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  180, Time: 12.9254s, gt_cnt:  95.0, et_cnt: 126.9 train_loss: 38601.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   86, step  190, Time: 9.9591s, gt_cnt: 273.0, et_cnt: 187.2 train_loss: 40436.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step    0, Time: 11.1478s, gt_cnt:  40.0, et_cnt:  87.0 train_loss: 43.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   10, Time: 29.7085s, gt_cnt: 120.0, et_cnt:  38.6 train_loss: 1620.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   20, Time: 21.3101s, gt_cnt:  47.0, et_cnt:  43.7 train_loss: 2163.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   40, Time: 35.4866s, gt_cnt:  38.0, et_cnt: 133.7 train_loss: 9181.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   50, Time: 18.9580s, gt_cnt:  62.0, et_cnt:  46.3 train_loss: 9662.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   60, Time: 21.5723s, gt_cnt: 560.0, et_cnt:  89.2 train_loss: 12932.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   70, Time: 13.3423s, gt_cnt:  76.0, et_cnt:  18.6 train_loss: 14654.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step   90, Time: 32.2857s, gt_cnt:  85.0, et_cnt:  47.0 train_loss: 17074.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  100, Time: 16.4428s, gt_cnt:  61.0, et_cnt:  19.4 train_loss: 17660.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  110, Time: 14.5766s, gt_cnt:  31.0, et_cnt:  36.5 train_loss: 20186.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  120, Time: 9.4030s, gt_cnt: 196.0, et_cnt:  88.1 train_loss: 21904.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  130, Time: 19.6917s, gt_cnt:  42.0, et_cnt:  74.2 train_loss: 22629.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  140, Time: 25.5994s, gt_cnt: 678.0, et_cnt: 283.8 train_loss: 29522.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  150, Time: 19.7377s, gt_cnt: 1622.0, et_cnt: 1680.7 train_loss: 32591.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  160, Time: 19.9798s, gt_cnt:  20.0, et_cnt:   8.2 train_loss: 34590.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  170, Time: 15.4843s, gt_cnt: 227.0, et_cnt: 133.3 train_loss: 36107.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  180, Time: 13.0506s, gt_cnt:  95.0, et_cnt: 126.6 train_loss: 38584.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   87, step  190, Time: 9.9242s, gt_cnt: 273.0, et_cnt: 193.4 train_loss: 40419.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step    0, Time: 11.0409s, gt_cnt:  40.0, et_cnt:  84.9 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   10, Time: 29.7235s, gt_cnt: 120.0, et_cnt:  35.7 train_loss: 1621.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   20, Time: 21.0061s, gt_cnt:  47.0, et_cnt:  42.5 train_loss: 2163.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   40, Time: 35.0451s, gt_cnt:  38.0, et_cnt: 133.5 train_loss: 9182.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   50, Time: 19.0267s, gt_cnt:  62.0, et_cnt:  49.8 train_loss: 9663.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   60, Time: 21.3941s, gt_cnt: 560.0, et_cnt: 114.2 train_loss: 12928.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   70, Time: 13.2997s, gt_cnt:  76.0, et_cnt:  13.9 train_loss: 14648.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step   90, Time: 31.9733s, gt_cnt:  85.0, et_cnt:  46.4 train_loss: 17068.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  100, Time: 16.5243s, gt_cnt:  61.0, et_cnt:  17.0 train_loss: 17653.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  110, Time: 14.6418s, gt_cnt:  31.0, et_cnt:  36.4 train_loss: 20176.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  120, Time: 9.3837s, gt_cnt: 196.0, et_cnt: 100.6 train_loss: 21896.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  130, Time: 19.5682s, gt_cnt:  42.0, et_cnt:  70.7 train_loss: 22623.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  140, Time: 25.5511s, gt_cnt: 678.0, et_cnt: 267.2 train_loss: 29520.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  150, Time: 19.6817s, gt_cnt: 1622.0, et_cnt: 1720.9 train_loss: 32585.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  160, Time: 19.8898s, gt_cnt:  20.0, et_cnt:   8.4 train_loss: 34584.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  170, Time: 15.3826s, gt_cnt: 227.0, et_cnt: 132.5 train_loss: 36102.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  180, Time: 12.9800s, gt_cnt:  95.0, et_cnt: 125.8 train_loss: 38579.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   88, step  190, Time: 9.9456s, gt_cnt: 273.0, et_cnt: 210.7 train_loss: 40414.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step    0, Time: 11.1453s, gt_cnt:  40.0, et_cnt: 108.0 train_loss: 44.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   10, Time: 29.9890s, gt_cnt: 120.0, et_cnt:  42.2 train_loss: 1621.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   20, Time: 21.3025s, gt_cnt:  47.0, et_cnt:  43.3 train_loss: 2164.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   40, Time: 35.5764s, gt_cnt:  38.0, et_cnt: 128.7 train_loss: 9186.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   50, Time: 19.1361s, gt_cnt:  62.0, et_cnt:  44.9 train_loss: 9664.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   60, Time: 21.5372s, gt_cnt: 560.0, et_cnt:  90.8 train_loss: 12932.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   70, Time: 13.2722s, gt_cnt:  76.0, et_cnt:  25.4 train_loss: 14654.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step   90, Time: 32.0514s, gt_cnt:  85.0, et_cnt:  51.4 train_loss: 17073.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  100, Time: 16.9133s, gt_cnt:  61.0, et_cnt:  20.0 train_loss: 17658.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  110, Time: 14.5897s, gt_cnt:  31.0, et_cnt:  36.6 train_loss: 20184.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  120, Time: 9.3882s, gt_cnt: 196.0, et_cnt:  82.8 train_loss: 21904.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  130, Time: 19.8433s, gt_cnt:  42.0, et_cnt:  77.5 train_loss: 22628.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  140, Time: 25.5875s, gt_cnt: 678.0, et_cnt: 286.1 train_loss: 29511.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  150, Time: 19.7550s, gt_cnt: 1622.0, et_cnt: 1394.2 train_loss: 32571.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  160, Time: 20.0859s, gt_cnt:  20.0, et_cnt:   9.7 train_loss: 34569.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  170, Time: 15.3795s, gt_cnt: 227.0, et_cnt: 159.9 train_loss: 36086.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  180, Time: 12.9277s, gt_cnt:  95.0, et_cnt: 128.4 train_loss: 38555.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   89, step  190, Time: 9.9353s, gt_cnt: 273.0, et_cnt: 178.8 train_loss: 40386.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   90, step    0, Time: 11.1408s, gt_cnt:  40.0, et_cnt:  88.1 train_loss: 43.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   10, Time: 30.1219s, gt_cnt: 120.0, et_cnt:  40.1 train_loss: 1619.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   20, Time: 21.2726s, gt_cnt:  47.0, et_cnt:  43.4 train_loss: 2162.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   40, Time: 35.6319s, gt_cnt:  38.0, et_cnt: 128.5 train_loss: 9166.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   50, Time: 19.3683s, gt_cnt:  62.0, et_cnt:  49.3 train_loss: 9647.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   60, Time: 21.4790s, gt_cnt: 560.0, et_cnt:  96.7 train_loss: 12916.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   70, Time: 13.2950s, gt_cnt:  76.0, et_cnt:  13.8 train_loss: 14637.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step   90, Time: 32.1000s, gt_cnt:  85.0, et_cnt:  47.0 train_loss: 17058.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  100, Time: 16.4530s, gt_cnt:  61.0, et_cnt:  19.8 train_loss: 17643.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  110, Time: 14.5334s, gt_cnt:  31.0, et_cnt:  33.4 train_loss: 20163.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  120, Time: 9.3751s, gt_cnt: 196.0, et_cnt:  84.8 train_loss: 21879.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  130, Time: 19.5168s, gt_cnt:  42.0, et_cnt:  74.5 train_loss: 22604.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  140, Time: 25.5807s, gt_cnt: 678.0, et_cnt: 285.9 train_loss: 29480.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  150, Time: 19.8305s, gt_cnt: 1622.0, et_cnt: 1751.3 train_loss: 32546.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  160, Time: 19.9191s, gt_cnt:  20.0, et_cnt:   6.9 train_loss: 34543.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  170, Time: 15.4938s, gt_cnt: 227.0, et_cnt: 120.7 train_loss: 36060.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  180, Time: 12.9484s, gt_cnt:  95.0, et_cnt: 125.1 train_loss: 38536.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   90, step  190, Time: 9.9269s, gt_cnt: 273.0, et_cnt: 201.5 train_loss: 40370.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step    0, Time: 11.1230s, gt_cnt:  40.0, et_cnt:  89.8 train_loss: 43.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   10, Time: 29.9662s, gt_cnt: 120.0, et_cnt:  36.0 train_loss: 1621.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   20, Time: 21.3137s, gt_cnt:  47.0, et_cnt:  42.0 train_loss: 2163.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   40, Time: 35.5706s, gt_cnt:  38.0, et_cnt: 129.2 train_loss: 9175.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   50, Time: 19.2656s, gt_cnt:  62.0, et_cnt:  52.8 train_loss: 9655.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   60, Time: 21.5109s, gt_cnt: 560.0, et_cnt: 110.5 train_loss: 12917.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   70, Time: 13.2987s, gt_cnt:  76.0, et_cnt:  10.8 train_loss: 14639.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step   90, Time: 32.3988s, gt_cnt:  85.0, et_cnt:  63.1 train_loss: 17067.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  100, Time: 16.4835s, gt_cnt:  61.0, et_cnt:  31.3 train_loss: 17655.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  110, Time: 14.5689s, gt_cnt:  31.0, et_cnt:  37.1 train_loss: 20161.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  120, Time: 9.3692s, gt_cnt: 196.0, et_cnt:  85.8 train_loss: 21879.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  130, Time: 19.6425s, gt_cnt:  42.0, et_cnt:  68.5 train_loss: 22601.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  140, Time: 25.5583s, gt_cnt: 678.0, et_cnt: 287.6 train_loss: 29472.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  150, Time: 19.6230s, gt_cnt: 1622.0, et_cnt: 1738.0 train_loss: 32539.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  160, Time: 19.9835s, gt_cnt:  20.0, et_cnt:   7.0 train_loss: 34535.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  170, Time: 15.3037s, gt_cnt: 227.0, et_cnt: 121.2 train_loss: 36053.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  180, Time: 13.0453s, gt_cnt:  95.0, et_cnt: 126.1 train_loss: 38529.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   91, step  190, Time: 9.9556s, gt_cnt: 273.0, et_cnt: 221.7 train_loss: 40363.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step    0, Time: 11.1607s, gt_cnt:  40.0, et_cnt: 100.4 train_loss: 44.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   10, Time: 30.1844s, gt_cnt: 120.0, et_cnt:  41.2 train_loss: 1620.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   20, Time: 21.3480s, gt_cnt:  47.0, et_cnt:  43.6 train_loss: 2163.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   40, Time: 35.3050s, gt_cnt:  38.0, et_cnt: 120.5 train_loss: 9173.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   50, Time: 19.2926s, gt_cnt:  62.0, et_cnt:  53.6 train_loss: 9652.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   60, Time: 21.5100s, gt_cnt: 560.0, et_cnt: 127.9 train_loss: 12912.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   70, Time: 13.2658s, gt_cnt:  76.0, et_cnt:  12.1 train_loss: 14630.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step   90, Time: 32.1429s, gt_cnt:  85.0, et_cnt:  50.4 train_loss: 17049.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  100, Time: 16.8211s, gt_cnt:  61.0, et_cnt:  20.1 train_loss: 17633.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  110, Time: 14.5659s, gt_cnt:  31.0, et_cnt:  32.8 train_loss: 20149.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  120, Time: 9.3539s, gt_cnt: 196.0, et_cnt:  89.2 train_loss: 21866.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  130, Time: 19.7978s, gt_cnt:  42.0, et_cnt:  75.0 train_loss: 22591.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  140, Time: 25.5141s, gt_cnt: 678.0, et_cnt: 282.9 train_loss: 29456.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  150, Time: 20.0216s, gt_cnt: 1622.0, et_cnt: 1452.9 train_loss: 32511.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  160, Time: 20.0410s, gt_cnt:  20.0, et_cnt:   9.2 train_loss: 34507.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  170, Time: 15.5001s, gt_cnt: 227.0, et_cnt: 151.3 train_loss: 36021.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  180, Time: 12.9511s, gt_cnt:  95.0, et_cnt: 131.5 train_loss: 38488.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   92, step  190, Time: 9.8764s, gt_cnt: 273.0, et_cnt: 186.5 train_loss: 40317.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step    0, Time: 11.0451s, gt_cnt:  40.0, et_cnt:  93.9 train_loss: 43.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   10, Time: 29.8077s, gt_cnt: 120.0, et_cnt:  40.1 train_loss: 1618.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   20, Time: 21.1900s, gt_cnt:  47.0, et_cnt:  41.8 train_loss: 2161.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   40, Time: 35.2046s, gt_cnt:  38.0, et_cnt: 124.8 train_loss: 9157.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   50, Time: 19.0874s, gt_cnt:  62.0, et_cnt:  50.4 train_loss: 9638.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   60, Time: 21.4147s, gt_cnt: 560.0, et_cnt: 103.5 train_loss: 12905.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   70, Time: 13.3016s, gt_cnt:  76.0, et_cnt:  14.7 train_loss: 14625.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step   90, Time: 32.0248s, gt_cnt:  85.0, et_cnt:  46.0 train_loss: 17044.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  100, Time: 16.9000s, gt_cnt:  61.0, et_cnt:  18.4 train_loss: 17628.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  110, Time: 14.6788s, gt_cnt:  31.0, et_cnt:  31.8 train_loss: 20147.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  120, Time: 9.3552s, gt_cnt: 196.0, et_cnt:  83.6 train_loss: 21860.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  130, Time: 19.3396s, gt_cnt:  42.0, et_cnt:  76.2 train_loss: 22585.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  140, Time: 25.2720s, gt_cnt: 678.0, et_cnt: 290.9 train_loss: 29442.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  150, Time: 19.4253s, gt_cnt: 1622.0, et_cnt: 1619.0 train_loss: 32499.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  160, Time: 19.9892s, gt_cnt:  20.0, et_cnt:   7.4 train_loss: 34496.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  170, Time: 15.4096s, gt_cnt: 227.0, et_cnt: 132.2 train_loss: 36010.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  180, Time: 13.0101s, gt_cnt:  95.0, et_cnt: 131.7 train_loss: 38478.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   93, step  190, Time: 9.9530s, gt_cnt: 273.0, et_cnt: 199.7 train_loss: 40308.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step    0, Time: 11.1783s, gt_cnt:  40.0, et_cnt:  87.5 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   10, Time: 30.0664s, gt_cnt: 120.0, et_cnt:  38.4 train_loss: 1619.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   20, Time: 21.4300s, gt_cnt:  47.0, et_cnt:  43.2 train_loss: 2161.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   40, Time: 35.7221s, gt_cnt:  38.0, et_cnt: 123.6 train_loss: 9158.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   50, Time: 19.4027s, gt_cnt:  62.0, et_cnt:  51.5 train_loss: 9637.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   60, Time: 21.6474s, gt_cnt: 560.0, et_cnt: 113.9 train_loss: 12898.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   70, Time: 13.3243s, gt_cnt:  76.0, et_cnt:  13.7 train_loss: 14616.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step   90, Time: 32.0914s, gt_cnt:  85.0, et_cnt:  49.8 train_loss: 17032.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  100, Time: 16.8543s, gt_cnt:  61.0, et_cnt:  17.7 train_loss: 17616.3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   94, step  110, Time: 14.6450s, gt_cnt:  31.0, et_cnt:  31.2 train_loss: 20132.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  120, Time: 9.3394s, gt_cnt: 196.0, et_cnt:  88.6 train_loss: 21847.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  130, Time: 19.8650s, gt_cnt:  42.0, et_cnt:  76.6 train_loss: 22573.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  140, Time: 25.5998s, gt_cnt: 678.0, et_cnt: 280.8 train_loss: 29427.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  150, Time: 19.7508s, gt_cnt: 1622.0, et_cnt: 1364.2 train_loss: 32478.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  160, Time: 19.9887s, gt_cnt:  20.0, et_cnt:   8.7 train_loss: 34471.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  170, Time: 15.3490s, gt_cnt: 227.0, et_cnt: 153.1 train_loss: 35989.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  180, Time: 12.9856s, gt_cnt:  95.0, et_cnt: 128.1 train_loss: 38455.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   94, step  190, Time: 9.9323s, gt_cnt: 273.0, et_cnt: 190.4 train_loss: 40283.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step    0, Time: 11.1592s, gt_cnt:  40.0, et_cnt:  98.7 train_loss: 44.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   10, Time: 29.9390s, gt_cnt: 120.0, et_cnt:  42.2 train_loss: 1619.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   20, Time: 21.2343s, gt_cnt:  47.0, et_cnt:  42.0 train_loss: 2162.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   40, Time: 35.3116s, gt_cnt:  38.0, et_cnt: 125.3 train_loss: 9152.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   50, Time: 19.1076s, gt_cnt:  62.0, et_cnt:  50.8 train_loss: 9633.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   60, Time: 21.4535s, gt_cnt: 560.0, et_cnt: 100.7 train_loss: 12898.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   70, Time: 13.3551s, gt_cnt:  76.0, et_cnt:  13.4 train_loss: 14618.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step   90, Time: 32.1156s, gt_cnt:  85.0, et_cnt:  45.8 train_loss: 17038.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  100, Time: 16.9246s, gt_cnt:  61.0, et_cnt:  19.2 train_loss: 17622.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  110, Time: 14.5788s, gt_cnt:  31.0, et_cnt:  28.3 train_loss: 20136.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  120, Time: 9.3915s, gt_cnt: 196.0, et_cnt:  81.7 train_loss: 21848.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  130, Time: 19.6797s, gt_cnt:  42.0, et_cnt:  72.6 train_loss: 22571.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  140, Time: 25.6302s, gt_cnt: 678.0, et_cnt: 304.3 train_loss: 29415.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  150, Time: 19.6600s, gt_cnt: 1622.0, et_cnt: 1667.7 train_loss: 32472.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  160, Time: 19.9242s, gt_cnt:  20.0, et_cnt:   7.4 train_loss: 34467.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  170, Time: 15.3634s, gt_cnt: 227.0, et_cnt: 132.5 train_loss: 35979.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  180, Time: 13.0499s, gt_cnt:  95.0, et_cnt: 131.6 train_loss: 38447.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   95, step  190, Time: 9.9274s, gt_cnt: 273.0, et_cnt: 210.3 train_loss: 40277.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step    0, Time: 11.0321s, gt_cnt:  40.0, et_cnt:  84.9 train_loss: 43.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   10, Time: 29.5252s, gt_cnt: 120.0, et_cnt:  38.3 train_loss: 1619.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   40, Time: 35.1574s, gt_cnt:  38.0, et_cnt: 128.1 train_loss: 9156.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   50, Time: 19.0636s, gt_cnt:  62.0, et_cnt:  49.3 train_loss: 9635.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   60, Time: 21.5960s, gt_cnt: 560.0, et_cnt: 101.5 train_loss: 12894.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   70, Time: 13.3107s, gt_cnt:  76.0, et_cnt:  24.4 train_loss: 14618.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step   90, Time: 31.9919s, gt_cnt:  85.0, et_cnt:  45.4 train_loss: 17033.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  100, Time: 16.8794s, gt_cnt:  61.0, et_cnt:  13.7 train_loss: 17616.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  110, Time: 14.6636s, gt_cnt:  31.0, et_cnt:  30.6 train_loss: 20144.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  120, Time: 9.3769s, gt_cnt: 196.0, et_cnt:  95.4 train_loss: 21858.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  130, Time: 19.3560s, gt_cnt:  42.0, et_cnt:  82.4 train_loss: 22587.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  140, Time: 25.3710s, gt_cnt: 678.0, et_cnt: 269.4 train_loss: 29441.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  150, Time: 19.5721s, gt_cnt: 1622.0, et_cnt: 1194.9 train_loss: 32489.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  160, Time: 19.9170s, gt_cnt:  20.0, et_cnt:   9.3 train_loss: 34482.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  170, Time: 15.5099s, gt_cnt: 227.0, et_cnt: 180.3 train_loss: 35997.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  180, Time: 12.8925s, gt_cnt:  95.0, et_cnt: 121.9 train_loss: 38461.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   96, step  190, Time: 9.8656s, gt_cnt: 273.0, et_cnt: 174.0 train_loss: 40287.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step    0, Time: 11.0617s, gt_cnt:  40.0, et_cnt:  94.3 train_loss: 44.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   10, Time: 29.8237s, gt_cnt: 120.0, et_cnt:  42.6 train_loss: 1619.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   20, Time: 21.2308s, gt_cnt:  47.0, et_cnt:  42.8 train_loss: 2161.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   40, Time: 34.9691s, gt_cnt:  38.0, et_cnt: 120.2 train_loss: 9138.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   50, Time: 19.2290s, gt_cnt:  62.0, et_cnt:  49.3 train_loss: 9617.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   60, Time: 21.6029s, gt_cnt: 560.0, et_cnt: 106.0 train_loss: 12882.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   70, Time: 13.2810s, gt_cnt:  76.0, et_cnt:  12.7 train_loss: 14601.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step   90, Time: 31.6459s, gt_cnt:  85.0, et_cnt:  47.6 train_loss: 17020.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  100, Time: 16.3462s, gt_cnt:  61.0, et_cnt:  20.4 train_loss: 17604.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  110, Time: 14.5926s, gt_cnt:  31.0, et_cnt:  25.3 train_loss: 20113.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  120, Time: 9.4243s, gt_cnt: 196.0, et_cnt:  76.0 train_loss: 21826.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  130, Time: 19.4165s, gt_cnt:  42.0, et_cnt:  69.3 train_loss: 22546.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  140, Time: 25.2850s, gt_cnt: 678.0, et_cnt: 315.5 train_loss: 29379.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  150, Time: 19.4917s, gt_cnt: 1622.0, et_cnt: 1629.5 train_loss: 32432.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  160, Time: 19.8364s, gt_cnt:  20.0, et_cnt:   7.8 train_loss: 34427.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  170, Time: 15.2620s, gt_cnt: 227.0, et_cnt: 135.9 train_loss: 35937.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  180, Time: 12.8711s, gt_cnt:  95.0, et_cnt: 129.1 train_loss: 38402.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   97, step  190, Time: 9.9680s, gt_cnt: 273.0, et_cnt: 202.9 train_loss: 40231.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step    0, Time: 11.1108s, gt_cnt:  40.0, et_cnt:  81.6 train_loss: 43.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   10, Time: 29.8236s, gt_cnt: 120.0, et_cnt:  39.9 train_loss: 1617.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   20, Time: 21.1478s, gt_cnt:  47.0, et_cnt:  41.9 train_loss: 2160.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   40, Time: 35.0982s, gt_cnt:  38.0, et_cnt: 124.1 train_loss: 9142.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   50, Time: 19.5358s, gt_cnt:  62.0, et_cnt:  49.5 train_loss: 9621.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   60, Time: 21.5904s, gt_cnt: 560.0, et_cnt: 104.4 train_loss: 12881.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   70, Time: 13.2427s, gt_cnt:  76.0, et_cnt:  15.8 train_loss: 14598.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step   90, Time: 32.2082s, gt_cnt:  85.0, et_cnt:  52.1 train_loss: 17012.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  100, Time: 16.5071s, gt_cnt:  61.0, et_cnt:  18.2 train_loss: 17596.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  110, Time: 14.5481s, gt_cnt:  31.0, et_cnt:  28.5 train_loss: 20108.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  120, Time: 9.3731s, gt_cnt: 196.0, et_cnt:  84.3 train_loss: 21821.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  130, Time: 19.5220s, gt_cnt:  42.0, et_cnt:  77.3 train_loss: 22546.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  140, Time: 25.6082s, gt_cnt: 678.0, et_cnt: 288.5 train_loss: 29378.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  150, Time: 19.7246s, gt_cnt: 1622.0, et_cnt: 1276.7 train_loss: 32424.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  160, Time: 20.0402s, gt_cnt:  20.0, et_cnt:   8.8 train_loss: 34416.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  170, Time: 15.5637s, gt_cnt: 227.0, et_cnt: 156.9 train_loss: 35934.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  180, Time: 12.9383s, gt_cnt:  95.0, et_cnt: 126.7 train_loss: 38394.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   98, step  190, Time: 9.9241s, gt_cnt: 273.0, et_cnt: 181.9 train_loss: 40218.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step    0, Time: 11.1347s, gt_cnt:  40.0, et_cnt:  96.7 train_loss: 44.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:   99, step   10, Time: 29.9828s, gt_cnt: 120.0, et_cnt:  44.3 train_loss: 1618.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   20, Time: 21.3027s, gt_cnt:  47.0, et_cnt:  42.6 train_loss: 2161.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   40, Time: 35.3969s, gt_cnt:  38.0, et_cnt: 121.7 train_loss: 9132.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   50, Time: 19.0526s, gt_cnt:  62.0, et_cnt:  49.7 train_loss: 9613.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   60, Time: 21.5371s, gt_cnt: 560.0, et_cnt: 105.0 train_loss: 12873.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   70, Time: 13.2804s, gt_cnt:  76.0, et_cnt:  11.3 train_loss: 14592.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step   90, Time: 32.0898s, gt_cnt:  85.0, et_cnt:  47.9 train_loss: 17010.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  100, Time: 16.4635s, gt_cnt:  61.0, et_cnt:  20.9 train_loss: 17593.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  110, Time: 14.6046s, gt_cnt:  31.0, et_cnt:  25.1 train_loss: 20100.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  120, Time: 9.3852s, gt_cnt: 196.0, et_cnt:  79.9 train_loss: 21810.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  130, Time: 19.6487s, gt_cnt:  42.0, et_cnt:  71.5 train_loss: 22532.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  140, Time: 25.6045s, gt_cnt: 678.0, et_cnt: 316.1 train_loss: 29353.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  150, Time: 19.6741s, gt_cnt: 1622.0, et_cnt: 1707.4 train_loss: 32407.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  160, Time: 19.9414s, gt_cnt:  20.0, et_cnt:   7.2 train_loss: 34401.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  170, Time: 15.4354s, gt_cnt: 227.0, et_cnt: 135.0 train_loss: 35912.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  180, Time: 13.0996s, gt_cnt:  95.0, et_cnt: 124.7 train_loss: 38378.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:   99, step  190, Time: 9.9429s, gt_cnt: 273.0, et_cnt: 210.5 train_loss: 40206.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "\n",
    "    for _ , blob in enumerate(data_loader, 1):         \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "                \n",
    "        # Forward pass + backward pass + optimise\n",
    "        try:\n",
    "            density_map = model(im_data, gt_data)\n",
    "            loss = model.loss\n",
    "            # Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Write to tensorboard\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "\n",
    "            # Write to tensorboard\n",
    "            #writer.add_scalar(f\"Loss/train_{epoch}\", train_loss, step)\n",
    "\n",
    "            if step % disp_interval == 0:\n",
    "                duration = t.toc(average=False)\n",
    "                gt_count = torch.sum(gt_data)    \n",
    "\n",
    "                et_count = torch.sum(density_map)\n",
    "                #utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "\n",
    "                # Log the results per display rate\n",
    "                log_text = (\n",
    "                    'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %5.1f, et_cnt: %5.1f train_loss: %4.1f' % (epoch,\n",
    "                    step, duration, gt_count,et_count, train_loss)\n",
    "                )\n",
    "                log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "                # Reset timer\n",
    "                re_cnt = True    \n",
    "\n",
    "\n",
    "            if re_cnt:                                \n",
    "                t.tic()\n",
    "                re_cnt = False\n",
    "\n",
    "        except Exception as e:\n",
    "            #print(e)\n",
    "            continue\n",
    "            \n",
    "    continue\n",
    "    \n",
    "    # Overwrite the current model weights\n",
    "    current_model = f'{method}_{learning_rate}.h5'\n",
    "    save_name = os.path.join(output_dir, current_model)\n",
    "    network.save_net(save_name, model)\n",
    "\n",
    "    # Evaluate the mae and mse results by doing a forward pass against the validation dataset i.e data_loader_val for\n",
    "    # each epoch\n",
    "\n",
    "    MAEcrowddensity, MSEcrowddensity, MAPEcrowddensity, MAEweather, MSEweather, MAPEweather, MAE, MSE, RMSE, MAPE = evaluate_model(save_name, data_loader_val, is_cuda=False)    \n",
    "    \n",
    "    # Pocket algorithm: Check to see if the current epoch mae is better than the best recorded one,\n",
    "    # If it is, then overwrite the current best .h5 weights file\n",
    "    if MAE < best_mae:\n",
    "        # Save the new best mae and mse\n",
    "        best_mae = MAE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_MAE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mae_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    if MSE < best_mse:\n",
    "        # Save the new best mae and mse\n",
    "        best_mse = MSE\n",
    "        best_epoch = epoch\n",
    "\n",
    "        best_model = f'best_MSE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mse_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    if MAPE < best_mape:\n",
    "        # Save the new best mae and mse\n",
    "        best_mape = MAPE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_MAPE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mape_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "\n",
    "\n",
    "    # Print out the best epoch that beat the current best mae\n",
    "    log_text = f'EPOCH: {epoch}, MAE: {MAE}, MSE: {MSE} RMSE: {RMSE}'\n",
    "    log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "\n",
    "    # Save the results to tensorboard for each epoch\n",
    "    if use_tensorboard:\n",
    "        # overall segment\n",
    "        writer.add_scalar(\"Overall/Val MAE\", MAE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val MSE\", MSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val RMSE\", RMSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Train MSE\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        writer.add_scalar(\"Overall/Train RMSE\", np.sqrt(train_loss / data_loader.get_num_samples()), epoch)\n",
    "        writer.add_scalar(\"Overall/Val MAPE\", MAPE, epoch)\n",
    "        writer.add_scalar(\"Overall/Train Loss\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        \n",
    "        \n",
    "        # crowd density segment\n",
    "\n",
    "        writer.add_scalar('Crowd Density/High/MAE', MAEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/MSE', MSEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/RMSE', np.sqrt(MSEcrowddensity['High']), epoch)\n",
    "        writer.add_scalar('Crowd Density/High/MAPE', MAPEcrowddensity['High'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Med/MAE', MAEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/MSE', MSEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/RMSE', np.sqrt(MSEcrowddensity['Med']), epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/MAPE', MAPEcrowddensity['Med'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Low/MAE', MAEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/MSE', MSEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/RMSE', np.sqrt(MSEcrowddensity['Low']), epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/MAPE', MAPEcrowddensity['Low'], epoch)\n",
    "        \n",
    "        # weather segment\n",
    "\n",
    "        writer.add_scalar('Weather/No Degradation/MAE', MAEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/MSE', MSEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/RMSE', np.sqrt(MSEweather['None']), epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/MAPE', MAPEweather['None'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Fog/MAE', MAEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/MSE', MSEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/RMSE', np.sqrt(MSEweather['Fog']), epoch)\n",
    "        writer.add_scalar('Weather/Fog/MAPE', MAPEweather['Fog'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Rain/MAE', MAEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/MSE', MSEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/RMSE', np.sqrt(MSEweather['Rain']), epoch)\n",
    "        writer.add_scalar('Weather/Rain/MAPE', MAPEweather['Rain'], epoch)\n",
    "        \n",
    "\n",
    "        writer.add_scalar('Weather/Snow/MAE', MAEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/MSE', MSEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/RMSE', np.sqrt(MSEweather['Snow']), epoch)\n",
    "        writer.add_scalar('Weather/Snow/MAPE', MAPEweather['Snow'], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mBEST MAE: 999999, BEST MSE: 999999, BEST MAPE: 9999999\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log_text = f'BEST MAE: {best_mae}, BEST MSE: {best_mse}, BEST MAPE: {best_mape}'\n",
    "log_print(log_text, color='green', attrs=['bold'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_mape_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-003c1c43d9b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_mape_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_mape_path' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(best_mape_path, data_loader_val, is_cuda=is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.smc.src.evaluate_model import analyse_loader\n",
    "\n",
    "analyse_loader(data_loader_val)\n",
    "analyse_loader(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mape_path = '../output/smc/saved_models/JHU/smc_0.0001.h5'\n",
    "\n",
    "is_cuda = False\n",
    "model2 = CrowdCounter(is_cuda=is_cuda)\n",
    "network.weights_normal_init(model2, dev=0.01)\n",
    "\n",
    "from models.csrnet_pytorch.src.network import load_net\n",
    "load_net(best_mape_path, model)\n",
    "model2.eval()\n",
    "\n",
    "for i in [23,18,11,15,32,7]:\n",
    "    test_image = data_loader_test.get_test_input(index=i)\n",
    "    density_map_test = model2(test_image['data'])\n",
    "    save_density_map(density_map_test.detach().numpy(), output_dir, fname=f'results_{i}.jpg')\n",
    "    \n",
    "    im_gray = cv2.imread(os.path.join(output_dir, f'results_{i}.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "    im_jet = cv2.applyColorMap(im_gray, cv2.COLORMAP_JET)\n",
    "    print(cv2.imwrite(os.path.join(output_dir, f'results_{i}.jpg'), im_jet))\n",
    "    \n",
    "    plt.imshow(cv2.imread(os.path.join(output_dir, f'results_{i}.jpg')))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.smc.src import *\n",
    "from models.smc.src.crowd_count import *\n",
    "from models.smc.src.network import *\n",
    "from models.smc.src.data_loader import ImageDataLoader\n",
    "from models.smc.src.timer import *\n",
    "from models.smc.src.evaluate_model import *\n",
    "from models.smc.src import utils\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check to see if device can be trained on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Using gpu Tesla T4 with device number 0.\n",
      "Memory allocated = 0\n",
      "Memory cached = 0\n"
     ]
    }
   ],
   "source": [
    "# Cuda configurations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "current_device_name = torch.cuda.get_device_name(current_device)\n",
    "memory_allocated = torch.cuda.memory_allocated()\n",
    "memory_cached = torch.cuda.memory_reserved()\n",
    "\n",
    "print(\n",
    "    f'Using gpu {current_device_name} with device number {current_device}.\\n'\n",
    "    f'Memory allocated = {memory_allocated}\\n'\n",
    "    f'Memory cached = {memory_cached}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'smc'\n",
    "dataset_name = 'JHU'\n",
    "output_dir = f'../output/{method}/saved_models/{dataset_name}'\n",
    "\n",
    "# Training data path\n",
    "train_path = '../data/JHU/train/consolidated'\n",
    "train_gt_path = '../data/JHU/train/gt'\n",
    "\n",
    "# Validation data path\n",
    "val_path = '../data/JHU/val/consolidated'\n",
    "val_gt_path = '../data/JHU/val/gt'\n",
    "\n",
    "# Test data path\n",
    "test_path = '../data/JHU/test/consolidated'\n",
    "test_gt_path = '../data/JHU/test/gt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (model): SMC(\n",
       "    (r1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(40, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(20, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_2): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r3): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Conv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Conv2d(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(82, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "is_cuda = True  # Determine if we should use the CPU to train or GPU\n",
    "\n",
    "model = CrowdCounter(is_cuda=is_cuda)  # is_cuda determines if all the input tensors should be converted to cuda tensors\n",
    "network.weights_normal_init(model, dev=0.01)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.r1.0.conv.weight\tcpu\ttorch.Size([16, 3, 9, 9])\n",
      "model.r1.0.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.2.conv.weight\tcpu\ttorch.Size([32, 16, 7, 7])\n",
      "model.r1.2.conv.bias\tcpu\ttorch.Size([32])\n",
      "model.r1.4.conv.weight\tcpu\ttorch.Size([16, 32, 7, 7])\n",
      "model.r1.4.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.5.conv.weight\tcpu\ttorch.Size([8, 16, 7, 7])\n",
      "model.r1.5.conv.bias\tcpu\ttorch.Size([8])\n",
      "model.r2_1.0.conv.weight\tcpu\ttorch.Size([20, 3, 7, 7])\n",
      "model.r2_1.0.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.2.conv.weight\tcpu\ttorch.Size([40, 20, 5, 5])\n",
      "model.r2_1.2.conv.bias\tcpu\ttorch.Size([40])\n",
      "model.r2_1.4.conv.weight\tcpu\ttorch.Size([20, 40, 5, 5])\n",
      "model.r2_1.4.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.5.conv.weight\tcpu\ttorch.Size([10, 20, 5, 5])\n",
      "model.r2_1.5.conv.bias\tcpu\ttorch.Size([10])\n",
      "model.r2_2.0.conv.weight\tcpu\ttorch.Size([24, 3, 5, 5])\n",
      "model.r2_2.0.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.2.conv.weight\tcpu\ttorch.Size([48, 24, 3, 3])\n",
      "model.r2_2.2.conv.bias\tcpu\ttorch.Size([48])\n",
      "model.r2_2.4.conv.weight\tcpu\ttorch.Size([24, 48, 3, 3])\n",
      "model.r2_2.4.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.5.conv.weight\tcpu\ttorch.Size([12, 24, 3, 3])\n",
      "model.r2_2.5.conv.bias\tcpu\ttorch.Size([12])\n",
      "model.r3.0.conv.weight\tcpu\ttorch.Size([64, 3, 3, 3])\n",
      "model.r3.0.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.1.conv.weight\tcpu\ttorch.Size([64, 64, 3, 3])\n",
      "model.r3.1.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.3.conv.weight\tcpu\ttorch.Size([128, 64, 3, 3])\n",
      "model.r3.3.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.4.conv.weight\tcpu\ttorch.Size([128, 128, 3, 3])\n",
      "model.r3.4.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.6.conv.weight\tcpu\ttorch.Size([256, 128, 3, 3])\n",
      "model.r3.6.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.7.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.7.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.8.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.8.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.9.conv.weight\tcpu\ttorch.Size([512, 256, 3, 3])\n",
      "model.r3.9.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.10.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.10.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.11.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.11.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.12.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.12.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.13.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.13.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.14.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.14.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.15.conv.weight\tcpu\ttorch.Size([256, 512, 3, 3])\n",
      "model.r3.15.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.16.conv.weight\tcpu\ttorch.Size([128, 256, 3, 3])\n",
      "model.r3.16.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.17.conv.weight\tcpu\ttorch.Size([64, 128, 3, 3])\n",
      "model.r3.17.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.fuse.0.conv.weight\tcpu\ttorch.Size([1, 82, 1, 1])\n",
      "model.fuse.0.conv.bias\tcpu\ttorch.Size([1])\n",
      "\n",
      "Model's state_dict: \n",
      "\n",
      "model.r1.0.conv.weight \t torch.float32\n",
      "model.r1.0.conv.bias \t torch.float32\n",
      "model.r1.2.conv.weight \t torch.float32\n",
      "model.r1.2.conv.bias \t torch.float32\n",
      "model.r1.4.conv.weight \t torch.float32\n",
      "model.r1.4.conv.bias \t torch.float32\n",
      "model.r1.5.conv.weight \t torch.float32\n",
      "model.r1.5.conv.bias \t torch.float32\n",
      "model.r2_1.0.conv.weight \t torch.float32\n",
      "model.r2_1.0.conv.bias \t torch.float32\n",
      "model.r2_1.2.conv.weight \t torch.float32\n",
      "model.r2_1.2.conv.bias \t torch.float32\n",
      "model.r2_1.4.conv.weight \t torch.float32\n",
      "model.r2_1.4.conv.bias \t torch.float32\n",
      "model.r2_1.5.conv.weight \t torch.float32\n",
      "model.r2_1.5.conv.bias \t torch.float32\n",
      "model.r2_2.0.conv.weight \t torch.float32\n",
      "model.r2_2.0.conv.bias \t torch.float32\n",
      "model.r2_2.2.conv.weight \t torch.float32\n",
      "model.r2_2.2.conv.bias \t torch.float32\n",
      "model.r2_2.4.conv.weight \t torch.float32\n",
      "model.r2_2.4.conv.bias \t torch.float32\n",
      "model.r2_2.5.conv.weight \t torch.float32\n",
      "model.r2_2.5.conv.bias \t torch.float32\n",
      "model.r3.0.conv.weight \t torch.float32\n",
      "model.r3.0.conv.bias \t torch.float32\n",
      "model.r3.1.conv.weight \t torch.float32\n",
      "model.r3.1.conv.bias \t torch.float32\n",
      "model.r3.3.conv.weight \t torch.float32\n",
      "model.r3.3.conv.bias \t torch.float32\n",
      "model.r3.4.conv.weight \t torch.float32\n",
      "model.r3.4.conv.bias \t torch.float32\n",
      "model.r3.6.conv.weight \t torch.float32\n",
      "model.r3.6.conv.bias \t torch.float32\n",
      "model.r3.7.conv.weight \t torch.float32\n",
      "model.r3.7.conv.bias \t torch.float32\n",
      "model.r3.8.conv.weight \t torch.float32\n",
      "model.r3.8.conv.bias \t torch.float32\n",
      "model.r3.9.conv.weight \t torch.float32\n",
      "model.r3.9.conv.bias \t torch.float32\n",
      "model.r3.10.conv.weight \t torch.float32\n",
      "model.r3.10.conv.bias \t torch.float32\n",
      "model.r3.11.conv.weight \t torch.float32\n",
      "model.r3.11.conv.bias \t torch.float32\n",
      "model.r3.12.conv.weight \t torch.float32\n",
      "model.r3.12.conv.bias \t torch.float32\n",
      "model.r3.13.conv.weight \t torch.float32\n",
      "model.r3.13.conv.bias \t torch.float32\n",
      "model.r3.14.conv.weight \t torch.float32\n",
      "model.r3.14.conv.bias \t torch.float32\n",
      "model.r3.15.conv.weight \t torch.float32\n",
      "model.r3.15.conv.bias \t torch.float32\n",
      "model.r3.16.conv.weight \t torch.float32\n",
      "model.r3.16.conv.bias \t torch.float32\n",
      "model.r3.17.conv.weight \t torch.float32\n",
      "model.r3.17.conv.bias \t torch.float32\n",
      "model.fuse.0.conv.weight \t torch.float32\n",
      "model.fuse.0.conv.bias \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}\\t{param.device}\\t{param.shape}')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"\\nModel's state_dict: \\n\")\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, \"\\t\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing to cuda weights\n"
     ]
    }
   ],
   "source": [
    "# Change model weights tensors to be cuda tensors if is_cuda is true and cuda is available\n",
    "\n",
    "if is_cuda and torch.cuda.is_available():\n",
    "    print(\"Changing to cuda weights\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "disp_interval = 10\n",
    "\n",
    "train_loss = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "\n",
    "# Set initial values\n",
    "best_mae, best_mse, best_epoch, best_mape = 999999, 999999, 0, 9999999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 100\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images, take note the num_pool argument\n",
    "\n",
    "data_loader = ImageDataLoader(train_path, shuffle=False, pre_load=False, num_pool = 2, size=200)\n",
    "data_loader_val = ImageDataLoader(val_path, shuffle=False, pre_load=False, num_pool = 2, size=40)\n",
    "data_loader_test = ImageDataLoader(test_path, shuffle=False, pre_load=False, num_pool = 2, size=40)\n",
    "\n",
    "# Saved weights\n",
    "save_name = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "current_date = datetime.now()\n",
    " \n",
    "# dd/mm/YY H:M:S\n",
    "cd_string = current_date.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs/{learning_rate}_{epochs}_{cd_string}')\n",
    "\n",
    "# Add model to tensorboard\n",
    "dummy_input = data_loader.get_dummy_input()\n",
    "\n",
    "writer.add_graph(model.get_model(), Variable(torch.from_numpy(dummy_input['data']).type(torch.FloatTensor)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 5.2897s, gt_cnt: 67.0, et_cnt: 174.5 train_loss: 75.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   10, Time: 20.4339s, gt_cnt: 270.9, et_cnt: 181.8 train_loss: 6599.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   20, Time: 19.1358s, gt_cnt: 18.4, et_cnt: 158.0 train_loss: 7474.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   30, Time: 20.7907s, gt_cnt: 26.1, et_cnt: 138.7 train_loss: 12109.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   40, Time: 18.7524s, gt_cnt: 71.7, et_cnt: 142.0 train_loss: 15821.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   50, Time: 21.5251s, gt_cnt: 424.4, et_cnt: 112.5 train_loss: 17147.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   60, Time: 19.2873s, gt_cnt: 447.1, et_cnt: 100.6 train_loss: 20634.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   70, Time: 19.0437s, gt_cnt: 579.7, et_cnt: 108.8 train_loss: 26343.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   80, Time: 22.3300s, gt_cnt:  1.0, et_cnt: 123.9 train_loss: 28379.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   90, Time: 19.3252s, gt_cnt: 141.8, et_cnt: 115.5 train_loss: 32021.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  100, Time: 22.4955s, gt_cnt: 131.4, et_cnt: 116.4 train_loss: 34855.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  110, Time: 19.4819s, gt_cnt: 21.7, et_cnt: 130.6 train_loss: 39097.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  120, Time: 19.3722s, gt_cnt: 472.4, et_cnt: 133.1 train_loss: 43403.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  130, Time: 22.5179s, gt_cnt: 163.6, et_cnt: 144.0 train_loss: 44420.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  140, Time: 20.4636s, gt_cnt: 2686.5, et_cnt: 133.6 train_loss: 50425.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  150, Time: 21.2730s, gt_cnt: 2206.5, et_cnt: 159.8 train_loss: 55600.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  160, Time: 22.3570s, gt_cnt: 73.0, et_cnt: 186.3 train_loss: 59865.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  170, Time: 20.7667s, gt_cnt: 583.4, et_cnt: 132.0 train_loss: 62488.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  180, Time: 20.6623s, gt_cnt: 337.5, et_cnt: 108.0 train_loss: 67699.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step  190, Time: 19.6268s, gt_cnt: 401.4, et_cnt: 145.9 train_loss: 73101.5\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 0, MAE: 241.70198421478273, MSE: 157535.8814382553 RMSE: 396.9079004482719\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 47.0860s, gt_cnt: 67.0, et_cnt: 171.4 train_loss: 75.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   10, Time: 21.8386s, gt_cnt: 270.9, et_cnt: 176.9 train_loss: 6599.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   20, Time: 20.6669s, gt_cnt: 18.4, et_cnt: 156.0 train_loss: 7475.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   30, Time: 22.2613s, gt_cnt: 26.1, et_cnt: 138.8 train_loss: 12110.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   40, Time: 19.8940s, gt_cnt: 71.7, et_cnt: 141.2 train_loss: 15822.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   50, Time: 22.7056s, gt_cnt: 424.4, et_cnt: 106.4 train_loss: 17148.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   60, Time: 20.1289s, gt_cnt: 447.1, et_cnt: 98.6 train_loss: 20635.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   70, Time: 19.8829s, gt_cnt: 579.7, et_cnt: 113.2 train_loss: 26343.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   80, Time: 23.3501s, gt_cnt:  1.0, et_cnt: 127.8 train_loss: 28379.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   90, Time: 19.9212s, gt_cnt: 141.8, et_cnt: 120.2 train_loss: 32021.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  100, Time: 23.0272s, gt_cnt: 131.4, et_cnt: 121.3 train_loss: 34855.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  110, Time: 19.8835s, gt_cnt: 21.7, et_cnt: 128.2 train_loss: 39097.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  120, Time: 19.7309s, gt_cnt: 472.4, et_cnt: 132.2 train_loss: 43402.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  130, Time: 22.8518s, gt_cnt: 163.6, et_cnt: 142.6 train_loss: 44420.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  140, Time: 20.7227s, gt_cnt: 2686.5, et_cnt: 137.0 train_loss: 50425.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  150, Time: 21.4598s, gt_cnt: 2206.5, et_cnt: 159.5 train_loss: 55599.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  160, Time: 22.8601s, gt_cnt: 73.0, et_cnt: 180.5 train_loss: 59864.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  170, Time: 20.8067s, gt_cnt: 583.4, et_cnt: 147.2 train_loss: 62487.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  180, Time: 20.8371s, gt_cnt: 337.5, et_cnt: 128.7 train_loss: 67695.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step  190, Time: 19.7309s, gt_cnt: 401.4, et_cnt: 152.7 train_loss: 73095.2\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 1, MAE: 243.22968349456787, MSE: 156763.03603172302 RMSE: 395.9331206551468\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    0, Time: 47.1348s, gt_cnt: 67.0, et_cnt: 175.7 train_loss: 75.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   10, Time: 21.8635s, gt_cnt: 270.9, et_cnt: 180.8 train_loss: 6599.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   20, Time: 20.7250s, gt_cnt: 18.4, et_cnt: 160.9 train_loss: 7475.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   30, Time: 22.4195s, gt_cnt: 26.1, et_cnt: 144.3 train_loss: 12109.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   40, Time: 19.9831s, gt_cnt: 71.7, et_cnt: 146.8 train_loss: 15821.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   50, Time: 22.5822s, gt_cnt: 424.4, et_cnt: 116.9 train_loss: 17147.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   60, Time: 20.1167s, gt_cnt: 447.1, et_cnt: 103.0 train_loss: 20633.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   70, Time: 19.8174s, gt_cnt: 579.7, et_cnt: 108.3 train_loss: 26342.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   80, Time: 23.1181s, gt_cnt:  1.0, et_cnt: 119.9 train_loss: 28378.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   90, Time: 19.8627s, gt_cnt: 141.8, et_cnt: 113.4 train_loss: 32020.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  100, Time: 22.9430s, gt_cnt: 131.4, et_cnt: 114.4 train_loss: 34855.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  110, Time: 19.8329s, gt_cnt: 21.7, et_cnt: 121.4 train_loss: 39097.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  120, Time: 19.6880s, gt_cnt: 472.4, et_cnt: 124.9 train_loss: 43403.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  130, Time: 22.9168s, gt_cnt: 163.6, et_cnt: 135.0 train_loss: 44420.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  140, Time: 20.7362s, gt_cnt: 2686.5, et_cnt: 129.7 train_loss: 50426.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  150, Time: 21.4160s, gt_cnt: 2206.5, et_cnt: 152.8 train_loss: 55601.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  160, Time: 22.7906s, gt_cnt: 73.0, et_cnt: 175.9 train_loss: 59867.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  170, Time: 20.7524s, gt_cnt: 583.4, et_cnt: 145.4 train_loss: 62490.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  180, Time: 20.7786s, gt_cnt: 337.5, et_cnt: 128.5 train_loss: 67697.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step  190, Time: 19.7097s, gt_cnt: 401.4, et_cnt: 151.5 train_loss: 73098.2\u001b[0m\n",
      "\u001b[1m\u001b[32mEPOCH: 2, MAE: 242.52789974212646, MSE: 157120.76944885254 RMSE: 396.3846231236178\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    0, Time: 46.9345s, gt_cnt: 67.0, et_cnt: 173.7 train_loss: 75.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   10, Time: 21.9017s, gt_cnt: 270.9, et_cnt: 178.7 train_loss: 6599.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   20, Time: 20.6550s, gt_cnt: 18.4, et_cnt: 159.5 train_loss: 7475.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   30, Time: 22.3094s, gt_cnt: 26.1, et_cnt: 143.6 train_loss: 12109.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   40, Time: 19.9681s, gt_cnt: 71.7, et_cnt: 146.0 train_loss: 15821.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   50, Time: 22.5908s, gt_cnt: 424.4, et_cnt: 117.1 train_loss: 17147.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   60, Time: 20.1273s, gt_cnt: 447.1, et_cnt: 103.0 train_loss: 20634.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   70, Time: 19.7788s, gt_cnt: 579.7, et_cnt: 108.4 train_loss: 26342.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   80, Time: 23.2251s, gt_cnt:  1.0, et_cnt: 119.4 train_loss: 28378.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   90, Time: 19.8464s, gt_cnt: 141.8, et_cnt: 113.9 train_loss: 32021.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  100, Time: 22.8930s, gt_cnt: 131.4, et_cnt: 116.3 train_loss: 34855.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  110, Time: 19.8316s, gt_cnt: 21.7, et_cnt: 125.6 train_loss: 39097.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  120, Time: 19.7031s, gt_cnt: 472.4, et_cnt: 129.0 train_loss: 43402.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  130, Time: 22.8876s, gt_cnt: 163.6, et_cnt: 139.4 train_loss: 44420.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step  140, Time: 20.7102s, gt_cnt: 2686.5, et_cnt: 133.1 train_loss: 50425.7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "\n",
    "    for _ , blob in enumerate(data_loader, 1):         \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "                \n",
    "        # Forward pass + backward pass + optimise\n",
    "        try:\n",
    "            density_map = model(im_data, gt_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        # Set the parameter gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Write to tensorboard\n",
    "        writer.add_scalar(f\"Loss/train_{epoch}\", train_loss, step)\n",
    "        \n",
    "        if step % disp_interval == 0:\n",
    "            duration = t.toc(average=False)\n",
    "            gt_count = np.sum(gt_data)    \n",
    "\n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            \n",
    "            # Log the results per display rate\n",
    "            log_text = (\n",
    "                'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %4.1f, et_cnt: %4.1f train_loss: %4.1f' % (epoch,\n",
    "                step, duration, gt_count,et_count, train_loss)\n",
    "            )\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            \n",
    "            # Reset timer\n",
    "            re_cnt = True    \n",
    "    \n",
    "       \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "\n",
    "    \n",
    "    # Overwrite the current model weights\n",
    "    current_model = f'{method}_{learning_rate}.h5'\n",
    "    save_name = os.path.join(output_dir, current_model)\n",
    "    network.save_net(save_name, model)\n",
    "\n",
    "    # Evaluate the mae and mse results by doing a forward pass against the validation dataset i.e data_loader_val for\n",
    "    # each epoch\n",
    "\n",
    "    MAEcrowddensity, MSEcrowddensity, MAPEcrowddensity, MAEweather, MSEweather, MAPEweather, MAE, MSE, RMSE, MAPE = evaluate_model(save_name, data_loader_val, is_cuda=is_cuda)    \n",
    "    \n",
    "    # Pocket algorithm: Check to see if the current epoch mae is better than the best recorded one,\n",
    "    # If it is, then overwrite the current best .h5 weights file\n",
    "    if MAE < best_mae:\n",
    "        # Save the new best mae and mse\n",
    "        best_mae = MAE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_MAE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mae_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    if MSE < best_mse:\n",
    "        # Save the new best mae and mse\n",
    "        best_mse = MSE\n",
    "        best_epoch = epoch\n",
    "\n",
    "        best_model = f'best_MSE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mse_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "    if MAPE < best_mape:\n",
    "        # Save the new best mae and mse\n",
    "        best_mape = MAPE\n",
    "        best_epoch = epoch\n",
    "        best_model = f'best_MAPE_epoch_{epoch}_{method}_{learning_rate}.h5'\n",
    "\n",
    "        # Overwrite or create a new file for the best model for this learning rate\n",
    "        save_name = os.path.join(output_dir, best_model)\n",
    "        best_mape_path = save_name\n",
    "        network.save_net(save_name, model)\n",
    "        \n",
    "\n",
    "\n",
    "    # Print out the best epoch that beat the current best mae\n",
    "    log_text = f'EPOCH: {epoch}, MAE: {MAE}, MSE: {MSE} RMSE: {RMSE}'\n",
    "    log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "\n",
    "    # Save the results to tensorboard for each epoch\n",
    "    if use_tensorboard:\n",
    "        # overall segment\n",
    "        writer.add_scalar(\"Overall/Val MAE\", MAE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val MSE\", MSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Val RMSE\", RMSE, epoch)\n",
    "        writer.add_scalar(\"Overall/Train MSE\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        writer.add_scalar(\"Overall/Train RMSE\", np.sqrt(train_loss / data_loader.get_num_samples()), epoch)\n",
    "        writer.add_scalar(\"Overall/Val MAPE\", MAPE, epoch)\n",
    "        writer.add_scalar(\"Overall/Train Loss\", train_loss / data_loader.get_num_samples(), epoch)\n",
    "        \n",
    "        \n",
    "        # crowd density segment\n",
    "\n",
    "        writer.add_scalar('Crowd Density/High/MAE', MAEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/MSE', MSEcrowddensity['High'], epoch)\n",
    "        writer.add_scalar('Crowd Density/High/RMSE', np.sqrt(MSEcrowddensity['High']), epoch)\n",
    "        writer.add_scalar('Crowd Density/High/MAPE', MAPEcrowddensity['High'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Med/MAE', MAEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/MSE', MSEcrowddensity['Med'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/RMSE', np.sqrt(MSEcrowddensity['Med']), epoch)\n",
    "        writer.add_scalar('Crowd Density/Med/MAPE', MAPEcrowddensity['Med'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Crowd Density/Low/MAE', MAEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/MSE', MSEcrowddensity['Low'], epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/RMSE', np.sqrt(MSEcrowddensity['Low']), epoch)\n",
    "        writer.add_scalar('Crowd Density/Low/MAPE', MAPEcrowddensity['Low'], epoch)\n",
    "        \n",
    "        # weather segment\n",
    "\n",
    "        writer.add_scalar('Weather/No Degradation/MAE', MAEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/MSE', MSEweather['None'], epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/RMSE', np.sqrt(MSEweather['None']), epoch)\n",
    "        writer.add_scalar('Weather/No Degradation/MAPE', MAPEweather['None'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Fog/MAE', MAEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/MSE', MSEweather['Fog'], epoch)\n",
    "        writer.add_scalar('Weather/Fog/RMSE', np.sqrt(MSEweather['Fog']), epoch)\n",
    "        writer.add_scalar('Weather/Fog/MAPE', MAPEweather['Fog'], epoch)\n",
    "        \n",
    "        writer.add_scalar('Weather/Rain/MAE', MAEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/MSE', MSEweather['Rain'], epoch)\n",
    "        writer.add_scalar('Weather/Rain/RMSE', np.sqrt(MSEweather['Rain']), epoch)\n",
    "        writer.add_scalar('Weather/Rain/MAPE', MAPEweather['Rain'], epoch)\n",
    "        \n",
    "\n",
    "        writer.add_scalar('Weather/Snow/MAE', MAEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/MSE', MSEweather['Snow'], epoch)\n",
    "        writer.add_scalar('Weather/Snow/RMSE', np.sqrt(MSEweather['Snow']), epoch)\n",
    "        writer.add_scalar('Weather/Snow/MAPE', MAPEweather['Snow'], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_text = f'BEST MAE: {best_mae}, BEST MSE: {best_mse}, BEST MAPE: {best_mape}'\n",
    "log_print(log_text, color='green', attrs=['bold'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_mape_path, data_loader_val, is_cuda=is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.smc.src.evaluate_model import analyse_loader\n",
    "\n",
    "analyse_loader(data_loader_val)\n",
    "analyse_loader(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.smc.src.utils import save_density_map\n",
    "\n",
    "test_image_0 = data_loader_test.get_test_input(num_pool=2, index=0)\n",
    "test_image_1 = data_loader_test.get_test_input(num_pool=2, index=0)\n",
    "test_image_2 = data_loader_test.get_test_input(num_pool=2, index=0)\n",
    "\n",
    "density_map_0 = model(test_image_0['data'])\n",
    "density_map_1 = model(test_image_1['data'])\n",
    "density_map_2 = model(test_image_2['data'])\n",
    "\n",
    "current_date = datetime.now()\n",
    " \n",
    "# dd/mm/YY H:M:S\n",
    "cd_string = current_date.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "save_density_map(density_map_0, output_dir, fname=f'results_0_{cd_string}')\n",
    "save_density_map(density_map_1, output_dir, fname=f'results_1_{cd_string}')\n",
    "save_density_map(density_map_2, output_dir, fname=f'results_2_{cd_string}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

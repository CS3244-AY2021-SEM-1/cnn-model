{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import h5py\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from models.smc.src import *\n",
    "from models.smc.src.crowd_count import *\n",
    "from models.smc.src.network import *\n",
    "from models.smc.src.data_loader import ImageDataLoader\n",
    "from models.smc.src.timer import *\n",
    "from models.smc.src.evaluate_model import *\n",
    "from models.smc.src import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check to see if device can be trained on GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "Using gpu Tesla T4 with device number 0.\n",
      "Memory allocated = 0\n",
      "Memory cached = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cuda configurations\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "current_device_name = torch.cuda.get_device_name(current_device)\n",
    "memory_allocated = torch.cuda.memory_allocated()\n",
    "memory_cached = torch.cuda.memory_cached()\n",
    "\n",
    "print(\n",
    "    f'Using gpu {current_device_name} with device number {current_device}.\\n'\n",
    "    f'Memory allocated = {memory_allocated}\\n'\n",
    "    f'Memory cached = {memory_cached}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from termcolor import cprint\n",
    "except ImportError:\n",
    "    cprint = None\n",
    "\n",
    "\n",
    "def log_print(text, color=None, on_color=None, attrs=None):\n",
    "    if cprint is not None:\n",
    "        cprint(text, color=color, on_color=on_color, attrs=attrs)\n",
    "    else:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Configurations\n",
    "\n",
    "method = 'smc'\n",
    "dataset_name = 'shtechB'\n",
    "output_dir = f'../output/{method}/saved_models'\n",
    "\n",
    "# Training data path\n",
    "train_path = '../data/SHT/part_B_final/train_data/consolidated'\n",
    "train_gt_path = '../data/SHT/part_B_final/train_data/ground_truth'\n",
    "\n",
    "# Validation data path\n",
    "val_path = '../data/SHT/part_B_final/test_data/consolidated'\n",
    "val_gt_path = '../data/SHT/part_B_final/test_data/ground_truth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesnt exist\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrowdCounter(\n",
       "  (model): SMC(\n",
       "    (r1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_1): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 20, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(40, 20, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(20, 10, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r2_2): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(\n",
       "        (conv): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Conv2d(\n",
       "        (conv): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (r3): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2d(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Conv2d(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Conv2d(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Conv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Conv2d(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Conv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Conv2d(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fuse): Sequential(\n",
       "      (0): Conv2d(\n",
       "        (conv): Conv2d(82, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "is_cuda = True  # Determine if we should use the CPU to train or GPU\n",
    "\n",
    "model = CrowdCounter(is_cuda=is_cuda)  # is_cuda determines if all the input tensors should be converted to cuda tensors\n",
    "network.weights_normal_init(model, dev=0.01)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.r1.0.conv.weight\tcpu\ttorch.Size([16, 3, 9, 9])\n",
      "model.r1.0.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.2.conv.weight\tcpu\ttorch.Size([32, 16, 7, 7])\n",
      "model.r1.2.conv.bias\tcpu\ttorch.Size([32])\n",
      "model.r1.4.conv.weight\tcpu\ttorch.Size([16, 32, 7, 7])\n",
      "model.r1.4.conv.bias\tcpu\ttorch.Size([16])\n",
      "model.r1.5.conv.weight\tcpu\ttorch.Size([8, 16, 7, 7])\n",
      "model.r1.5.conv.bias\tcpu\ttorch.Size([8])\n",
      "model.r2_1.0.conv.weight\tcpu\ttorch.Size([20, 3, 7, 7])\n",
      "model.r2_1.0.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.2.conv.weight\tcpu\ttorch.Size([40, 20, 5, 5])\n",
      "model.r2_1.2.conv.bias\tcpu\ttorch.Size([40])\n",
      "model.r2_1.4.conv.weight\tcpu\ttorch.Size([20, 40, 5, 5])\n",
      "model.r2_1.4.conv.bias\tcpu\ttorch.Size([20])\n",
      "model.r2_1.5.conv.weight\tcpu\ttorch.Size([10, 20, 5, 5])\n",
      "model.r2_1.5.conv.bias\tcpu\ttorch.Size([10])\n",
      "model.r2_2.0.conv.weight\tcpu\ttorch.Size([24, 3, 5, 5])\n",
      "model.r2_2.0.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.2.conv.weight\tcpu\ttorch.Size([48, 24, 3, 3])\n",
      "model.r2_2.2.conv.bias\tcpu\ttorch.Size([48])\n",
      "model.r2_2.4.conv.weight\tcpu\ttorch.Size([24, 48, 3, 3])\n",
      "model.r2_2.4.conv.bias\tcpu\ttorch.Size([24])\n",
      "model.r2_2.5.conv.weight\tcpu\ttorch.Size([12, 24, 3, 3])\n",
      "model.r2_2.5.conv.bias\tcpu\ttorch.Size([12])\n",
      "model.r3.0.conv.weight\tcpu\ttorch.Size([64, 3, 3, 3])\n",
      "model.r3.0.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.1.conv.weight\tcpu\ttorch.Size([64, 64, 3, 3])\n",
      "model.r3.1.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.r3.3.conv.weight\tcpu\ttorch.Size([128, 64, 3, 3])\n",
      "model.r3.3.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.4.conv.weight\tcpu\ttorch.Size([128, 128, 3, 3])\n",
      "model.r3.4.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.6.conv.weight\tcpu\ttorch.Size([256, 128, 3, 3])\n",
      "model.r3.6.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.7.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.7.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.8.conv.weight\tcpu\ttorch.Size([256, 256, 3, 3])\n",
      "model.r3.8.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.9.conv.weight\tcpu\ttorch.Size([512, 256, 3, 3])\n",
      "model.r3.9.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.10.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.10.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.11.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.11.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.12.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.12.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.13.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.13.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.14.conv.weight\tcpu\ttorch.Size([512, 512, 3, 3])\n",
      "model.r3.14.conv.bias\tcpu\ttorch.Size([512])\n",
      "model.r3.15.conv.weight\tcpu\ttorch.Size([256, 512, 3, 3])\n",
      "model.r3.15.conv.bias\tcpu\ttorch.Size([256])\n",
      "model.r3.16.conv.weight\tcpu\ttorch.Size([128, 256, 3, 3])\n",
      "model.r3.16.conv.bias\tcpu\ttorch.Size([128])\n",
      "model.r3.17.conv.weight\tcpu\ttorch.Size([64, 128, 3, 3])\n",
      "model.r3.17.conv.bias\tcpu\ttorch.Size([64])\n",
      "model.fuse.0.conv.weight\tcpu\ttorch.Size([1, 82, 1, 1])\n",
      "model.fuse.0.conv.bias\tcpu\ttorch.Size([1])\n",
      "\n",
      "Model's state_dict: \n",
      "\n",
      "model.r1.0.conv.weight \t torch.float32\n",
      "model.r1.0.conv.bias \t torch.float32\n",
      "model.r1.2.conv.weight \t torch.float32\n",
      "model.r1.2.conv.bias \t torch.float32\n",
      "model.r1.4.conv.weight \t torch.float32\n",
      "model.r1.4.conv.bias \t torch.float32\n",
      "model.r1.5.conv.weight \t torch.float32\n",
      "model.r1.5.conv.bias \t torch.float32\n",
      "model.r2_1.0.conv.weight \t torch.float32\n",
      "model.r2_1.0.conv.bias \t torch.float32\n",
      "model.r2_1.2.conv.weight \t torch.float32\n",
      "model.r2_1.2.conv.bias \t torch.float32\n",
      "model.r2_1.4.conv.weight \t torch.float32\n",
      "model.r2_1.4.conv.bias \t torch.float32\n",
      "model.r2_1.5.conv.weight \t torch.float32\n",
      "model.r2_1.5.conv.bias \t torch.float32\n",
      "model.r2_2.0.conv.weight \t torch.float32\n",
      "model.r2_2.0.conv.bias \t torch.float32\n",
      "model.r2_2.2.conv.weight \t torch.float32\n",
      "model.r2_2.2.conv.bias \t torch.float32\n",
      "model.r2_2.4.conv.weight \t torch.float32\n",
      "model.r2_2.4.conv.bias \t torch.float32\n",
      "model.r2_2.5.conv.weight \t torch.float32\n",
      "model.r2_2.5.conv.bias \t torch.float32\n",
      "model.r3.0.conv.weight \t torch.float32\n",
      "model.r3.0.conv.bias \t torch.float32\n",
      "model.r3.1.conv.weight \t torch.float32\n",
      "model.r3.1.conv.bias \t torch.float32\n",
      "model.r3.3.conv.weight \t torch.float32\n",
      "model.r3.3.conv.bias \t torch.float32\n",
      "model.r3.4.conv.weight \t torch.float32\n",
      "model.r3.4.conv.bias \t torch.float32\n",
      "model.r3.6.conv.weight \t torch.float32\n",
      "model.r3.6.conv.bias \t torch.float32\n",
      "model.r3.7.conv.weight \t torch.float32\n",
      "model.r3.7.conv.bias \t torch.float32\n",
      "model.r3.8.conv.weight \t torch.float32\n",
      "model.r3.8.conv.bias \t torch.float32\n",
      "model.r3.9.conv.weight \t torch.float32\n",
      "model.r3.9.conv.bias \t torch.float32\n",
      "model.r3.10.conv.weight \t torch.float32\n",
      "model.r3.10.conv.bias \t torch.float32\n",
      "model.r3.11.conv.weight \t torch.float32\n",
      "model.r3.11.conv.bias \t torch.float32\n",
      "model.r3.12.conv.weight \t torch.float32\n",
      "model.r3.12.conv.bias \t torch.float32\n",
      "model.r3.13.conv.weight \t torch.float32\n",
      "model.r3.13.conv.bias \t torch.float32\n",
      "model.r3.14.conv.weight \t torch.float32\n",
      "model.r3.14.conv.bias \t torch.float32\n",
      "model.r3.15.conv.weight \t torch.float32\n",
      "model.r3.15.conv.bias \t torch.float32\n",
      "model.r3.16.conv.weight \t torch.float32\n",
      "model.r3.16.conv.bias \t torch.float32\n",
      "model.r3.17.conv.weight \t torch.float32\n",
      "model.r3.17.conv.bias \t torch.float32\n",
      "model.fuse.0.conv.weight \t torch.float32\n",
      "model.fuse.0.conv.bias \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}\\t{param.device}\\t{param.shape}')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"\\nModel's state_dict: \\n\")\n",
    "for k, v in model.state_dict().items():\n",
    "    print(k, \"\\t\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing to cuda weights\n"
     ]
    }
   ],
   "source": [
    "# Change model weights tensors to be cuda tensors if is_cuda is true and cuda is available\n",
    "\n",
    "if is_cuda and torch.cuda.is_available():\n",
    "    print(\"Changing to cuda weights\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training configuration\n",
    "\n",
    "momentum = 0.9\n",
    "disp_interval = 2\n",
    "log_interval = 250\n",
    "\n",
    "train_loss = 0\n",
    "step_cnt = 0\n",
    "re_cnt = False\n",
    "t = Timer()\n",
    "t.tic()\n",
    "\n",
    "# Set initial values\n",
    "best_mae, best_mse, best_epoch = 999999, 999999, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "\n",
    "# construct an optimizer\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "#optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images, take note the num_pool argument\n",
    "\n",
    "data_loader = ImageDataLoader(train_path, shuffle=False, pre_load=False, num_pool = 2 )\n",
    "data_loader_val = ImageDataLoader(val_path, shuffle=False, pre_load=False, num_pool = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard  config\n",
    "use_tensorboard = True\n",
    "\n",
    "writer = SummaryWriter(f'../output/tensorboard/runs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    0, step    0, Time: 3.0957s, gt_cnt:  8.7, et_cnt: 13.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    2, Time: 0.0149s, gt_cnt:  1.6, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    4, Time: 0.0146s, gt_cnt:  3.3, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    6, Time: 0.0144s, gt_cnt:  3.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step    8, Time: 0.0142s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   10, Time: 0.0140s, gt_cnt:  1.8, et_cnt:  9.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   12, Time: 0.0137s, gt_cnt:  2.7, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   14, Time: 0.0134s, gt_cnt: 20.4, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   16, Time: 0.0132s, gt_cnt:  6.2, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   18, Time: 0.0130s, gt_cnt: 18.3, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   20, Time: 0.0128s, gt_cnt:  6.7, et_cnt:  7.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   22, Time: 0.0126s, gt_cnt:  2.7, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   24, Time: 0.0124s, gt_cnt:  9.2, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   26, Time: 0.0123s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   28, Time: 0.0121s, gt_cnt:  2.7, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   30, Time: 0.0119s, gt_cnt: 21.4, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   32, Time: 0.0118s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   34, Time: 0.0116s, gt_cnt: 39.8, et_cnt:  8.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   36, Time: 0.0114s, gt_cnt:  1.3, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   38, Time: 0.0113s, gt_cnt: 14.8, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   40, Time: 0.0111s, gt_cnt:  9.7, et_cnt: 10.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   42, Time: 0.0110s, gt_cnt: 10.8, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   44, Time: 0.0109s, gt_cnt: 11.6, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   46, Time: 0.0108s, gt_cnt: 21.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   48, Time: 0.0106s, gt_cnt: 18.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   50, Time: 0.0105s, gt_cnt:  3.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   52, Time: 0.0103s, gt_cnt: 21.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   54, Time: 0.0102s, gt_cnt:  2.8, et_cnt: 11.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   56, Time: 0.0101s, gt_cnt:  8.0, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   58, Time: 0.0100s, gt_cnt:  2.4, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   60, Time: 0.0099s, gt_cnt:  2.0, et_cnt: 10.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   62, Time: 0.0098s, gt_cnt:  2.4, et_cnt:  9.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   64, Time: 0.0097s, gt_cnt: 10.3, et_cnt:  8.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   66, Time: 0.0096s, gt_cnt:  1.0, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   68, Time: 0.0095s, gt_cnt: 15.1, et_cnt:  7.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   70, Time: 0.0094s, gt_cnt:  5.6, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   72, Time: 0.0093s, gt_cnt:  3.4, et_cnt:  6.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   74, Time: 0.0092s, gt_cnt:  8.8, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   76, Time: 0.0090s, gt_cnt:  5.0, et_cnt:  5.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   78, Time: 0.0090s, gt_cnt: 10.7, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   80, Time: 0.0089s, gt_cnt: 13.3, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   82, Time: 0.0088s, gt_cnt: 13.5, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   84, Time: 0.0087s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   86, Time: 0.0086s, gt_cnt: 27.1, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   88, Time: 0.0085s, gt_cnt: 14.3, et_cnt:  8.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   90, Time: 0.0084s, gt_cnt:  8.5, et_cnt:  9.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   92, Time: 0.0084s, gt_cnt:  2.9, et_cnt: 10.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   94, Time: 0.0083s, gt_cnt: 13.9, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   96, Time: 0.0082s, gt_cnt: 13.7, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    0, step   98, Time: 0.0081s, gt_cnt:  2.9, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    0, Time: 0.0090s, gt_cnt:  8.7, et_cnt: 12.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    2, Time: 0.0080s, gt_cnt:  1.6, et_cnt: 12.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    4, Time: 0.0079s, gt_cnt:  3.3, et_cnt: 12.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    6, Time: 0.0078s, gt_cnt:  3.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step    8, Time: 0.0078s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   10, Time: 0.0077s, gt_cnt:  1.8, et_cnt:  9.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   12, Time: 0.0076s, gt_cnt:  2.7, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   14, Time: 0.0075s, gt_cnt: 20.4, et_cnt:  8.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   16, Time: 0.0075s, gt_cnt:  6.2, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   18, Time: 0.0075s, gt_cnt: 18.3, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   20, Time: 0.0074s, gt_cnt:  6.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   22, Time: 0.0073s, gt_cnt:  2.7, et_cnt:  7.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   24, Time: 0.0073s, gt_cnt:  9.2, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   26, Time: 0.0072s, gt_cnt:  2.7, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   28, Time: 0.0072s, gt_cnt:  2.7, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   30, Time: 0.0071s, gt_cnt: 21.4, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   32, Time: 0.0070s, gt_cnt:  6.7, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   34, Time: 0.0070s, gt_cnt: 39.8, et_cnt:  8.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   36, Time: 0.0069s, gt_cnt:  1.3, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   38, Time: 0.0069s, gt_cnt: 14.8, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   40, Time: 0.0068s, gt_cnt:  9.7, et_cnt: 10.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   42, Time: 0.0068s, gt_cnt: 10.8, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   44, Time: 0.0067s, gt_cnt: 11.6, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   46, Time: 0.0067s, gt_cnt: 21.8, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   48, Time: 0.0066s, gt_cnt: 18.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   50, Time: 0.0066s, gt_cnt:  3.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   52, Time: 0.0065s, gt_cnt: 21.7, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   54, Time: 0.0064s, gt_cnt:  2.8, et_cnt: 11.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   56, Time: 0.0064s, gt_cnt:  8.0, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   58, Time: 0.0064s, gt_cnt:  2.4, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   60, Time: 0.0063s, gt_cnt:  2.0, et_cnt: 10.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   62, Time: 0.0063s, gt_cnt:  2.4, et_cnt:  9.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   64, Time: 0.0062s, gt_cnt: 10.3, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   66, Time: 0.0062s, gt_cnt:  1.0, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   68, Time: 0.0062s, gt_cnt: 15.1, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   70, Time: 0.0061s, gt_cnt:  5.6, et_cnt:  6.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   72, Time: 0.0061s, gt_cnt:  3.4, et_cnt:  6.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   74, Time: 0.0061s, gt_cnt:  8.8, et_cnt:  5.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   76, Time: 0.0060s, gt_cnt:  5.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   78, Time: 0.0060s, gt_cnt: 10.7, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   80, Time: 0.0059s, gt_cnt: 13.3, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   82, Time: 0.0059s, gt_cnt: 13.5, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   84, Time: 0.0059s, gt_cnt: 16.6, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   86, Time: 0.0058s, gt_cnt: 27.1, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   88, Time: 0.0058s, gt_cnt: 14.3, et_cnt:  8.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   90, Time: 0.0057s, gt_cnt:  8.5, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   92, Time: 0.0057s, gt_cnt:  2.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   94, Time: 0.0057s, gt_cnt: 13.9, et_cnt: 11.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   96, Time: 0.0056s, gt_cnt: 13.7, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    1, step   98, Time: 0.0056s, gt_cnt:  2.9, et_cnt: 12.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    0, Time: 0.0062s, gt_cnt:  8.7, et_cnt: 13.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    2, Time: 0.0055s, gt_cnt:  1.6, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    4, Time: 0.0055s, gt_cnt:  3.3, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step    6, Time: 0.0054s, gt_cnt:  3.1, et_cnt: 11.5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    2, step    8, Time: 0.0054s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   10, Time: 0.0054s, gt_cnt:  1.8, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   12, Time: 0.0053s, gt_cnt:  2.7, et_cnt:  9.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   14, Time: 0.0053s, gt_cnt: 20.4, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   16, Time: 0.0053s, gt_cnt:  6.2, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   18, Time: 0.0053s, gt_cnt: 18.3, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   20, Time: 0.0052s, gt_cnt:  6.7, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   22, Time: 0.0052s, gt_cnt:  2.7, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   24, Time: 0.0052s, gt_cnt:  9.2, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   26, Time: 0.0051s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   28, Time: 0.0051s, gt_cnt:  2.7, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   30, Time: 0.0051s, gt_cnt: 21.4, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   32, Time: 0.0050s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   34, Time: 0.0050s, gt_cnt: 39.8, et_cnt:  7.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   36, Time: 0.0050s, gt_cnt:  1.3, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   38, Time: 0.0050s, gt_cnt: 14.8, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   40, Time: 0.0050s, gt_cnt:  9.7, et_cnt: 10.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   42, Time: 0.0049s, gt_cnt: 10.8, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   44, Time: 0.0049s, gt_cnt: 11.6, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   46, Time: 0.0049s, gt_cnt: 21.8, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   48, Time: 0.0048s, gt_cnt: 18.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   50, Time: 0.0048s, gt_cnt:  3.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   52, Time: 0.0048s, gt_cnt: 21.7, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   54, Time: 0.0048s, gt_cnt:  2.8, et_cnt: 12.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   56, Time: 0.0047s, gt_cnt:  8.0, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   58, Time: 0.0047s, gt_cnt:  2.4, et_cnt: 10.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   60, Time: 0.0047s, gt_cnt:  2.0, et_cnt: 10.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   62, Time: 0.0047s, gt_cnt:  2.4, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   64, Time: 0.0047s, gt_cnt: 10.3, et_cnt:  8.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   66, Time: 0.0046s, gt_cnt:  1.0, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   68, Time: 0.0046s, gt_cnt: 15.1, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   70, Time: 0.0046s, gt_cnt:  5.6, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   72, Time: 0.0045s, gt_cnt:  3.4, et_cnt:  6.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   74, Time: 0.0045s, gt_cnt:  8.8, et_cnt:  5.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   76, Time: 0.0045s, gt_cnt:  5.0, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   78, Time: 0.0045s, gt_cnt: 10.7, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   80, Time: 0.0044s, gt_cnt: 13.3, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   82, Time: 0.0044s, gt_cnt: 13.5, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   84, Time: 0.0044s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   86, Time: 0.0044s, gt_cnt: 27.1, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   88, Time: 0.0044s, gt_cnt: 14.3, et_cnt:  8.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   90, Time: 0.0043s, gt_cnt:  8.5, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   92, Time: 0.0043s, gt_cnt:  2.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   94, Time: 0.0043s, gt_cnt: 13.9, et_cnt: 11.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   96, Time: 0.0043s, gt_cnt: 13.7, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    2, step   98, Time: 0.0043s, gt_cnt:  2.9, et_cnt: 12.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    0, Time: 0.0047s, gt_cnt:  8.7, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    2, Time: 0.0042s, gt_cnt:  1.6, et_cnt: 12.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    4, Time: 0.0042s, gt_cnt:  3.3, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    6, Time: 0.0042s, gt_cnt:  3.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step    8, Time: 0.0042s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   10, Time: 0.0041s, gt_cnt:  1.8, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   12, Time: 0.0041s, gt_cnt:  2.7, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   14, Time: 0.0041s, gt_cnt: 20.4, et_cnt:  8.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   16, Time: 0.0041s, gt_cnt:  6.2, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   18, Time: 0.0041s, gt_cnt: 18.3, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   20, Time: 0.0040s, gt_cnt:  6.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   22, Time: 0.0040s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   24, Time: 0.0040s, gt_cnt:  9.2, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   26, Time: 0.0040s, gt_cnt:  2.7, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   28, Time: 0.0040s, gt_cnt:  2.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   30, Time: 0.0040s, gt_cnt: 21.4, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   32, Time: 0.0039s, gt_cnt:  6.7, et_cnt:  7.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   34, Time: 0.0039s, gt_cnt: 39.8, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   36, Time: 0.0039s, gt_cnt:  1.3, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   38, Time: 0.0039s, gt_cnt: 14.8, et_cnt:  9.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   40, Time: 0.0039s, gt_cnt:  9.7, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   42, Time: 0.0039s, gt_cnt: 10.8, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   44, Time: 0.0038s, gt_cnt: 11.6, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   46, Time: 0.0038s, gt_cnt: 21.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   48, Time: 0.0038s, gt_cnt: 18.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   50, Time: 0.0038s, gt_cnt:  3.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   52, Time: 0.0038s, gt_cnt: 21.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   54, Time: 0.0037s, gt_cnt:  2.8, et_cnt: 12.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   56, Time: 0.0037s, gt_cnt:  8.0, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   58, Time: 0.0037s, gt_cnt:  2.4, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   60, Time: 0.0037s, gt_cnt:  2.0, et_cnt: 10.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   62, Time: 0.0037s, gt_cnt:  2.4, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   64, Time: 0.0037s, gt_cnt: 10.3, et_cnt:  8.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   66, Time: 0.0037s, gt_cnt:  1.0, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   68, Time: 0.0037s, gt_cnt: 15.1, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   70, Time: 0.0036s, gt_cnt:  5.6, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   72, Time: 0.0036s, gt_cnt:  3.4, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   74, Time: 0.0036s, gt_cnt:  8.8, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   76, Time: 0.0036s, gt_cnt:  5.0, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   78, Time: 0.0036s, gt_cnt: 10.7, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   80, Time: 0.0036s, gt_cnt: 13.3, et_cnt:  5.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   82, Time: 0.0036s, gt_cnt: 13.5, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   84, Time: 0.0035s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   86, Time: 0.0035s, gt_cnt: 27.1, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   88, Time: 0.0035s, gt_cnt: 14.3, et_cnt:  8.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   90, Time: 0.0035s, gt_cnt:  8.5, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   92, Time: 0.0035s, gt_cnt:  2.9, et_cnt: 10.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   94, Time: 0.0035s, gt_cnt: 13.9, et_cnt: 12.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   96, Time: 0.0034s, gt_cnt: 13.7, et_cnt: 13.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    3, step   98, Time: 0.0034s, gt_cnt:  2.9, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    0, Time: 0.0038s, gt_cnt:  8.7, et_cnt: 13.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    2, Time: 0.0034s, gt_cnt:  1.6, et_cnt: 12.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    4, Time: 0.0034s, gt_cnt:  3.3, et_cnt: 12.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    6, Time: 0.0034s, gt_cnt:  3.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step    8, Time: 0.0034s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   10, Time: 0.0034s, gt_cnt:  1.8, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   12, Time: 0.0034s, gt_cnt:  2.7, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   14, Time: 0.0033s, gt_cnt: 20.4, et_cnt:  8.4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    4, step   16, Time: 0.0033s, gt_cnt:  6.2, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   18, Time: 0.0033s, gt_cnt: 18.3, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   20, Time: 0.0033s, gt_cnt:  6.7, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   22, Time: 0.0033s, gt_cnt:  2.7, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   24, Time: 0.0033s, gt_cnt:  9.2, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   26, Time: 0.0033s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   28, Time: 0.0033s, gt_cnt:  2.7, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   30, Time: 0.0032s, gt_cnt: 21.4, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   32, Time: 0.0032s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   34, Time: 0.0032s, gt_cnt: 39.8, et_cnt:  8.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   36, Time: 0.0032s, gt_cnt:  1.3, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   38, Time: 0.0032s, gt_cnt: 14.8, et_cnt:  9.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   40, Time: 0.0032s, gt_cnt:  9.7, et_cnt: 10.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   42, Time: 0.0032s, gt_cnt: 10.8, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   44, Time: 0.0032s, gt_cnt: 11.6, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   46, Time: 0.0031s, gt_cnt: 21.8, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   48, Time: 0.0031s, gt_cnt: 18.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   50, Time: 0.0031s, gt_cnt:  3.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   52, Time: 0.0031s, gt_cnt: 21.7, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   54, Time: 0.0031s, gt_cnt:  2.8, et_cnt: 12.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   56, Time: 0.0031s, gt_cnt:  8.0, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   58, Time: 0.0031s, gt_cnt:  2.4, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   60, Time: 0.0031s, gt_cnt:  2.0, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   62, Time: 0.0031s, gt_cnt:  2.4, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   64, Time: 0.0031s, gt_cnt: 10.3, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   66, Time: 0.0030s, gt_cnt:  1.0, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   68, Time: 0.0030s, gt_cnt: 15.1, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   70, Time: 0.0030s, gt_cnt:  5.6, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   72, Time: 0.0030s, gt_cnt:  3.4, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   74, Time: 0.0030s, gt_cnt:  8.8, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   76, Time: 0.0030s, gt_cnt:  5.0, et_cnt:  5.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   78, Time: 0.0030s, gt_cnt: 10.7, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   80, Time: 0.0030s, gt_cnt: 13.3, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   82, Time: 0.0030s, gt_cnt: 13.5, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   84, Time: 0.0030s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   86, Time: 0.0029s, gt_cnt: 27.1, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   88, Time: 0.0029s, gt_cnt: 14.3, et_cnt:  8.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   90, Time: 0.0029s, gt_cnt:  8.5, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   92, Time: 0.0029s, gt_cnt:  2.9, et_cnt: 10.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   94, Time: 0.0029s, gt_cnt: 13.9, et_cnt: 11.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   96, Time: 0.0029s, gt_cnt: 13.7, et_cnt: 13.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    4, step   98, Time: 0.0029s, gt_cnt:  2.9, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    0, Time: 0.0032s, gt_cnt:  8.7, et_cnt: 12.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    2, Time: 0.0029s, gt_cnt:  1.6, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    4, Time: 0.0028s, gt_cnt:  3.3, et_cnt: 12.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    6, Time: 0.0029s, gt_cnt:  3.1, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step    8, Time: 0.0028s, gt_cnt:  5.9, et_cnt: 10.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   10, Time: 0.0028s, gt_cnt:  1.8, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   12, Time: 0.0028s, gt_cnt:  2.7, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   14, Time: 0.0028s, gt_cnt: 20.4, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   16, Time: 0.0028s, gt_cnt:  6.2, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   18, Time: 0.0028s, gt_cnt: 18.3, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   20, Time: 0.0028s, gt_cnt:  6.7, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   22, Time: 0.0028s, gt_cnt:  2.7, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   24, Time: 0.0028s, gt_cnt:  9.2, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   26, Time: 0.0028s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   28, Time: 0.0027s, gt_cnt:  2.7, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   30, Time: 0.0027s, gt_cnt: 21.4, et_cnt:  7.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   32, Time: 0.0027s, gt_cnt:  6.7, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   34, Time: 0.0027s, gt_cnt: 39.8, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   36, Time: 0.0027s, gt_cnt:  1.3, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   38, Time: 0.0027s, gt_cnt: 14.8, et_cnt:  9.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   40, Time: 0.0027s, gt_cnt:  9.7, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   42, Time: 0.0027s, gt_cnt: 10.8, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   44, Time: 0.0027s, gt_cnt: 11.6, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   46, Time: 0.0027s, gt_cnt: 21.8, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   48, Time: 0.0027s, gt_cnt: 18.1, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   50, Time: 0.0027s, gt_cnt:  3.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   52, Time: 0.0026s, gt_cnt: 21.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   54, Time: 0.0026s, gt_cnt:  2.8, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   56, Time: 0.0026s, gt_cnt:  8.0, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   58, Time: 0.0026s, gt_cnt:  2.4, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   60, Time: 0.0026s, gt_cnt:  2.0, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   62, Time: 0.0026s, gt_cnt:  2.4, et_cnt:  8.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   64, Time: 0.0026s, gt_cnt: 10.3, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   66, Time: 0.0026s, gt_cnt:  1.0, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   68, Time: 0.0026s, gt_cnt: 15.1, et_cnt:  6.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   70, Time: 0.0026s, gt_cnt:  5.6, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   72, Time: 0.0026s, gt_cnt:  3.4, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   74, Time: 0.0026s, gt_cnt:  8.8, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   76, Time: 0.0026s, gt_cnt:  5.0, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   78, Time: 0.0026s, gt_cnt: 10.7, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   80, Time: 0.0026s, gt_cnt: 13.3, et_cnt:  5.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   82, Time: 0.0025s, gt_cnt: 13.5, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   84, Time: 0.0025s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   86, Time: 0.0025s, gt_cnt: 27.1, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   88, Time: 0.0025s, gt_cnt: 14.3, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   90, Time: 0.0025s, gt_cnt:  8.5, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   92, Time: 0.0025s, gt_cnt:  2.9, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   94, Time: 0.0025s, gt_cnt: 13.9, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   96, Time: 0.0025s, gt_cnt: 13.7, et_cnt: 13.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    5, step   98, Time: 0.0025s, gt_cnt:  2.9, et_cnt: 13.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    0, Time: 0.0027s, gt_cnt:  8.7, et_cnt: 13.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    2, Time: 0.0025s, gt_cnt:  1.6, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    4, Time: 0.0025s, gt_cnt:  3.3, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    6, Time: 0.0024s, gt_cnt:  3.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step    8, Time: 0.0024s, gt_cnt:  5.9, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   10, Time: 0.0024s, gt_cnt:  1.8, et_cnt:  9.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   12, Time: 0.0024s, gt_cnt:  2.7, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   14, Time: 0.0024s, gt_cnt: 20.4, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   16, Time: 0.0024s, gt_cnt:  6.2, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   18, Time: 0.0024s, gt_cnt: 18.3, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   20, Time: 0.0024s, gt_cnt:  6.7, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   22, Time: 0.0024s, gt_cnt:  2.7, et_cnt:  6.6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    6, step   24, Time: 0.0024s, gt_cnt:  9.2, et_cnt:  6.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   26, Time: 0.0024s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   28, Time: 0.0024s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   30, Time: 0.0024s, gt_cnt: 21.4, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   32, Time: 0.0024s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   34, Time: 0.0024s, gt_cnt: 39.8, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   36, Time: 0.0024s, gt_cnt:  1.3, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   38, Time: 0.0023s, gt_cnt: 14.8, et_cnt:  9.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   40, Time: 0.0023s, gt_cnt:  9.7, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   42, Time: 0.0023s, gt_cnt: 10.8, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   44, Time: 0.0023s, gt_cnt: 11.6, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   46, Time: 0.0023s, gt_cnt: 21.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   48, Time: 0.0023s, gt_cnt: 18.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   50, Time: 0.0023s, gt_cnt:  3.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   52, Time: 0.0023s, gt_cnt: 21.7, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   54, Time: 0.0023s, gt_cnt:  2.8, et_cnt: 12.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   56, Time: 0.0023s, gt_cnt:  8.0, et_cnt: 11.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   58, Time: 0.0023s, gt_cnt:  2.4, et_cnt: 10.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   60, Time: 0.0023s, gt_cnt:  2.0, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   62, Time: 0.0023s, gt_cnt:  2.4, et_cnt:  8.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   64, Time: 0.0023s, gt_cnt: 10.3, et_cnt:  7.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   66, Time: 0.0023s, gt_cnt:  1.0, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   68, Time: 0.0023s, gt_cnt: 15.1, et_cnt:  6.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   70, Time: 0.0022s, gt_cnt:  5.6, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   72, Time: 0.0022s, gt_cnt:  3.4, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   74, Time: 0.0022s, gt_cnt:  8.8, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   76, Time: 0.0022s, gt_cnt:  5.0, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   78, Time: 0.0022s, gt_cnt: 10.7, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   80, Time: 0.0022s, gt_cnt: 13.3, et_cnt:  5.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   82, Time: 0.0022s, gt_cnt: 13.5, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   84, Time: 0.0022s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   86, Time: 0.0022s, gt_cnt: 27.1, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   88, Time: 0.0022s, gt_cnt: 14.3, et_cnt:  8.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   90, Time: 0.0022s, gt_cnt:  8.5, et_cnt:  9.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   92, Time: 0.0022s, gt_cnt:  2.9, et_cnt: 10.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   94, Time: 0.0022s, gt_cnt: 13.9, et_cnt: 12.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   96, Time: 0.0022s, gt_cnt: 13.7, et_cnt: 13.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    6, step   98, Time: 0.0022s, gt_cnt:  2.9, et_cnt: 13.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    0, Time: 0.0024s, gt_cnt:  8.7, et_cnt: 13.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    2, Time: 0.0021s, gt_cnt:  1.6, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    4, Time: 0.0021s, gt_cnt:  3.3, et_cnt: 12.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    6, Time: 0.0021s, gt_cnt:  3.1, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step    8, Time: 0.0021s, gt_cnt:  5.9, et_cnt: 10.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   10, Time: 0.0021s, gt_cnt:  1.8, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   12, Time: 0.0021s, gt_cnt:  2.7, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   14, Time: 0.0021s, gt_cnt: 20.4, et_cnt:  8.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   16, Time: 0.0021s, gt_cnt:  6.2, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   18, Time: 0.0021s, gt_cnt: 18.3, et_cnt:  7.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   20, Time: 0.0021s, gt_cnt:  6.7, et_cnt:  6.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   22, Time: 0.0021s, gt_cnt:  2.7, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   24, Time: 0.0021s, gt_cnt:  9.2, et_cnt:  6.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   26, Time: 0.0021s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   28, Time: 0.0021s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   30, Time: 0.0021s, gt_cnt: 21.4, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   32, Time: 0.0021s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   34, Time: 0.0021s, gt_cnt: 39.8, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   36, Time: 0.0021s, gt_cnt:  1.3, et_cnt:  9.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   38, Time: 0.0021s, gt_cnt: 14.8, et_cnt:  9.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   40, Time: 0.0021s, gt_cnt:  9.7, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   42, Time: 0.0021s, gt_cnt: 10.8, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   44, Time: 0.0021s, gt_cnt: 11.6, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   46, Time: 0.0021s, gt_cnt: 21.8, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   48, Time: 0.0020s, gt_cnt: 18.1, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   50, Time: 0.0020s, gt_cnt:  3.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   52, Time: 0.0020s, gt_cnt: 21.7, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   54, Time: 0.0020s, gt_cnt:  2.8, et_cnt: 12.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   56, Time: 0.0020s, gt_cnt:  8.0, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   58, Time: 0.0020s, gt_cnt:  2.4, et_cnt: 10.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   60, Time: 0.0020s, gt_cnt:  2.0, et_cnt: 10.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   62, Time: 0.0020s, gt_cnt:  2.4, et_cnt:  8.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   64, Time: 0.0020s, gt_cnt: 10.3, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   66, Time: 0.0020s, gt_cnt:  1.0, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   68, Time: 0.0020s, gt_cnt: 15.1, et_cnt:  6.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   70, Time: 0.0020s, gt_cnt:  5.6, et_cnt:  6.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   72, Time: 0.0020s, gt_cnt:  3.4, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   74, Time: 0.0020s, gt_cnt:  8.8, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   76, Time: 0.0020s, gt_cnt:  5.0, et_cnt:  5.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   78, Time: 0.0020s, gt_cnt: 10.7, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   80, Time: 0.0020s, gt_cnt: 13.3, et_cnt:  5.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   82, Time: 0.0020s, gt_cnt: 13.5, et_cnt:  5.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   84, Time: 0.0020s, gt_cnt: 16.6, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   86, Time: 0.0020s, gt_cnt: 27.1, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   88, Time: 0.0019s, gt_cnt: 14.3, et_cnt:  9.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   90, Time: 0.0020s, gt_cnt:  8.5, et_cnt:  9.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   92, Time: 0.0019s, gt_cnt:  2.9, et_cnt: 11.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   94, Time: 0.0019s, gt_cnt: 13.9, et_cnt: 12.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   96, Time: 0.0019s, gt_cnt: 13.7, et_cnt: 14.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    7, step   98, Time: 0.0019s, gt_cnt:  2.9, et_cnt: 13.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    0, Time: 0.0021s, gt_cnt:  8.7, et_cnt: 13.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    2, Time: 0.0019s, gt_cnt:  1.6, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    4, Time: 0.0019s, gt_cnt:  3.3, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    6, Time: 0.0019s, gt_cnt:  3.1, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step    8, Time: 0.0019s, gt_cnt:  5.9, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   10, Time: 0.0019s, gt_cnt:  1.8, et_cnt:  8.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   12, Time: 0.0019s, gt_cnt:  2.7, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   14, Time: 0.0019s, gt_cnt: 20.4, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   16, Time: 0.0019s, gt_cnt:  6.2, et_cnt:  7.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   18, Time: 0.0019s, gt_cnt: 18.3, et_cnt:  7.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   20, Time: 0.0019s, gt_cnt:  6.7, et_cnt:  6.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   22, Time: 0.0019s, gt_cnt:  2.7, et_cnt:  6.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   24, Time: 0.0019s, gt_cnt:  9.2, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   26, Time: 0.0019s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   28, Time: 0.0019s, gt_cnt:  2.7, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   30, Time: 0.0019s, gt_cnt: 21.4, et_cnt:  7.4\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mepoch:    8, step   32, Time: 0.0019s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   34, Time: 0.0019s, gt_cnt: 39.8, et_cnt:  8.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   36, Time: 0.0019s, gt_cnt:  1.3, et_cnt:  9.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   38, Time: 0.0018s, gt_cnt: 14.8, et_cnt: 10.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   40, Time: 0.0018s, gt_cnt:  9.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   42, Time: 0.0018s, gt_cnt: 10.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   44, Time: 0.0018s, gt_cnt: 11.6, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   46, Time: 0.0018s, gt_cnt: 21.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   48, Time: 0.0018s, gt_cnt: 18.1, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   50, Time: 0.0018s, gt_cnt:  3.7, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   52, Time: 0.0018s, gt_cnt: 21.7, et_cnt: 11.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   54, Time: 0.0018s, gt_cnt:  2.8, et_cnt: 12.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   56, Time: 0.0018s, gt_cnt:  8.0, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   58, Time: 0.0018s, gt_cnt:  2.4, et_cnt: 10.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   60, Time: 0.0018s, gt_cnt:  2.0, et_cnt: 10.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   62, Time: 0.0018s, gt_cnt:  2.4, et_cnt:  8.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   64, Time: 0.0018s, gt_cnt: 10.3, et_cnt:  7.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   66, Time: 0.0018s, gt_cnt:  1.0, et_cnt:  6.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   68, Time: 0.0018s, gt_cnt: 15.1, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   70, Time: 0.0018s, gt_cnt:  5.6, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   72, Time: 0.0018s, gt_cnt:  3.4, et_cnt:  5.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   74, Time: 0.0018s, gt_cnt:  8.8, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   76, Time: 0.0018s, gt_cnt:  5.0, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   78, Time: 0.0018s, gt_cnt: 10.7, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   80, Time: 0.0018s, gt_cnt: 13.3, et_cnt:  4.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   82, Time: 0.0018s, gt_cnt: 13.5, et_cnt:  5.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   84, Time: 0.0018s, gt_cnt: 16.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   86, Time: 0.0018s, gt_cnt: 27.1, et_cnt:  6.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   88, Time: 0.0018s, gt_cnt: 14.3, et_cnt:  9.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   90, Time: 0.0018s, gt_cnt:  8.5, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   92, Time: 0.0017s, gt_cnt:  2.9, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   94, Time: 0.0018s, gt_cnt: 13.9, et_cnt: 13.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   96, Time: 0.0017s, gt_cnt: 13.7, et_cnt: 14.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    8, step   98, Time: 0.0017s, gt_cnt:  2.9, et_cnt: 13.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    0, Time: 0.0019s, gt_cnt:  8.7, et_cnt: 13.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    2, Time: 0.0017s, gt_cnt:  1.6, et_cnt: 12.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    4, Time: 0.0017s, gt_cnt:  3.3, et_cnt: 12.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    6, Time: 0.0017s, gt_cnt:  3.1, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step    8, Time: 0.0017s, gt_cnt:  5.9, et_cnt: 10.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   10, Time: 0.0017s, gt_cnt:  1.8, et_cnt:  8.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   12, Time: 0.0017s, gt_cnt:  2.7, et_cnt:  8.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   14, Time: 0.0017s, gt_cnt: 20.4, et_cnt:  8.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   16, Time: 0.0017s, gt_cnt:  6.2, et_cnt:  7.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   18, Time: 0.0017s, gt_cnt: 18.3, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   20, Time: 0.0017s, gt_cnt:  6.7, et_cnt:  6.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   22, Time: 0.0017s, gt_cnt:  2.7, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   24, Time: 0.0017s, gt_cnt:  9.2, et_cnt:  6.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   26, Time: 0.0017s, gt_cnt:  2.7, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   28, Time: 0.0017s, gt_cnt:  2.7, et_cnt:  7.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   30, Time: 0.0017s, gt_cnt: 21.4, et_cnt:  7.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   32, Time: 0.0017s, gt_cnt:  6.7, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   34, Time: 0.0017s, gt_cnt: 39.8, et_cnt:  8.3\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   36, Time: 0.0017s, gt_cnt:  1.3, et_cnt:  9.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   38, Time: 0.0017s, gt_cnt: 14.8, et_cnt: 10.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   40, Time: 0.0017s, gt_cnt:  9.7, et_cnt: 11.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   42, Time: 0.0017s, gt_cnt: 10.8, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   44, Time: 0.0017s, gt_cnt: 11.6, et_cnt: 11.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   46, Time: 0.0017s, gt_cnt: 21.8, et_cnt: 11.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   48, Time: 0.0017s, gt_cnt: 18.1, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   50, Time: 0.0017s, gt_cnt:  3.7, et_cnt: 11.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   52, Time: 0.0016s, gt_cnt: 21.7, et_cnt: 11.2\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   54, Time: 0.0016s, gt_cnt:  2.8, et_cnt: 12.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   56, Time: 0.0016s, gt_cnt:  8.0, et_cnt: 11.6\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   58, Time: 0.0016s, gt_cnt:  2.4, et_cnt: 10.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   60, Time: 0.0016s, gt_cnt:  2.0, et_cnt: 10.9\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   62, Time: 0.0016s, gt_cnt:  2.4, et_cnt:  7.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   64, Time: 0.0016s, gt_cnt: 10.3, et_cnt:  7.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   66, Time: 0.0016s, gt_cnt:  1.0, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   68, Time: 0.0016s, gt_cnt: 15.1, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   70, Time: 0.0016s, gt_cnt:  5.6, et_cnt:  6.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   72, Time: 0.0016s, gt_cnt:  3.4, et_cnt:  5.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   74, Time: 0.0016s, gt_cnt:  8.8, et_cnt:  5.4\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   76, Time: 0.0016s, gt_cnt:  5.0, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   78, Time: 0.0016s, gt_cnt: 10.7, et_cnt:  5.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   80, Time: 0.0016s, gt_cnt: 13.3, et_cnt:  4.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   82, Time: 0.0016s, gt_cnt: 13.5, et_cnt:  5.0\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   84, Time: 0.0016s, gt_cnt: 16.6, et_cnt:  6.1\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   86, Time: 0.0016s, gt_cnt: 27.1, et_cnt:  6.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   88, Time: 0.0016s, gt_cnt: 14.3, et_cnt:  9.7\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   90, Time: 0.0016s, gt_cnt:  8.5, et_cnt:  9.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   92, Time: 0.0016s, gt_cnt:  2.9, et_cnt: 11.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   94, Time: 0.0016s, gt_cnt: 13.9, et_cnt: 13.8\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   96, Time: 0.0016s, gt_cnt: 13.7, et_cnt: 15.5\u001b[0m\n",
      "\u001b[1m\u001b[32mepoch:    9, step   98, Time: 0.0016s, gt_cnt:  2.9, et_cnt: 13.8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "saved_weights = []\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    step = -1\n",
    "    train_loss = 0\n",
    "    for blob in data_loader:                \n",
    "        step = step + 1        \n",
    "        im_data = blob['data']\n",
    "        gt_data = blob['gt_density']\n",
    "        \n",
    "        # Forward pass\n",
    "        density_map = model(im_data, gt_data)\n",
    "        loss = model.loss\n",
    "        train_loss += loss.data\n",
    "        \n",
    "        # Write to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        # Reset zero gradient and backpropagate\n",
    "        step_cnt += 1\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % disp_interval == 0:            \n",
    "            duration = t.toc(average=False)\n",
    "            fps = step_cnt / duration\n",
    "            gt_count = np.sum(gt_data)    \n",
    "\n",
    "            density_map = density_map.data.cpu().numpy()\n",
    "            et_count = np.sum(density_map)\n",
    "            utils.save_results(im_data,gt_data,density_map, output_dir)\n",
    "            log_text = 'epoch: %4d, step %4d, Time: %.4fs, gt_cnt: %4.1f, et_cnt: %4.1f' % (epoch,\n",
    "                step, 1./fps, gt_count,et_count)\n",
    "            log_print(log_text, color='green', attrs=['bold'])\n",
    "            re_cnt = True    \n",
    "    \n",
    "       \n",
    "        if re_cnt:                                \n",
    "            t.tic()\n",
    "            re_cnt = False\n",
    "\n",
    "    save_name = os.path.join(output_dir, f'{method}_{dataset_name}_{epoch}.h5')\n",
    "    saved_weights.append(save_name)\n",
    "    network.save_net(save_name, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate error on the validation dataset \n",
    "for weights in saved_weights:\n",
    "    mae,mse = evaluate_model(weights, data_loader_val, is_cuda=is_cuda)\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_mse = mse\n",
    "        best_model = '{}_{}_{}.h5'.format(method,dataset_name,epoch)\n",
    "\n",
    "\n",
    "    log_text = 'EPOCH: %d, MAE: %.1f, MSE: %0.1f' % (epoch,mae,mse)\n",
    "    log_print(log_text, color='green', attrs=['bold'])\n",
    "    log_text = 'BEST MAE: %0.1f, BEST MSE: %0.1f, BEST MODEL: %s' % (best_mae,best_mse, best_model)\n",
    "    log_print(log_text, color='green', attrs=['bold'])\n",
    "\n",
    "    if use_tensorboard:\n",
    "        writer.add_scalar(\"MAE\", mae, epoch)\n",
    "        writer.add_scalar(\"MSE\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train_loss\", train_loss/data_loader.get_num_samples(), epoch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
